<!DOCTYPE HTML>
<html lang="zh-CN">
 <!--自定义看板娘-->
  <script src="https://cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script>
  <script src="/live2d-widget/autoload.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"/>


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="TimeChat, 后端开发">
    <meta name="description" content="Java | LeetCode | Algorithm">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>TimeChat | wolf-ll&#39;s blog</title>
    <link rel="icon" type="image/png" href="/medias/logo.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: #FFF;
        text-align: center;
        /* loaderҳ����ʧ���ý����ķ�ʽ*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid #49b1f5;
        border-right-color: transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid #49b1f5;
        border-right-color: transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: #49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: #2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo���ֶ��� */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ʹ�ý����ķ�������loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },1000); 
        },1000);//ǿ����ʾloading page 1s  
    };
    loaded();
})()
 </script><meta name="generator" content="Hexo 7.2.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="wolf-ll's blog" type="application/atom+xml">
</head>





 <div id="loading-container">
     <p class="loading-text"></p> 
     <div class="loading-image">
         <div></div>
         <div></div>
         <div></div>
         <div></div> 
         <div></div>
     </div>
 </div><body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">wolf-ll&#39;s blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">wolf-ll&#39;s blog</div>
        <div class="logo-desc">
            
            Java | LeetCode | Algorithm
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/wolf-ll/wolf-ll.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/wolf-ll/wolf-ll.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/10.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">TimeChat</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/MLLM/">
                                <span class="chip bg-color">MLLM</span>
                            </a>
                        
                            <a href="/tags/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                                <span class="chip bg-color">视频理解</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E8%AE%BA%E6%96%87/" class="post-category">
                                论文
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-10-13
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2024-12-16
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    11.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    49 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="TimeChat-A-Time-sensitive-Multimodal-Large-Language-Model"><a href="#TimeChat-A-Time-sensitive-Multimodal-Large-Language-Model" class="headerlink" title="TimeChat: A Time-sensitive Multimodal Large Language Model"></a>TimeChat: A Time-sensitive Multimodal Large Language Model</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>本研究提出的 TimeChat 是一种时间敏感的多模态大型语言模型，专为长视频理解而设计。模型包含两个关键的架构贡献：（1）<strong>时间戳感知帧编码器</strong>，可以将视觉内容与每个帧的时间戳绑定；（2）<strong>滑动视频 Q-Former</strong>，生成不同长度的视频token序列，以适应不同时长的视频。此外，本文还构建了一个<strong>指令微调（instruction-tuning）数据集，包含 6 个任务和总共 125K 个实例</strong>，以进一步提高 TimeChat 的instruction-following性能。各种视频理解任务（如dense captioning, temporal grounding, and highlight detection）的实验结果都证明了 TimeChat 强大的<strong>零样本时间定位和推理</strong>能力。例如，与最先进的视频大语言模型相比，TimeChat 在 YouCook2 上获得了 +9.2 的 F1  score和 +2.8 的 CIDEr 分数，在 QVHighlights 上获得了 +5.8 的 HIT@1 分数，在 Charades-STA 上获得了 +27.5 的 R@1 分数（IoU=0.5），有望成为<strong>长视频理解任务的多功能视频助手</strong>，满足用户的实际需求。</p>
<img src="/2024/10/13/timechat-a-time-sensitive-multimodal-large-language-model/image-20241013105855336.png" alt="image-20241013105855336" style="zoom:80%;">

<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p><strong>背景</strong></p>
<ul>
<li>从教育教程到故事电影，长格式的视频已经成为我们日常生活中的一个重要媒介。但筛选冗长的视频是相当耗时且无趣的工作。</li>
<li>人类的注意力总是被有意义的或突出的视觉片段所吸引，比如烹饪教程中的基本步骤或体育赛事中的精彩时刻。</li>
<li>一个智能的时间敏感视频助手，为用户分析长视频，包括<strong>时间定位、时间戳检测和关键时刻总结</strong>，是社会的长期需求。</li>
<li>大模型拥有强大的<strong>指令遵循</strong>能力，可以用于长视频理解任务，满足用户的现实需求。</li>
</ul>
<p><strong>现状</strong></p>
<ul>
<li>已经进行了一些初步探索以集成视觉编码器和LLM来实现基本的视频理解（说明字幕、问答）。</li>
<li>然而，现有的视频LLM（VidLLM）只能<strong>捕获短片段的全局视觉语义</strong>，而不能<strong>将重要的视频内容与准确的时间戳关联</strong>起来。<ul>
<li>例如，VideoLLaMA和VideoChat努力定位和描述未经修剪的视频中的有意义的事件，导致在Tab2中验证的准确性较低。</li>
<li>个人理解：上述两种模型侧重识别特定事件发生，本文模型侧重时间戳定位。<strong>在社区事件定位场景中需要取二者均衡。</strong></li>
</ul>
</li>
</ul>
<p>现有的VidLLM有两个问题：（1）刚性压缩将视频token转换为固定数字不适合长视频输入–它忽略了视频的持续时间，在处理长视频的大量帧时，导致严重的<strong>时空语义退化。</strong>（2）它们分别处理视频和时间戳信息，而不考虑显式的<strong>时间-视觉关联</strong>，因此无法准确地定位时间戳。</p>
<p><strong>本文贡献</strong></p>
<ul>
<li><p>提出TimeChat，一种时间敏感的多模态大语言模型，用于长视频理解和准确的时间定位。</p>
</li>
<li><p>为了处理长视频输入，提出了一种<strong>滑动视频Q-Former</strong>来适应视频特征提取和压缩过程中的自适应视频标记长度。视频Q-Former将滑窗内的帧压缩为视频token。移动窗口可以动态创建不同长度的视频token序列。它保留了<strong>长视频的重要视觉语义</strong>，并得到了更具表现力和可伸缩的视频表示。（<strong>捕获帧间时间信息</strong>）</p>
</li>
<li><p>为了增强<strong>视觉-时间戳的关联</strong>，提出了一个具有时间感知能力的<strong>帧编码器</strong>，它显式地将视觉上下文与每个帧的时间戳描述绑定起来。（<strong>绑定帧+时间戳信息</strong>）</p>
</li>
<li><p>为了提高TimeChat固有的时间戳定位能力，增强它的指令遵循能力，构建了一个新的指<strong>令调优数据集TimeIT</strong>，涉及不同的<strong>时间戳相关的用户指令</strong>。该数据集是由各种与时间戳相关的长视频数据集编译而来的，平均视频长度为<strong>190.8s</strong>。它由6个不同的任务、12个广泛使用的学术基准和总共125K实例组成。（<strong>增强时间-视觉关联能力</strong>）</p>
</li>
</ul>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>许多研究都在努力将llm与视频编码器集成起来，从而利用llm的强大理解和生成能力来进行视频任务。这些研究通常使用开源的llm，如Vicuna和LLaMA。它们的关键区别在于它们<strong>如何将视频编码为与llm兼容的视觉token</strong>。有代表性的工作，如VideoChat利用一个video transformer来编码视频features，随后实现一个Query Transformer（Q-Former）来压缩video tokens。VideoLLaMA首先使用vision transformer（ViT）和图像Q-Former对独立帧进行编码，然后使用视频Q-Former进行时间建模。然而，这些方法将视频token压缩到一个固定的数字，导致在处理长视频时视觉语义退化。相比之下，本文模型为视觉标记提供了可调的压缩率，增加了对不同视频长度的适应性。此外，模型明确地建立了一个帧级的视觉-时间戳关系，以提高时间定位能力。</p>
<p>视觉-语言指令微调需要使用人工指令生成高质量的数据，这可以分为两个技术分支。（1）合并可用的多模态基准数据集，将它们转化为指令格式；（2）利用GPT生成更多样化的对话式数据。</p>
<p>时间定位是视频理解任务的一个基本能力，特别是对于未修剪的长视频。有各种时间敏感的视频任务，包括视频时间定位、视频说明字幕、视频摘要、视频亮点检测、步长定位等。这些任务需要在视频语义和相应的时间戳之间进行显式的关联。以前的研究倾向于在专门的下游数据集上单独处理每个任务。尽管最近的工作对弥合一些任务进行了初步的尝试，但基于llm的通用范式仍在探索中。本文在语言建模上统一了一些时间敏感的视频任务，迈出了充分利用llm的通用能力的第一步。</p>
<h2 id="本文方法"><a href="#本文方法" class="headerlink" title="本文方法"></a>本文方法</h2><p>模型组件主要由三部分构成：1）时间感知帧编码器，2）视频滑窗Q-Former，3）LLM</p>
<p>给定一个输入视频，帧编码器首先<strong>独立地提取每个帧的视觉和时间戳特征</strong>。接下来，视频Q-Former建模<strong>滑动窗口内帧的时间关系</strong>，以生成视频token。最后，将这些视频token与可选的转录语音和用户指令连接起来，然后将这些指令输入LLM以生成响应。</p>
<img src="/2024/10/13/timechat-a-time-sensitive-multimodal-large-language-model/image-20241013153746315.png" alt="image-20241013153746315" style="zoom:80%;">

<h3 id="Timestamp-aware-Frame-Encoder"><a href="#Timestamp-aware-Frame-Encoder" class="headerlink" title="Timestamp-aware Frame Encoder"></a>Timestamp-aware Frame Encoder</h3><p>以前的研究通常将视觉语义的建模和输入帧各自的时间戳信息分开。该方法不能直接捕获视觉事件发生时的时间。一些方法为视觉标记了可学习的位置（时间）嵌入。然而，<strong>这只能使模型能够识别帧的顺序，在确定精确的时间矩时缺乏精度。</strong></p>
<p>为了解决这些问题，引入受 InstructBLIP启发的时间戳感知帧编码器。给定一个视频输入V，首先使用一个<strong>预训练好的图像编码器</strong>即ViT对 每一帧进行编码获得<strong>帧特征（n*n*d）</strong>，随后，一个图像Q-Former进一步压缩帧token。如图2所示，Q-Former以Dq维的可学习查询作为输入。这些查询通过交叉注意力与frame feature进行交互，并将初始查询更新到维度Dq中的Ni视觉标记。值得注意的是，在视觉标记抽取过程中，添加了帧的时间戳例如“This frame is sampled at 2s.”作为Q-Former融合视觉和时间戳信息的一个条件。</p>
<blockquote>
<p>借鉴了InstructBLIP的Q-Former。首先通过ViT-G/14 from EVA-CLIP来抽取图片特征（n*n*d），再通过Q-Former来对feature做提取，并通过输入文本“This frame is sampled at 2s.”，来把时间戳信息也混合进去。一帧图像出来的特征是Ni*D的，Ni就是query向量的个数。这里的Q-Former是用InstructBLIP权重初始化的。</p>
</blockquote>
<h3 id="Sliding-Video-Q-Former"><a href="#Sliding-Video-Q-Former" class="headerlink" title="Sliding Video Q-Former"></a>Sliding Video Q-Former</h3><p>对于T帧的视频输入，使用时间戳感知帧编码器后，获取到T*Ni*D的视觉token。此时各帧独立编码，没有建模<strong>帧间时间信息</strong>。为此，引入Q-Former滑窗，在时间维度上增强特征融合。设计了一个长度为Lw的滑动窗口，并在每个窗口内<strong>利用视频Q-Former从Lw帧中提取Nv长度的视频token</strong>。（<strong>滑窗Lw，步长S，Q-former查询向量数Nv</strong>）最终可以将输入的视频表示为（T /S）×Nv的视频token。（上图黄色部分）</p>
<p>由于视频的三维特性，有大量冗余时空信息，原始视觉token会非常长（原始帧中的所有patch），需要压缩信息以降低LLM计算量。<strong>之前的工作一般都设置固定的视觉token数Nv比如32，当输入帧数T很大时，会造成严重的视觉语义退化。</strong></p>
<p><strong>本文采用固定的步长来保证长视频不会被过度压缩，即最终送入LLM的tokens数量会根据视频的长度变化而变化。在送入LLM之前还会</strong>经过一个线性映射层来使tokens的特征维度符合LLM的输入特征维度需求。</p>
<p>将压缩率R定义为<strong>原始视觉标记的数量与最终视频标记的数量之比</strong>。则以前Video-LLaMA的压缩率是：<br>$$<br>R=（T<em>N_P）/N_V<br>$$<br>其中，<strong>Np为每一帧的patch数</strong>。这个比率随着输入帧数T的增加而增加，并会导致长视频的过度压缩。使用滑动视频Q-Former，压缩率R’变成一个常数值：<br>$$<br>R’=\frac{T</em>N_P}{(T/S)<em>N_V}=\frac{S</em>N_P}{N_V}<br>$$<br>为长视频保留更丰富的语义。通过调整步幅S，可以根据计算预算来控制视频token的最终数量。最后，利用线性层对视频标记的维数DQ进行变换，以匹配LLM嵌入空间的维数DLLM。</p>
<h3 id="Large-Language-Model"><a href="#Large-Language-Model" class="headerlink" title="Large Language Model"></a>Large Language Model</h3><p>将多种模态的输入连接起来，包括视频token Xv，文本查询向量Xq（包括可选的转录语音和用户指令），并将其输入一个大型语言模型，以生成合理和连贯的响应Xa。在这里，Xv、Xq和Xa具有相同的标记embedding维数DLLM。</p>
<p>VidLLM的训练通常采用<strong>两阶段训练框架。</strong>第一阶段使用大规模图像/视频-文本对进行预训练，以实现<strong>视觉-语言对齐</strong>。第二阶段使用指令数据对模型进行微调，以实现<strong>指令遵循</strong>。考虑到计算效率，本文重用了在第一阶段训练后现有开源模型的检查点（模型用的是LLaMA-2 (7B)），<strong>仅进行指令微调</strong>。采用LoRA微调的方式来对LLM模型进行微调。在训练过程中，利用<strong>语言建模损失</strong>生成长度为LT的目标答案Xa：</p>
<img src="/2024/10/13/timechat-a-time-sensitive-multimodal-large-language-model/image-20241014144753535.png" alt="image-20241014144753535" style="zoom:80%;">

<h3 id="数据集TimeIT"><a href="#数据集TimeIT" class="headerlink" title="数据集TimeIT"></a>数据集TimeIT</h3><p>为了提高TimeChat对时间敏感的人类指令的理解能力，提出TimeIT，一个涉及时间戳的以视频为中心的指令调优数据集。该数据集集成了广泛的与时间戳相关的视频数据集，并以长篇视频为特征。</p>
<p>TimeIT包含了6个与时间戳相关的视频任务，即：**(1) 视频说明字幕生成，(2) 视频时间定位，(3) 步骤定位和文字生成，(4) 视频摘要，(5) 视频亮点检测，以及 (6) 转录语音生成**。它还整合了来自不同领域的12个特定数据集。数据集适应了在现实世界应用中与AI助手交互时涉及视频时间戳的普遍用户请求。</p>
<p>数据集构建方式分两步：1）Instruction Writing  和  2) Answer Formatting。</p>
<p><strong>指令构造</strong>：先通过人工进行构造，然后利用GPT-4进行扩写来产生更多样化的表达，最后通过人工检查和refine来形成最终的版本。对于<strong>每个task会产生6个高质量的指令</strong>（instructions）。</p>
<p><strong>答案模板</strong>：根据编写的指令，我们进一步将任务输出重新表述为用户友好的自然语言响应范式。考虑到所涉及的视频数据集是人工收集的，TimeIT数据的整体质量得到了保证。</p>
<img src="/2024/10/13/timechat-a-time-sensitive-multimodal-large-language-model/image-20241014164810146.png" alt="image-20241014164810146" style="zoom:80%;">

<p>表1将TimeIT数据与现有的视频指令调优数据进行了比较，揭示了本文数据集在数据规模、任务多样性和视频长度方面的显著优势。附录C提供了每个任务对模型性能的贡献分析。总的来说，所有6个任务都是有益的。</p>
<img src="/2024/10/13/timechat-a-time-sensitive-multimodal-large-language-model/image-20241014165334936.png" alt="image-20241014165334936" style="zoom:80%;">

<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>以EVA-CLIP中的ViT-G/14作为图像编码器，以LLaMA-2（7B）作为语言基础模型。图像Q-Former的参数从InstructBLIP的检查点初始化，而视频Q-Former从Video-LLaMA的检查点初始化。在TimeIT和Valley上调整了3个epoch，使用32的批处理大小，使用一台8-V100（32G）机器。如图2所示，ViT和LLM的参数被冻结，而图像Q-Former、视频Q-Former和线性层的参数被调整。窗口大小Lw、步幅S和每个窗口的视频token Nv数为32。输入帧数为96。其他超参数请参阅附录D。</p>
<ul>
<li><p>模型在三个任务上进行零样本长视频理解评估，即字幕（说明性文字）生成，时间定位，和亮点检测。评估数据集包括YouCook2、 Charades-STA和 QVHighlights。评价指标的细节详见附录E。</p>
</li>
<li><p>用于解析LLM输出的启发式规则：由llm生成的输出可能包括口语化表达式，从而导致较大的响应变化。因此，作者设计了大量的启发式规则，以保证能够准确地从模型的响应中提取预测的答案，以计算最终的度量。</p>
</li>
<li><p>方法比较：将模型与两个基线对比。（1）<strong>多模态pipeline</strong>： VideoChat-Text，InstructBLIP+ChatGPT。这些pipeline将专用的视觉模型与GPT集成，首先将视觉语义转换为文本描述，然后利用ChatGPT来处理所有输入来解决目标任务。（2）<strong>端到端模型</strong>：Valley，VideoChat-Embed，Video-LLaMA with 7B LLMs。这些模型直接将视频作为输入，并以端到端的方式生成响应。</p>
</li>
</ul>
<h3 id="零样本性能"><a href="#零样本性能" class="headerlink" title="零样本性能"></a>零样本性能</h3><p>表2显示了TimeChat(7B)的零样本性能，它在所有任务中都优于以前的VidLLM(7B/13B)。</p>
<img src="/2024/10/13/timechat-a-time-sensitive-multimodal-large-language-model/image-20241014173705687.png" alt="image-20241014173705687" style="zoom:80%;">

<p><strong>密集字幕/说明文字生成</strong>：该任务在YouCook2上训练。模型需要在平均320秒的视频持续时间内，准确地识别出大约8个基本的烹饪步骤，并提供与视觉内容相匹配的忠实描述。烹饪的特殊性也提高了任务的复杂性，挑战了模型的通用性。现有的端到端VidLLM难以实现精确的moment定位，性能最好的VideoChat-Embed模型获得的低F1分数3.4就证明了这一点。<strong>这种momen定位的不精确显著影响了说明文字的评估，使得SODA_c和CIDEr指标都接近于零。</strong>与之相比，本文模型通过+1.0 SODA_c、+2.8 CIDEr和+9.2 F1评分获得了显著的SOTA。这表明TimeChat能够有效地处理长时间的视频，拥有精确的时间定位能力。此外，本文模型性能也显著超过了由ChatGPT提供的多模态pipeline（F1评分从8.4到12.6）。</p>
<p><strong>视频亮点检测</strong>：dense video captioning任务集中于在clip级别定位事件，而亮点检测任务需要在帧级别进行更细粒度的视频理解。对于输入视频，其目标是输出亮点帧的时间和突出分数。整体来看，本文模型在QVHhemict上达到了14.5 mAP和23.9 HIT@1，比之前的vidllm分别获得了+1.4和+5.8分。这突出了<strong>时间戳感知帧编码器在识别每个帧的显著语义方面</strong>的贡献。此外，该任务是TimeIT的held-out任务，表明了模型对新任务的泛化能力。<strong>多模态pipeline方法获得了更好的性能</strong>，作者推测，这是由于高亮检测的格式与他们的方法更兼容，鉴于模型接收到一系列的输入帧的联合的时间戳-视觉描述。这使得LLM能够逐帧进行评估，从而促进更准确的判断。</p>
<p><strong>时间定位</strong>：此任务旨在<strong>识别查询语句所描述的对应时间戳。</strong>TimeChat在Charades-STA数据集的“R@1，IoU=0.5”上达到32.2分，大大超过了之前的SOTA端到端VidLLM，即Valley（+27.5）。这表明，本文模型能够准确地定位给定文本查询的视频时刻。值得注意的是，TimeChat在时间定位任务上取得了最大的进步，作者认为该任务主要强调了<strong>长视频的时间定位能力</strong>，而这正是TimeChat的最佳优势。</p>
<h3 id="定性评估"><a href="#定性评估" class="headerlink" title="定性评估"></a>定性评估</h3><p>图4显示了在零样本设置下，TimeChat和其他VidLLM之间的定性比较。Video-LLaMA没有完全理解用户的指令，因为它只描述了步骤，而没有给出相应时间戳。VideoChat生成了符合请求格式的说明，但错位了所有步骤的时间。此外，VideoChat生成的描述包含一些幻觉。与之相比，TimeChat显示了改进的时间定位和总结功能。它成功地匹配了几乎所有提取的剪辑的视频内容。此外，幻觉的发生也明显减少了。然而，在增强模型生成的摘要的丰富性和细节方面仍有改进的空间。</p>
<img src="/2024/10/13/timechat-a-time-sensitive-multimodal-large-language-model/image-20241015171454792.png" alt="image-20241015171454792" style="zoom:80%;">

<p><strong>领域推广</strong>：在附录G中，展示了新领域的定性结果，如movie和egocentric videos，展示了TimeChat对新场景的泛化。这种泛化是一个实用的视频助手的一个关键特征，它代表了基于LLM的TimeChat和当前为特定的下游数据集量身定制的专用模型之间的根本区别。</p>
<h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h3><p>当<strong>删除滑动视频Q-Former</strong>时，最终视觉token的数量从96减少到32，导致信息压缩率为3倍。语义信息的减少导致了生成的描述和视频内容之间的对齐性的降低。具体来说，SODA_c度量减少了1.0，而CIDEr度量减少了2.8。此外，时间戳的准确性（以F1分数衡量）降低了3.0。在<strong>去除时间戳感知帧编码器</strong>的情况下，模型对时间基础描述的能力显著下降，F1分数下降了2.3。这些结果突出了模型中两个新模块的有效性。</p>
<img src="/2024/10/13/timechat-a-time-sensitive-multimodal-large-language-model/image-20241015173335537.png" alt="image-20241015173335537" style="zoom:80%;">

<h3 id="其他分析"><a href="#其他分析" class="headerlink" title="其他分析"></a>其他分析</h3><p>为了证明模型的性能提高不仅归因于新的TimeIT数据集，而且还归因于模型架构的改进，<strong>只使用YouCook2数据集进行微调和评估</strong>。在这个设置中，使用现有的开源检查点初始化模型（参见4.1）。对于所有的模型，应用LoRA 并微调Q-Former。Tab.4给出了结果，显示模型在所有指标上都始终优于以前的模型。</p>
<img src="/2024/10/13/timechat-a-time-sensitive-multimodal-large-language-model/image-20241015174655078.png" alt="image-20241015174655078" style="zoom:80%;">

<p>在图5中，作者检查了模型关于输入帧数的性能测量。如3.1.3中提到的，以前的模型如Video-LLaMA和VideoChat压缩了长视频的过多信息，当输入帧数从32增加到96时，性能表现最差。相比之下，本文模型使用滑动视频Q-Former解耦帧数T和压缩率R‘。随着帧数的增加，曲线表现出线性提高，显示出优越的可伸缩性。</p>
<img src="/2024/10/13/timechat-a-time-sensitive-multimodal-large-language-model/image-20241015175208335.png" alt="image-20241015175208335" style="zoom:80%;">



<h3 id="与专用模型的比较"><a href="#与专用模型的比较" class="headerlink" title="与专用模型的比较"></a>与专用模型的比较</h3><p>比较TimeChat与在三个任务上分别拥有最先进性能的专用模型。鉴于所有专用模型都在特定数据集上做了微调，作者对自己的模型也做了微调以进行公平比较。如表5所示，微调后TimeChat进一步提升了性能（+6.9 F1 score on YouCook2, +16.9 HIT@1 on</p>
<p>QVHighlights, and +16.4 R@1 (IoU=0.5) on Charades-STA）。专用模型的优越性来自特定任务的设计，例如Vid2Seq在YT-Temporal-1B上做预训练，这个数据集具有更多高质量的长视频；QD-DETR采用一种特殊的显著性token进行显著性预测，并引入了4个损失函数用于训练，而本文模型纯粹通过语言建模进行训练。此外，这些模型还使用了更多的微调步骤，以更好地适应下游数据集。</p>
<p>而作为一个通用模型，TimeChat在零样本场景、多任务和多领域设置中表现出很强的泛化能力，而这在这些专家模型中是不存在的。在每项任务上实现最先进的性能并不是本文的主要目标。</p>
<img src="/2024/10/13/timechat-a-time-sensitive-multimodal-large-language-model/image-20241015190311946.png" alt="image-20241015190311946" style="zoom:80%;">

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文提出了TimeChat，一个用于长视频理解的时间敏感的VidLLM。得益于新的时间感知帧编码器、滑动视频Q-Former和TimeIT上的指令调优，本文模型显示了强大的时间定位能力，这是在以前的VidLLM中所没有的。通过在冗长的视频中识别重大事件，确定事件的开始和结束时间，并生成简明的总结，TimeChat向智能视频助手迈出了关键的一步。在未来，将进一步取得架构上的进步，以提高视频语义密度，同时减少时空冗余。作者还将收集更多样化和高质量的指令调优数据，以扩大与时间相关的应用。</p>
<h2 id="项目配置"><a href="#项目配置" class="headerlink" title="==项目配置=="></a>==项目配置==</h2><h2 id="数据相关"><a href="#数据相关" class="headerlink" title="数据相关"></a>数据相关</h2><h3 id="video-annotations"><a href="#video-annotations" class="headerlink" title="video&amp;annotations"></a>video&amp;annotations</h3><ul>
<li>YouCook2: <a target="_blank" rel="noopener" href="http://youcook2.eecs.umich.edu/download">http://youcook2.eecs.umich.edu/download</a></li>
<li>Charades-STA: <a target="_blank" rel="noopener" href="https://github.com/jiyanggao/TALL#charades-sta-anno-download">https://github.com/jiyanggao/TALL#charades-sta-anno-download</a></li>
<li>QVHighlight: <a target="_blank" rel="noopener" href="https://github.com/jayleicn/moment_detr/blob/main/data/README.md">https://github.com/jayleicn/moment_detr/blob/main/data/README.md</a></li>
<li>ActivityNet Captions: <a target="_blank" rel="noopener" href="http://activity-net.org/download.html">http://activity-net.org/download.html</a></li>
<li>ViTT: <a target="_blank" rel="noopener" href="https://github.com/google-research-datasets/Video-Timeline-Tags-ViTT">https://github.com/google-research-datasets/Video-Timeline-Tags-ViTT</a></li>
<li>DiDeMo: <a target="_blank" rel="noopener" href="https://github.com/LisaAnne/LocalizingMoments?tab=readme-ov-file#dataset">https://github.com/LisaAnne/LocalizingMoments?tab=readme-ov-file#dataset</a></li>
<li>QuerYD: <a target="_blank" rel="noopener" href="https://www.robots.ox.ac.uk/~vgg/data/queryd/">https://www.robots.ox.ac.uk/~vgg/data/queryd/</a></li>
<li>HiREST: <a target="_blank" rel="noopener" href="https://github.com/j-min/HiREST">https://github.com/j-min/HiREST</a></li>
<li>TVSum: <a target="_blank" rel="noopener" href="https://github.com/yalesong/tvsum">https://github.com/yalesong/tvsum</a></li>
<li>SumMe: <a target="_blank" rel="noopener" href="http://classif.ai/dataset/ethz-cvl-video-summe/">http://classif.ai/dataset/ethz-cvl-video-summe/</a></li>
<li>COIN: <a target="_blank" rel="noopener" href="https://github.com/coin-dataset/annotations">https://github.com/coin-dataset/annotations</a></li>
<li>YT-Temporal: <a target="_blank" rel="noopener" href="https://rowanzellers.com/merlot/#data">https://rowanzellers.com/merlot/#data</a></li>
</ul>
<p>对视频进行预处理，降低 FPS 和维度，以减少存储空间并改进数据加载。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">ls <span class="token operator">-</span>U <span class="token operator">/</span>path<span class="token operator">/</span>to<span class="token operator">/</span>raw<span class="token operator">/</span>video <span class="token operator">&gt;&gt;</span> <span class="token operator">/</span>path<span class="token operator">/</span>to<span class="token operator">/</span>video_names<span class="token punctuation">.</span>txt

<span class="token comment"># for YouCook2</span>
python utils<span class="token operator">/</span>compress_video_data<span class="token punctuation">.</span>py \
<span class="token operator">-</span><span class="token operator">-</span>input_root<span class="token operator">=</span><span class="token operator">/</span>path<span class="token operator">/</span>to<span class="token operator">/</span>raw<span class="token operator">/</span>videos<span class="token operator">/</span> \
<span class="token operator">-</span><span class="token operator">-</span>output_root<span class="token operator">=</span>data<span class="token operator">/</span>YouCook2<span class="token operator">-</span>BB<span class="token operator">/</span>YouCook2_asr_denseCap<span class="token operator">/</span>youcook2_6fps_224<span class="token operator">/</span> \
<span class="token operator">-</span><span class="token operator">-</span>input_file_list_path<span class="token operator">=</span><span class="token operator">/</span>path<span class="token operator">/</span>to<span class="token operator">/</span>video_names<span class="token punctuation">.</span>txt \
<span class="token operator">-</span><span class="token operator">-</span>fps<span class="token operator">=</span><span class="token number">6</span> <span class="token operator">-</span><span class="token operator">-</span>size<span class="token operator">=</span><span class="token number">224</span> <span class="token operator">-</span><span class="token operator">-</span>file_type<span class="token operator">=</span>video <span class="token operator">-</span><span class="token operator">-</span>num_workers <span class="token number">24</span>

<span class="token comment"># for ActivityNet Captions</span>
python utils<span class="token operator">/</span>compress_video_data<span class="token punctuation">.</span>py \
<span class="token operator">-</span><span class="token operator">-</span>input_root<span class="token operator">=</span><span class="token operator">/</span>path<span class="token operator">/</span>to<span class="token operator">/</span>raw<span class="token operator">/</span>videos<span class="token operator">/</span> \
<span class="token operator">-</span><span class="token operator">-</span>output_root<span class="token operator">=</span>data<span class="token operator">/</span>Activitynet_Captions<span class="token operator">/</span>anet_6fps_224 \
<span class="token operator">-</span><span class="token operator">-</span>input_file_list_path<span class="token operator">=</span><span class="token operator">/</span>path<span class="token operator">/</span>to<span class="token operator">/</span>video_names<span class="token punctuation">.</span>txt \
<span class="token operator">-</span><span class="token operator">-</span>fps<span class="token operator">=</span><span class="token number">6</span> <span class="token operator">-</span><span class="token operator">-</span>size<span class="token operator">=</span><span class="token number">224</span> <span class="token operator">-</span><span class="token operator">-</span>file_type<span class="token operator">=</span>video <span class="token operator">-</span><span class="token operator">-</span>num_workers <span class="token number">24</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>HiREST_STEP&amp;VALLEY：run <code>python utils/process_valley.py</code>及<code>python utils/process_hirest.py</code></p>
<h3 id="Automatic-speech-transcription"><a href="#Automatic-speech-transcription" class="headerlink" title="Automatic speech transcription"></a>Automatic speech transcription</h3><p>从视频中提取音频：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">python utils<span class="token operator">/</span>extract_audio<span class="token punctuation">.</span>py <span class="token operator">-</span><span class="token operator">-</span><span class="token builtin">dir</span> <span class="token operator">/</span>home<span class="token operator">/</span>v<span class="token operator">-</span>shuhuairen<span class="token operator">/</span>mycontainer<span class="token operator">/</span>data<span class="token operator">/</span>DiDeMo<span class="token operator">/</span> <span class="token operator">-</span><span class="token operator">-</span>video_folder videos
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token punctuation">{</span><span class="token number">0.</span><span class="token number">.179</span><span class="token punctuation">}</span><span class="token punctuation">;</span> do python utils<span class="token operator">/</span>extract_audio<span class="token punctuation">.</span>py <span class="token operator">-</span><span class="token operator">-</span><span class="token builtin">dir</span> <span class="token operator">/</span>home<span class="token operator">/</span>v<span class="token operator">-</span>shuhuairen<span class="token operator">/</span>mycontainer<span class="token operator">/</span>data<span class="token operator">/</span>COIN<span class="token operator">/</span> <span class="token operator">-</span><span class="token operator">-</span>video_folder videos_ali<span class="token operator">/</span>$<span class="token punctuation">{</span>i<span class="token punctuation">}</span> <span class="token operator">-</span><span class="token operator">-</span>audio_folder audio_files<span class="token operator">/</span>$<span class="token punctuation">{</span>i<span class="token punctuation">}</span><span class="token punctuation">;</span> done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>使用whisper：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">python utils<span class="token operator">/</span>asr<span class="token operator">/</span>asr<span class="token punctuation">.</span>py <span class="token operator">-</span><span class="token operator">-</span>audio_dir audio_files <span class="token operator">-</span><span class="token operator">-</span><span class="token builtin">dir</span> <span class="token operator">/</span>home<span class="token operator">/</span>v<span class="token operator">-</span>shuhuairen<span class="token operator">/</span>mycontainer<span class="token operator">/</span>data<span class="token operator">/</span>DiDeMo<span class="token operator">/</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token punctuation">{</span><span class="token number">0.</span><span class="token number">.179</span><span class="token punctuation">}</span><span class="token punctuation">;</span> do python utils<span class="token operator">/</span>asr<span class="token operator">/</span>asr<span class="token punctuation">.</span>py <span class="token operator">-</span><span class="token operator">-</span><span class="token builtin">dir</span> <span class="token operator">/</span>home<span class="token operator">/</span>v<span class="token operator">-</span>shuhuairen<span class="token operator">/</span>mycontainer<span class="token operator">/</span>data<span class="token operator">/</span>COIN<span class="token operator">/</span> <span class="token operator">-</span><span class="token operator">-</span>audio_dir audio_files<span class="token operator">/</span>$<span class="token punctuation">{</span>i<span class="token punctuation">}</span><span class="token punctuation">;</span> done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>清除ASR结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">python utils<span class="token operator">/</span>clean_asr<span class="token punctuation">.</span>py <span class="token operator">-</span><span class="token operator">-</span><span class="token builtin">dir</span> <span class="token operator">/</span>home<span class="token operator">/</span>v<span class="token operator">-</span>shuhuairen<span class="token operator">/</span>mycontainer<span class="token operator">/</span>data<span class="token operator">/</span>DiDeMo<span class="token operator">/</span>whisper_outputs_with_time<span class="token operator">/</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>将ASR结果纳入instruction中：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">Incorporate the ASR results into the instructions<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h3 id="指令数据集"><a href="#指令数据集" class="headerlink" title="指令数据集"></a>指令数据集</h3><ul>
<li>TimeIT: <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/ShuhuaiRen/TimeIT">https://huggingface.co/datasets/ShuhuaiRen/TimeIT</a></li>
<li>Valley: <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/luoruipu1/Valley-Instruct-65k">https://huggingface.co/datasets/luoruipu1/Valley-Instruct-65k</a></li>
</ul>
<p>数据格式：</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>
  <span class="token property">"video"</span><span class="token operator">:</span> <span class="token string">"ActivityNet_asr_denseCap/anet_6fps_224/v_MinmayCk2Nk.mp4"</span><span class="token punctuation">,</span> 
  <span class="token property">"QA"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
      <span class="token property">"q"</span><span class="token operator">:</span> <span class="token string">"Capture and describe the activity events in the given video, specifying their respective time intervals, and outputting the time intervals in the 'start - end seconds format'."</span><span class="token punctuation">,</span> 
      <span class="token property">"a"</span><span class="token operator">:</span> <span class="token string">"0.0 - 9.1 seconds, We see a male gymnast prepare to use the pommel horse.  9.1 - 10.8 seconds, The man mounts the pommel horse and spins his legs around it.  29.9 - 35.2 seconds, The man does a handstand and dismounts.  35.7 - 38.6 seconds, The man takes a bow and starts walking away."</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">]</span><span class="token punctuation">,</span> 
  <span class="token property">"source"</span><span class="token operator">:</span> <span class="token string">"Activitynet_Captions"</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>字幕（说明文本）生成：</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span><span class="token property">"video"</span><span class="token operator">:</span> <span class="token string">"vitt/raw_videos/--L2yxB3CUg.mp4"</span><span class="token punctuation">,</span> <span class="token property">"QA"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token property">"q"</span><span class="token operator">:</span> <span class="token string">"Detect and report the start timestamp of activity events in the video, along with descriptions."</span><span class="token punctuation">,</span> <span class="token property">"a"</span><span class="token operator">:</span> <span class="token string">"2.7 seconds, Introduction.  8.5 seconds, Ingredients needed.  38.4 seconds, Measuring cornstarch.  54.1 seconds, Adding water.  62.0 seconds, Mixing mixture.  106.3 seconds, Explaining quicksand.  189.0 seconds, Closure."</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span>

<span class="token punctuation">{</span><span class="token property">"video"</span><span class="token operator">:</span> <span class="token string">"YouCook2_asr_denseCap/youcook2_6fps_224/GLd3aX16zBg.mp4"</span><span class="token punctuation">,</span> <span class="token property">"QA"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token property">"q"</span><span class="token operator">:</span> <span class="token string">"Localize a series of activity events in the video, output the start and end timestamp for each event, and describe each event with sentences. The output format of each predicted event should be like: start - end seconds, event description. An specific example is : 90.0 - 102.0 seconds, spread margarine on two slices of white bread in the video."</span><span class="token punctuation">,</span> <span class="token property">"a"</span><span class="token operator">:</span> <span class="token string">"90.0 - 102.0 seconds, spread margarine on two slices of white bread.  114.0 - 127.0 seconds, place a slice of cheese on the bread.  132.0 - 138.0 seconds, place the bread slices on top of each other and place in a hot pan.  139.0 - 145.0 seconds, flip the sandwich over and press down.  173.0 - 174.0 seconds, cut the sandwich in half diagonally. "</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>步骤定位：</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span><span class="token property">"video"</span><span class="token operator">:</span> <span class="token string">"COIN/videos_ali/116/NLy71UrHElw.mp4"</span><span class="token punctuation">,</span> <span class="token property">"QA"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token property">"q"</span><span class="token operator">:</span> <span class="token string">"Identify and mark the video segments corresponding to a series of actions or steps, specifying the timestamps and describing the steps."</span><span class="token punctuation">,</span> <span class="token property">"a"</span><span class="token operator">:</span> <span class="token string">"21.0 - 22.0 seconds, begin to run up.  23.0 - 24.0 seconds, begin to jump up.  25.0 - 26.0 seconds, fall to the ground."</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span>

<span class="token punctuation">{</span><span class="token property">"video"</span><span class="token operator">:</span> <span class="token string">"HiREST/clips/_7urSjT6sQY_35_79.mp4"</span><span class="token punctuation">,</span> <span class="token property">"QA"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token property">"q"</span><span class="token operator">:</span> <span class="token string">"Find, identify, and determine the temporal boundaries of a series of distinct actions or steps occurring throughout the video. For each action, output the corresponding start and end timestamps, accompanied by a concise description."</span><span class="token punctuation">,</span> <span class="token property">"a"</span><span class="token operator">:</span> <span class="token string">"0.0 - 13.0 seconds, clean out the face.  13.0 - 25.0 seconds, apply tissue using water on face.  25.0 - 37.0 seconds, apply it for full face.  37.0 - 42.0 seconds, put it under the neck .  42.0 - 44.0 seconds, dry it out."</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>基于查询文本的视频切片定位：</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>
    <span class="token property">"0"</span><span class="token operator">:</span> <span class="token string">"Localize the visual content described by the given textual query &lt;query_placeholder&gt; in the video, and output the start and end timestamps in seconds."</span><span class="token punctuation">,</span>
    <span class="token property">"1"</span><span class="token operator">:</span> <span class="token string">"Detect and report the start and end timestamps of the video segment that semantically matches the given textual query &lt;query_placeholder&gt;."</span><span class="token punctuation">,</span>
    <span class="token property">"2"</span><span class="token operator">:</span> <span class="token string">"Give you a textual query: &lt;query_placeholder&gt; When does the described content occur in the video? Please return the timestamp in seconds."</span><span class="token punctuation">,</span>
    <span class="token property">"3"</span><span class="token operator">:</span> <span class="token string">"Locate and describe the visual content mentioned in the text query &lt;query_placeholder&gt; within the video, including timestamps."</span><span class="token punctuation">,</span>
    <span class="token property">"4"</span><span class="token operator">:</span> <span class="token string">"The given natural language query &lt;query_placeholder&gt; is semantically  aligned with a video moment, please give the start time and end time of the video moment."</span><span class="token punctuation">,</span>
    <span class="token property">"5"</span><span class="token operator">:</span> <span class="token string">"Find the video segment that corresponds to the given textual query &lt;query_placeholder&gt; and determine its start and end seconds."</span>
<span class="token punctuation">}</span>

<span class="token punctuation">{</span><span class="token property">"video"</span><span class="token operator">:</span> <span class="token string">"Charades/videos/AO8RW.mp4"</span><span class="token punctuation">,</span> <span class="token property">"QA"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token property">"q"</span><span class="token operator">:</span> <span class="token string">"The given natural language query 'a person is putting a book on a shelf' is semantically  aligned with a video moment, please give the start time and end time of the video moment."</span><span class="token punctuation">,</span> <span class="token property">"a"</span><span class="token operator">:</span> <span class="token string">"The given query happens in 0.0 - 6.9 seconds."</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>语音转录：</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>
    <span class="token property">"0"</span><span class="token operator">:</span> <span class="token string">"After watching the video from the YTTemporal dataset, transcribe the spoken content into text and document the start and end time for each segment. The format should be: 'start time - end time, transcribed speech'."</span><span class="token punctuation">,</span>
    <span class="token property">"1"</span><span class="token operator">:</span> <span class="token string">"Observe the video thoroughly and transcribe the speech in a maximum of 20 segments. Make sure to include the starting and ending times for each segment in the following format: 'start time - end time, transcribed speech'."</span><span class="token punctuation">,</span>
    <span class="token property">"2"</span><span class="token operator">:</span> <span class="token string">"Watch the provided video and transcribe the audio content. For each transcribed speech segment, note down its duration in the format: 'start time - end time, transcribed speech'."</span><span class="token punctuation">,</span>
    <span class="token property">"3"</span><span class="token operator">:</span> <span class="token string">"Review the video from the YTTemporal dataset. Identify segments where speech occurs and transcribe those into text. Record the start and end time for each segment in this format: 'start time - end time, transcribed speech'."</span><span class="token punctuation">,</span>
    <span class="token property">"4"</span><span class="token operator">:</span> <span class="token string">"Transcribe the spoken words in the video and note down the timestamps for each segment. Your output should look like this: 'start time - end time, transcribed speech'."</span><span class="token punctuation">,</span>
    <span class="token property">"5"</span><span class="token operator">:</span> <span class="token string">"Watch the video, transcribe the speech, and indicate when each segment starts and ends. Follow this format: 'start time - end time, transcribed speech'."</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>视频亮点检测：</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>
    <span class="token property">"0"</span><span class="token operator">:</span> <span class="token string">"You are given a video from the QVHighlights dataset. Please find the highlight contents in the video described by a sentence query, determining the highlight timestamps and its saliency score on a scale from 1 to 5. The output format should be like: 'The highlight timestamps are in the 82, 84, 86, 88, 90, 92, 94, 96, 98, 100 seconds. Their saliency scores are 1.3, 1.7, 1.7, 1.7, 1.7, 1.3, 1.7, 2.3, 2.3, 2.3'. Now I will give you the sentence query: &lt;query_placeholder&gt;. Please return the query-based highlight timestamps and salient scores."</span><span class="token punctuation">,</span>
    <span class="token property">"1"</span><span class="token operator">:</span> <span class="token string">"Watch the provided video and mark out the scenes that stand out based on the description: &lt;query_placeholder&gt;. Document the timestamps of these highlights and evaluate their saliency scores."</span><span class="token punctuation">,</span>
    <span class="token property">"2"</span><span class="token operator">:</span> <span class="token string">"Perform a thorough review of the video content, extracting key highlight moments that align with &lt;query_placeholder&gt;. It is essential to record the times of these moments and assign a distinct saliency value to each."</span><span class="token punctuation">,</span>
    <span class="token property">"3"</span><span class="token operator">:</span> <span class="token string">"Examine the video and, in accordance with query &lt;query_placeholder&gt;, highlight the standout moments. You're required to provide the exact timing alongside a saliency rating for each segment."</span><span class="token punctuation">,</span>
    <span class="token property">"4"</span><span class="token operator">:</span> <span class="token string">"In the video presented, seek moments that are a perfect match with &lt;query_placeholder&gt;. It's vital to notate their timestamps and to score each based on their level of saliency."</span><span class="token punctuation">,</span>
    <span class="token property">"5"</span><span class="token operator">:</span> <span class="token string">"Go through the video content, and upon identifying highlight moments that resonate with &lt;query_placeholder&gt;, list their timestamps. Subsequently, provide a saliency score for each identified highlight."</span>
<span class="token punctuation">}</span>

<span class="token punctuation">{</span><span class="token property">"video"</span><span class="token operator">:</span> <span class="token string">"QVhighlights/videos/train/v_j7rJstUseKg_360.0_510.0.mp4"</span><span class="token punctuation">,</span> <span class="token property">"QA"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token property">"q"</span><span class="token operator">:</span> <span class="token string">"Watch the provided video and mark out the scenes that stand out based on the description: 'some military patriots takes us through their safety procedures and measures.'. Document the timestamps of these highlights and evaluate their saliency scores."</span><span class="token punctuation">,</span> <span class="token property">"a"</span><span class="token operator">:</span> <span class="token string">"There are 29 highlight moments in the 72.0, 74.0, 76.0, 78.0, 80.0, 84.0, 86.0, 88.0, 90.0, 92.0, 96.0, 98.0, 100.0, 102.0, 104.0, 108.0, 110.0, 112.0, 114.0, 116.0, 120.0, 122.0, 124.0, 126.0, 128.0, 136.0, 138.0, 140.0, 144.0 second. Their saliency scores are 3.0, 2.7, 3.7, 2.3, 2.7, 2.7, 2.7, 2.7, 2.3, 2.7, 3.7, 3.3, 3.3, 3.7, 3.0, 2.3, 3.0, 2.3, 2.3, 2.3, 2.3, 3.0, 3.7, 2.7, 2.3, 2.3, 2.3, 2.3, 2.3."</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>视频摘要：</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>
    <span class="token property">"0"</span><span class="token operator">:</span> <span class="token string">"From the &lt;dataset_placeholder&gt; dataset, generate a summarized version of the video, focusing on extracting key frames that best represent the overall narrative. The output should be a list of timestamps in seconds and their corresponding salient scores"</span><span class="token punctuation">,</span>
    <span class="token property">"1"</span><span class="token operator">:</span> <span class="token string">"You are given a video from the &lt;dataset_placeholder&gt; dataset. Please find the highlight contents in the video, determining the highlight timestamps and its saliency score on a scale from 1 to 5. The output format should be like: 'The highlight timestamps are in the 82, 84, 86, 88, 90, 92, 94, 96, 98, 100 second. Their saliency scores are 1.3, 1.7, 1.7, 1.7, 1.7, 1.3, 1.7, 2.3, 2.3, 2.3'. "</span><span class="token punctuation">,</span>
    <span class="token property">"2"</span><span class="token operator">:</span> <span class="token string">"Identify and extract the most emotionally impactful moments from the video provided by &lt;dataset_placeholder&gt; dataset, rating their intensity on a scale from 1 to 5."</span><span class="token punctuation">,</span>
    <span class="token property">"3"</span><span class="token operator">:</span> <span class="token string">"Watch the provided video from the &lt;dataset_placeholder&gt; dataset and mark out the timestamps with stand-out visual content. Document the timestamps of these highlights and evaluate their saliency scores."</span><span class="token punctuation">,</span>
    <span class="token property">"4"</span><span class="token operator">:</span> <span class="token string">"In the video presented from &lt;dataset_placeholder&gt; dataset, seek moments that could serve as an executive summary for a busy stakeholder. It's vital to notate their timestamps and to score each based on their level of saliency."</span><span class="token punctuation">,</span>
    <span class="token property">"5"</span><span class="token operator">:</span> <span class="token string">"Go through the video content from &lt;dataset_placeholder&gt; dataset, and upon identifying highlight moments, list their timestamps. Subsequently, provide a saliency score for each identified highlight."</span>
<span class="token punctuation">}</span>

<span class="token punctuation">{</span><span class="token property">"video"</span><span class="token operator">:</span> <span class="token string">"SumMe/videos/Air_Force_One.mp4"</span><span class="token punctuation">,</span> <span class="token property">"QA"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token property">"q"</span><span class="token operator">:</span> <span class="token string">"From the summe dataset, generate a summarized version of the video, focusing on extracting key frames that best represent the overall narrative. The output should be a list of timestamps in seconds and their corresponding salient scores"</span><span class="token punctuation">,</span> <span class="token property">"a"</span><span class="token operator">:</span> <span class="token string">"The highlight timestamps are in the 57.0, 62.4, 68.4, 73.2, 78.0, 79.2, 80.4, 84.6, 155.4, 156.6, 157.8, 159.6, 160.8, 161.4, 162.6, 164.4, 165.6, 167.4, 169.2, 171.0, 172.2 seconds. Their saliency scores are 2.1, 1.8, 2.1, 2.9, 4.2, 3.9, 3.7, 3.1, 1.8, 2.3, 2.9, 3.1, 3.4, 3.4, 3.7, 3.1, 3.1, 2.6, 2.1, 2.1, 1.8."</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="评估数据集"><a href="#评估数据集" class="headerlink" title="评估数据集"></a>评估数据集</h3><p>数据格式–对于字幕（说明文本）生成：</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>
    <span class="token property">"annotations"</span><span class="token operator">:</span> 
    <span class="token punctuation">[</span>
        <span class="token punctuation">{</span>
            <span class="token property">"image_id"</span><span class="token operator">:</span> <span class="token string">"3MSZA.mp4"</span><span class="token punctuation">,</span>
            <span class="token property">"duration"</span><span class="token operator">:</span> <span class="token number">206.86</span><span class="token punctuation">,</span>
            <span class="token property">"segments"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">47</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">67</span><span class="token punctuation">,</span> <span class="token number">89</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">91</span><span class="token punctuation">,</span> <span class="token number">98</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">99</span><span class="token punctuation">,</span> <span class="token number">137</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">153</span><span class="token punctuation">,</span> <span class="token number">162</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">163</span><span class="token punctuation">,</span> <span class="token number">185</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token property">"caption"</span><span class="token operator">:</span> <span class="token string">"pick the ends off the verdalago. ..."</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
        ...
        eg<span class="token operator">:</span><span class="token punctuation">{</span><span class="token property">"image_id"</span><span class="token operator">:</span> <span class="token string">"v_QOlSCBRmfWY.mp4"</span><span class="token punctuation">,</span> <span class="token property">"caption"</span><span class="token operator">:</span> <span class="token string">"A young woman is seen standing in a room and leads into her dancing. The girl dances around the room while the camera captures her movements. She continues dancing around the room and ends by laying on the floor."</span><span class="token punctuation">,</span> <span class="token property">"segments"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.83</span><span class="token punctuation">,</span> <span class="token number">19.86</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">17.37</span><span class="token punctuation">,</span> <span class="token number">60.81</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">56.26</span><span class="token punctuation">,</span> <span class="token number">79.42</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token property">"duration"</span><span class="token operator">:</span> <span class="token number">82.73</span><span class="token punctuation">,</span> <span class="token property">"id"</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">}</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">}</span>  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>数据格式–对于视频切片定位：</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>
    <span class="token property">"annotations"</span><span class="token operator">:</span> 
    <span class="token punctuation">[</span>
      <span class="token punctuation">{</span>   
            <span class="token property">"image_id"</span><span class="token operator">:</span> <span class="token string">"3MSZA.mp4"</span><span class="token punctuation">,</span> 
            <span class="token property">"caption"</span><span class="token operator">:</span> <span class="token string">"person turn a light on."</span><span class="token punctuation">,</span>
            <span class="token property">"timestamp"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token number">24.3</span><span class="token punctuation">,</span> <span class="token number">30.4</span><span class="token punctuation">]</span>
      <span class="token punctuation">}</span><span class="token punctuation">,</span>
      ...
      eg<span class="token operator">:</span><span class="token punctuation">{</span><span class="token property">"image_id"</span><span class="token operator">:</span> <span class="token string">"AO8RW.mp4"</span><span class="token punctuation">,</span> <span class="token property">"caption"</span><span class="token operator">:</span> <span class="token string">"a person is putting a book on a shelf."</span><span class="token punctuation">,</span> <span class="token property">"timestamp"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">6.9</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token property">"id"</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token property">"image_id"</span><span class="token operator">:</span> <span class="token string">"Y6R7T.mp4"</span><span class="token punctuation">,</span> <span class="token property">"caption"</span><span class="token operator">:</span> <span class="token string">"person begins to play on a phone."</span><span class="token punctuation">,</span> <span class="token property">"timestamp"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token number">20.8</span><span class="token punctuation">,</span> <span class="token number">30.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token property">"id"</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">}</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="模型相关"><a href="#模型相关" class="headerlink" title="模型相关"></a>模型相关</h2><p>以下checkpoint存储可学习的参数（位置嵌入层、时间感知帧编码器、滑动视频Q-Former、线性投影层和lora）</p>
<table>
<thead>
<tr>
<th>Checkpoint</th>
<th>LLM backbone</th>
<th>Link</th>
<th>Note</th>
</tr>
</thead>
<tbody><tr>
<td>TimeChat-2-7B-Finetuned</td>
<td>LLaMA-2 7B</td>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/ShuhuaiRen/TimeChat-7b/blob/main/timechat_7b.pth">link</a></td>
<td>Fine-tuned on the instruction-tuning data from <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/ShuhuaiRen/TimeIT">TimeIT-104K</a> (asr version) and <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/ShuhuaiRen/TimeIT/blob/main/data/valley/Valley_instruct_73k.json">Valley-73K</a> (previous version of current Valley-65K)</td>
</tr>
</tbody></table>
<h3 id="ViT-g-from-EVA-CLIP"><a href="#ViT-g-from-EVA-CLIP" class="headerlink" title="ViT-g from EVA-CLIP"></a>ViT-g from EVA-CLIP</h3><p><strong>预训练的图编码器</strong><code>wget https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/eva_vit_g.pth</code></p>
<p>《EVA-CLIP: Improved Training Techniques for CLIP at Scale》</p>
<p>EVA-CLIP是一系列改进的CLIP模型，通过结合新表示学习、优化和增强技术，降低训练成本，提高训练效率和零次学习性能。最大模型EVA-02-CLIP-E/14+在ImageNet-1K上实现82.0%的零次学习准确率，而较小的EVA-02-CLIP-L/14+模型也有80.4%的准确率，但参数和样本量更少。</p>
<h4 id="CLIP"><a href="#CLIP" class="headerlink" title="CLIP"></a>CLIP</h4><blockquote>
<p>CLIP（Contrastive Language-Image Pre-Training）模型是一种<strong>多模态预训练神经网络</strong>，由OpenAI在2021年发布，是从自然语言监督中学习的一种有效且可扩展的方法。CLIP在预训练期间学习执行广泛的任务，包括OCR，地理定位，动作识别。</p>
<p>该模型的核心思想是<strong>使用大量图像和文本的配对数据进行预训练，以学习图像和文本之间的对齐关系。</strong>CLIP模型有两个模态，一个是<strong>文本模态</strong>，一个是<strong>视觉模态</strong>，包括两个主要部分：</p>
<p>i. Text Encoder：用于将文本转换为低维向量表示-Embeding。</p>
<p>ii. Image Encoder：用于将图像转换为类似的向量表示-Embedding。</p>
<p>在预测阶段，CLIP模型通过计算文本和图像向量之间的<strong>余弦相似度</strong>来生成预测。这种模型特别适用于<strong>零样本学习</strong>任务，即模型不需要看到新的图像或文本的训练示例就能进行预测。CLIP模型在多个领域表现出色，如图像文本检索、图文生成等。</p>
</blockquote>
<p>CLIP的的核心思想是通过<strong>海量</strong>的<strong>弱监督</strong>文本对通过<strong>对比学习</strong>，将图片和文本通过各自的<strong>预训练</strong>模型获得的编码向量在向量空间上<strong>对齐</strong>。<strong>不足：clip可以实现图文匹配，但不具有文本生成能力。</strong></p>
<img src="/2024/10/13/timechat-a-time-sensitive-multimodal-large-language-model/image-20241021110850956.png" alt="image-20241021110850956" style="zoom:80%;">

<p><strong>流程解读：</strong></p>
<ul>
<li><p>主要分为两个分支，一个图像encoder、一个文本encoder。<strong>图像分支是ResNet50或是VIT，文本分支和bert的结构类似，采用12层transformer</strong>，8个head，词表大小是49,152。最大sequence长度76。并且添加[SOS]和[EOS]标识token，并且[EOS]对应位置的特征就是最后的文本特征。</p>
</li>
<li><p>通过encoder特征提取以后，图像分支获得的特征是[batch, embed_dim]，文本分支获得的特征是[batch, embed_dim]。其中对应位置上的embedding是匹配的，来自同一组图像-文本对。<strong>对于优化任务，一种自然的想法，就是拉近同一对embedding之间的距离，推远不同对的embedding之间的距离。作者采用了InfoNCE loss。</strong>特征间进行两两计算，[batch, embed_dim] * [embed_dim, batch] = [batch, batch]，获取到batch*batch对样本之间的距离。</p>
<ul>
<li>这里对提取的文本特征和图像特征进行对比学习。对于一个包含N个文本-图像对的训练batch，将N个文本特征和N个图像特征两两组合，CLIP模型会预测出N^2个可能的文本-图像对的相似度，这里的相似度直接<strong>计算文本特征和图像特征的余弦相似性（cosine similarity）</strong>，即上图所示的矩阵。这里共有N个正样本，即真正属于一对的文本和图像（矩阵中的对角线元素），而剩余的N^2−N个文本-图像对为负样本，那么CLIP的训练目标就是最大化N个正样本的相似度，同时最小化N^2−N个负样本的相似度</li>
</ul>
</li>
<li><p>作者采用的对称loss。针对每一个image特征，将text batch中对应的那个text特征拉近，而推远其余未配对的text特征。同样，针对每一个text特征，将image batch中对应的那个image特征拉进，而推远其余未配对的image特征。<strong>站在loss对称的角度，模型优化中图像、文本的地位是相同的。因此，论文标题想表达利用文本监督去学习视觉特征，但是这未尝不是利用图像监督去学习文本特征。</strong>对比纯图像领域的自监督学习方法，其实和上面的方法是类似的，只是将文本分支替换为图像分支，两个分支同时输入同一张图的图像增强版本。</p>
</li>
<li><p>CLIP之所以经典，在于其出色的zero-shot能力。</p>
</li>
<li><p>上面我们介绍了CLIP的原理，可以看到训练后的CLIP其实是两个模型，除了视觉模型外还有一个文本模型，那么如何对预训练好的视觉模型进行迁移呢？<strong>与CV中常用的先预训练然后微调不同，CLIP可以直接实现zero-shot的图像分类，即不需要任何训练数据，就能在某个具体下游任务上实现分类，</strong>这也是CLIP亮点和强大之处。用CLIP实现zero-shot分类很简单，只需要简单的两步：</p>
</li>
</ul>
<ol>
<li>根据任务的分类标签构建每个类别的描述文本：<code>A photo of {label}</code>，然后将这些文本送入Text Encoder得到对应的文本特征，如果类别数目为N，那么将得到N个文本特征；</li>
<li>将要预测的图像送入Image Encoder得到图像特征，然后与N个文本特征计算缩放的余弦相似度（和训练过程一致），然后选择相似度最大的文本对应的类别作为图像分类预测结果，进一步地，可以将这些相似度看成logits，送入softmax后可以到每个类别的预测概率。</li>
</ol>
<ul>
<li><p><strong>流程解读：</strong></p>
</li>
<li><p>输入单张图像，通过Image Encoder提取对应的embedding。然后设定想要查找的标签集合，如”plane”, “car”, “dog”等。然后<strong>利用prompt语句 “a photo of a {}”，分别构成”a photo of a plane”, “a photo of a dog”等文本</strong>。<strong>然后利用Text Encoder分别提取对应的文本embedding。最后利用文本embedding和图像embedding计算对应的相似度，然后对相似度进行softmax，获得最大的概率值，即为对应的label。</strong>实验结果显示CLIP在zero-shot上面具有较高的精度，表明CLIP的泛化性很好。</p>
</li>
<li><p>这里需要注意两点：<strong>一是标签集合是自行定义的</strong>，如果我们定义为imagenet的类别标签，那么这时zero-shot就相当于完成imagenet分类任务；<strong>二是prompt语句的改变，可能会影响最后的分类效果</strong>，论文指出不同的数据集，有自己最优的prompt语句，并且多个prompt语句的结果取平均，可能最终的效果更好。</p>
</li>
</ul>
<h4 id="VIT"><a href="#VIT" class="headerlink" title="VIT"></a>VIT</h4><p>ViT（vision transformer）是Google在2020年提出的<strong>直接将transformer应用在图像分类的模型</strong>，后面很多的工作都是基于ViT进行改进的。ViT的思路很简单：</p>
<ul>
<li><p>直接把图像分成固定大小的patchs，然后通过线性变换得到<strong>patch embedding</strong>，这就类比NLP的words和word embedding</p>
</li>
<li><p>由于transformer的输入就是a sequence of token embeddings，所以将图像的patch embeddings送入transformer后就能够进行特征提取从而分类了。</p>
</li>
<li><p>ViT模型原理如下图所示，其实<strong>ViT模型只是用了transformer的Encoder来提取特征</strong>（原始的transformer还有decoder部分，用于实现sequence to sequence，比如机器翻译）。</p>
<img src="/2024/10/13/timechat-a-time-sensitive-multimodal-large-language-model/image-20241021112226815.png" alt="image-20241021112226815" style="zoom:80%;"></li>
</ul>
<h3 id="InstructBLIP-Q-Former"><a href="#InstructBLIP-Q-Former" class="headerlink" title="InstructBLIP Q-Former"></a>InstructBLIP Q-Former</h3><p>图片Q-Former <code>wget https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/InstructBLIP/instruct_blip_vicuna7b_trimmed.pth</code></p>
<p><strong>BLIP-2：使用冻结图像编码器和大型语言模型进行语言图像预训练</strong></p>
<blockquote>
<p>InstructBLIP 是 BLIP 作者团队在多模态领域的又一续作。现代的大语言模型在无监督预训练之后会经过进一步的指令微调 (Instruction-Tuning) 过程，但是这种范式在视觉语言模型上面探索得还比较少。InstructBLIP 这个工作介绍了<strong>如何把指令微调的范式做在 BLIP-2 模型上面</strong>。用指令微调方法的时候会额外有一条 instruction，如何<strong>借助这个 instruction 提取更有用的视觉特征</strong>是本文的亮点之一。InstructBLIP 的架构和 BLIP-2 相似，<strong>从预训练好的 BLIP-2 模型初始化，由图像编码器、LLM 和 Q-Former 组成。</strong>在指令微调期间<strong>只训练 Q-Former</strong>，冻结图像编码器和 LLM 的参数。作者将26个数据集转化成指令微调的格式，把它们分成13个 held-in 数据集用于指令微调，和13个 held-out 数据集用于 Zero-Shot 能力的评估。</p>
</blockquote>
<p>Q-Former是一种轻量级transformer结构，采用一组可学习的查询向量来提取和压缩视觉特征。</p>
<p>Q-Former 的输入还包括<strong>可学习的 Queries (BLIP-2 的做法)</strong> 和 <strong>Instruction</strong>。Q-Former 的内部结构如图3黄色部分所示，其中可学习的 Queries 通过 Self-Attention 和 Instruction 交互，可学习的 Queries 通过 Cross-Attention 和输入图片的特征交互，鼓励提取与任务相关的图像特征。</p>
<p>Q-Former 的输出通过一个 FC 层送入 LLM，Q-Former 的预训练过程遵循 BLIP-2 的两步：1) 不用 LLM，固定视觉编码器的参数预训练 Q-Former 的参数，训练目标是视觉语言建模。2) 固定 LLM 的参数，训练 Q-Former 的参数，训练目标是文本生成。</p>
<img src="/2024/10/13/timechat-a-time-sensitive-multimodal-large-language-model/image-20241022105848543.png" alt="image-20241022105848543" style="zoom:80%;">



<h3 id="LLaMA-2-7B-Video-Q-Former-of-Video-LLaMA"><a href="#LLaMA-2-7B-Video-Q-Former-of-Video-LLaMA" class="headerlink" title="LLaMA-2-7B &amp; Video Q-Former of Video-LLaMA"></a>LLaMA-2-7B &amp; Video Q-Former of Video-LLaMA</h3><p>预训练的LLM及对应的视频编码器</p>
<p>Video-LLaMA：指令微调的用于视频理解的视听语言模型</p>
<p><code>git lfs install git clone https://huggingface.co/DAMO-NLP-SG/Video-LLaMA-2-7B-Finetuned</code></p>
<h2 id="代码相关"><a href="#代码相关" class="headerlink" title="代码相关"></a>代码相关</h2><h3 id="Q-Former"><a href="#Q-Former" class="headerlink" title="Q-Former"></a>Q-Former</h3><ul>
<li>Q-Former的实现基于BERT（BertModel），并包含自注意力和交叉注意力层。</li>
<li>交叉注意力机制在模型的不同层插入，用于处理视觉和语言特征之间的结合，这使得模型可以在多模态任务中有效地执行跨模态对齐。</li>
<li>模型包括输入embedding、编码器层和输出层，整体架构与BERT类似，但针对多模态任务进行了适配。</li>
</ul>
<img src="/2024/10/13/timechat-a-time-sensitive-multimodal-large-language-model/image-20241022195840325.png" alt="image-20241022195840325" style="zoom:80%;">

<p>Q-Former由两个transfomer子模块组成，左边为(learnable) query encoder，右边为text encoder &amp; decoder。记视觉模型的image encoder的输出为I。左边网络的(learnable) query为Q，右边网络的输入text为T。注意Q是一个向量集，非单个向量。它可以视为Q-Former的参数。</p>
<ul>
<li>左边的transformer和视觉模型image encoder交互，提取视觉表征，右边的transformer同时作为text encoder和decoder。</li>
<li>左边的query encoder和右边的text encoder共享self-attention layer。</li>
<li>通过self attention layer，实现Q向量之间的交互。</li>
<li>通过cross attention layer，实现Q向量和I的交互。</li>
<li>Q和T之间的交互，也是通过共享的self attention layer实现的，不过根据训练目标的不同，通过不同的attention mask来实现不同的交互。</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">
<span class="token keyword">class</span> <span class="token class-name">BertSelfAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> config<span class="token punctuation">,</span> is_cross_attention<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>config <span class="token operator">=</span> config
        <span class="token keyword">if</span> config<span class="token punctuation">.</span>hidden_size <span class="token operator">%</span> config<span class="token punctuation">.</span>num_attention_heads <span class="token operator">!=</span> <span class="token number">0</span> <span class="token keyword">and</span> <span class="token keyword">not</span> <span class="token builtin">hasattr</span><span class="token punctuation">(</span>
            config<span class="token punctuation">,</span> <span class="token string">"embedding_size"</span>
        <span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span>
                <span class="token string">"The hidden size (%d) is not a multiple of the number of attention "</span>
                <span class="token string">"heads (%d)"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>config<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> config<span class="token punctuation">.</span>num_attention_heads<span class="token punctuation">)</span>
            <span class="token punctuation">)</span>

        <span class="token comment"># 初始化--设置注意力头的数量和每个头的维度</span>
        self<span class="token punctuation">.</span>num_attention_heads <span class="token operator">=</span> config<span class="token punctuation">.</span>num_attention_heads
        self<span class="token punctuation">.</span>attention_head_size <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>hidden_size <span class="token operator">/</span> config<span class="token punctuation">.</span>num_attention_heads<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>all_head_size <span class="token operator">=</span> self<span class="token punctuation">.</span>num_attention_heads <span class="token operator">*</span> self<span class="token punctuation">.</span>attention_head_size

        <span class="token comment"># 初始化查询query、键和值的线性变换</span>
        self<span class="token punctuation">.</span>query <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>config<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>all_head_size<span class="token punctuation">)</span>

        <span class="token comment"># ===如果是交叉注意力（cross-attention），键和值从编码器获取，否则从隐层获取===</span>
        <span class="token keyword">if</span> is_cross_attention<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>key <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>config<span class="token punctuation">.</span>encoder_width<span class="token punctuation">,</span> self<span class="token punctuation">.</span>all_head_size<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>value <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>config<span class="token punctuation">.</span>encoder_width<span class="token punctuation">,</span> self<span class="token punctuation">.</span>all_head_size<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>key <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>config<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>all_head_size<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>value <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>config<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>all_head_size<span class="token punctuation">)</span>

        <span class="token comment"># 注意力得分的dropout</span>
        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>config<span class="token punctuation">.</span>attention_probs_dropout_prob<span class="token punctuation">)</span>

        <span class="token comment"># 获取位置嵌入类型，如果是相对位置嵌入，则初始化相关嵌入层</span>
        self<span class="token punctuation">.</span>position_embedding_type <span class="token operator">=</span> <span class="token builtin">getattr</span><span class="token punctuation">(</span>
            config<span class="token punctuation">,</span> <span class="token string">"position_embedding_type"</span><span class="token punctuation">,</span> <span class="token string">"absolute"</span>
        <span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>position_embedding_type <span class="token operator">==</span> <span class="token string">"relative_key"</span>
            <span class="token keyword">or</span> self<span class="token punctuation">.</span>position_embedding_type <span class="token operator">==</span> <span class="token string">"relative_key_query"</span>
        <span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>max_position_embeddings <span class="token operator">=</span> config<span class="token punctuation">.</span>max_position_embeddings
            self<span class="token punctuation">.</span>distance_embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>
                <span class="token number">2</span> <span class="token operator">*</span> config<span class="token punctuation">.</span>max_position_embeddings <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>attention_head_size
            <span class="token punctuation">)</span>
        <span class="token comment"># 是否保存注意力图（用于可视化或调试）</span>
        self<span class="token punctuation">.</span>save_attention <span class="token operator">=</span> <span class="token boolean">False</span>

    <span class="token keyword">def</span> <span class="token function">save_attn_gradients</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> attn_gradients<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>attn_gradients <span class="token operator">=</span> attn_gradients    <span class="token comment"># 注意力梯度</span>

    <span class="token keyword">def</span> <span class="token function">get_attn_gradients</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>attn_gradients

    <span class="token keyword">def</span> <span class="token function">save_attention_map</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> attention_map<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>attention_map <span class="token operator">=</span> attention_map  <span class="token comment"># 注意力图</span>

    <span class="token keyword">def</span> <span class="token function">get_attention_map</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>attention_map

    <span class="token keyword">def</span> <span class="token function">transpose_for_scores</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 将输入的张量x转置为(num_attention_heads, attention_head_size)格式</span>
        new_x_shape <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>num_attention_heads<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>attention_head_size<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">*</span>new_x_shape<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        hidden_states<span class="token punctuation">,</span>
        attention_mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>    <span class="token comment"># 注意力掩码</span>
        head_mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>     <span class="token comment"># 注意力头掩码</span>
        encoder_hidden_states<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
        encoder_attention_mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>    <span class="token comment"># 编码器注意力掩码</span>
        past_key_value<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>    <span class="token comment"># 前一个时间步的键值对</span>
        output_attentions<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># 如果是交叉注意力，键和值来自编码器，否则从当前隐藏状态获取</span>
        is_cross_attention <span class="token operator">=</span> encoder_hidden_states <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>

        <span class="token keyword">if</span> is_cross_attention<span class="token punctuation">:</span>
            <span class="token comment"># 计算交叉注意力的键和值</span>
            key_layer <span class="token operator">=</span> self<span class="token punctuation">.</span>transpose_for_scores<span class="token punctuation">(</span>self<span class="token punctuation">.</span>key<span class="token punctuation">(</span>encoder_hidden_states<span class="token punctuation">)</span><span class="token punctuation">)</span>
            value_layer <span class="token operator">=</span> self<span class="token punctuation">.</span>transpose_for_scores<span class="token punctuation">(</span>self<span class="token punctuation">.</span>value<span class="token punctuation">(</span>encoder_hidden_states<span class="token punctuation">)</span><span class="token punctuation">)</span>
            attention_mask <span class="token operator">=</span> encoder_attention_mask     <span class="token comment"># 使用编码器的注意力掩码</span>
        <span class="token keyword">elif</span> past_key_value <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            <span class="token comment"># 如果存在之前的键/值缓存，则将当前计算结果与缓存进行拼接</span>
            key_layer <span class="token operator">=</span> self<span class="token punctuation">.</span>transpose_for_scores<span class="token punctuation">(</span>self<span class="token punctuation">.</span>key<span class="token punctuation">(</span>hidden_states<span class="token punctuation">)</span><span class="token punctuation">)</span>
            value_layer <span class="token operator">=</span> self<span class="token punctuation">.</span>transpose_for_scores<span class="token punctuation">(</span>self<span class="token punctuation">.</span>value<span class="token punctuation">(</span>hidden_states<span class="token punctuation">)</span><span class="token punctuation">)</span>
            key_layer <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>past_key_value<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> key_layer<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
            value_layer <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>past_key_value<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> value_layer<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment"># 计算自注意力的键和值</span>
            key_layer <span class="token operator">=</span> self<span class="token punctuation">.</span>transpose_for_scores<span class="token punctuation">(</span>self<span class="token punctuation">.</span>key<span class="token punctuation">(</span>hidden_states<span class="token punctuation">)</span><span class="token punctuation">)</span>
            value_layer <span class="token operator">=</span> self<span class="token punctuation">.</span>transpose_for_scores<span class="token punctuation">(</span>self<span class="token punctuation">.</span>value<span class="token punctuation">(</span>hidden_states<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 计算查询向量</span>
        mixed_query_layer <span class="token operator">=</span> self<span class="token punctuation">.</span>query<span class="token punctuation">(</span>hidden_states<span class="token punctuation">)</span>

        query_layer <span class="token operator">=</span> self<span class="token punctuation">.</span>transpose_for_scores<span class="token punctuation">(</span>mixed_query_layer<span class="token punctuation">)</span>

        <span class="token comment"># 保存当前的键/值对，用于后续步骤</span>
        past_key_value <span class="token operator">=</span> <span class="token punctuation">(</span>key_layer<span class="token punctuation">,</span> value_layer<span class="token punctuation">)</span>

        <span class="token comment"># Take the dot product between "query" and "key" to get the raw attention scores.</span>
        <span class="token comment"># 计算查询和键的点积，得到注意力得分</span>
        attention_scores <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>query_layer<span class="token punctuation">,</span> key_layer<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 处理相对位置嵌入的情况</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>position_embedding_type <span class="token operator">==</span> <span class="token string">"relative_key"</span>
            <span class="token keyword">or</span> self<span class="token punctuation">.</span>position_embedding_type <span class="token operator">==</span> <span class="token string">"relative_key_query"</span>
        <span class="token punctuation">)</span><span class="token punctuation">:</span>
            seq_length <span class="token operator">=</span> hidden_states<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
            position_ids_l <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>
                seq_length<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">,</span> device<span class="token operator">=</span>hidden_states<span class="token punctuation">.</span>device
            <span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
            position_ids_r <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>
                seq_length<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">,</span> device<span class="token operator">=</span>hidden_states<span class="token punctuation">.</span>device
            <span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token comment"># 计算位置差</span>
            distance <span class="token operator">=</span> position_ids_l <span class="token operator">-</span> position_ids_r
            positional_embedding <span class="token operator">=</span> self<span class="token punctuation">.</span>distance_embedding<span class="token punctuation">(</span>
                distance <span class="token operator">+</span> self<span class="token punctuation">.</span>max_position_embeddings <span class="token operator">-</span> <span class="token number">1</span>
            <span class="token punctuation">)</span>
            positional_embedding <span class="token operator">=</span> positional_embedding<span class="token punctuation">.</span>to<span class="token punctuation">(</span>
                dtype<span class="token operator">=</span>query_layer<span class="token punctuation">.</span>dtype
            <span class="token punctuation">)</span>  <span class="token comment"># fp16 compatibility</span>

            <span class="token keyword">if</span> self<span class="token punctuation">.</span>position_embedding_type <span class="token operator">==</span> <span class="token string">"relative_key"</span><span class="token punctuation">:</span>
                <span class="token comment"># 计算相对位置得分并加到注意力得分中</span>
                relative_position_scores <span class="token operator">=</span> torch<span class="token punctuation">.</span>einsum<span class="token punctuation">(</span>
                    <span class="token string">"bhld,lrd-&gt;bhlr"</span><span class="token punctuation">,</span> query_layer<span class="token punctuation">,</span> positional_embedding
                <span class="token punctuation">)</span>
                attention_scores <span class="token operator">=</span> attention_scores <span class="token operator">+</span> relative_position_scores
            <span class="token keyword">elif</span> self<span class="token punctuation">.</span>position_embedding_type <span class="token operator">==</span> <span class="token string">"relative_key_query"</span><span class="token punctuation">:</span>
                <span class="token comment"># 计算查询和键的相对位置得分，并加到注意力得分中</span>
                relative_position_scores_query <span class="token operator">=</span> torch<span class="token punctuation">.</span>einsum<span class="token punctuation">(</span>
                    <span class="token string">"bhld,lrd-&gt;bhlr"</span><span class="token punctuation">,</span> query_layer<span class="token punctuation">,</span> positional_embedding
                <span class="token punctuation">)</span>
                relative_position_scores_key <span class="token operator">=</span> torch<span class="token punctuation">.</span>einsum<span class="token punctuation">(</span>
                    <span class="token string">"bhrd,lrd-&gt;bhlr"</span><span class="token punctuation">,</span> key_layer<span class="token punctuation">,</span> positional_embedding
                <span class="token punctuation">)</span>
                attention_scores <span class="token operator">=</span> <span class="token punctuation">(</span>
                    attention_scores
                    <span class="token operator">+</span> relative_position_scores_query
                    <span class="token operator">+</span> relative_position_scores_key
                <span class="token punctuation">)</span>

        attention_scores <span class="token operator">=</span> attention_scores <span class="token operator">/</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>self<span class="token punctuation">.</span>attention_head_size<span class="token punctuation">)</span>
        <span class="token keyword">if</span> attention_mask <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            <span class="token comment"># 添加注意力掩码（在BertModel前向传播中预计算）</span>
            <span class="token comment"># Apply the attention mask is (precomputed for all layers in BertModel forward() function)</span>
            attention_scores <span class="token operator">=</span> attention_scores <span class="token operator">+</span> attention_mask

        <span class="token comment"># Normalize the attention scores to probabilities.</span>
        <span class="token comment"># 归一化注意力得分为概率分布</span>
        attention_probs <span class="token operator">=</span> nn<span class="token punctuation">.</span>Softmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>attention_scores<span class="token punctuation">)</span>

        <span class="token keyword">if</span> is_cross_attention <span class="token keyword">and</span> self<span class="token punctuation">.</span>save_attention<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>save_attention_map<span class="token punctuation">(</span>attention_probs<span class="token punctuation">)</span>
            attention_probs<span class="token punctuation">.</span>register_hook<span class="token punctuation">(</span>self<span class="token punctuation">.</span>save_attn_gradients<span class="token punctuation">)</span>

        <span class="token comment"># This is actually dropping out entire tokens to attend to, which might</span>
        <span class="token comment"># seem a bit unusual, but is taken from the original Transformer paper.</span>
        attention_probs_dropped <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>attention_probs<span class="token punctuation">)</span>

        <span class="token comment"># Mask heads if we want to</span>
        <span class="token comment"># 如果需要掩盖特定的注意力头</span>
        <span class="token keyword">if</span> head_mask <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            attention_probs_dropped <span class="token operator">=</span> attention_probs_dropped <span class="token operator">*</span> head_mask

        <span class="token comment"># 计算上下文向量（注意力概率与值的乘积）</span>
        context_layer <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>attention_probs_dropped<span class="token punctuation">,</span> value_layer<span class="token punctuation">)</span>

        <span class="token comment"># 调整上下文向量形状</span>
        context_layer <span class="token operator">=</span> context_layer<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>
        new_context_layer_shape <span class="token operator">=</span> context_layer<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>all_head_size<span class="token punctuation">,</span><span class="token punctuation">)</span>
        context_layer <span class="token operator">=</span> context_layer<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">*</span>new_context_layer_shape<span class="token punctuation">)</span>

        outputs <span class="token operator">=</span> <span class="token punctuation">(</span>
            <span class="token punctuation">(</span>context_layer<span class="token punctuation">,</span> attention_probs<span class="token punctuation">)</span> <span class="token keyword">if</span> output_attentions <span class="token keyword">else</span> <span class="token punctuation">(</span>context_layer<span class="token punctuation">,</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

        outputs <span class="token operator">=</span> outputs <span class="token operator">+</span> <span class="token punctuation">(</span>past_key_value<span class="token punctuation">,</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> outputs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/672514787">TimeChat：基于Q-Former的时序感知VideoLLM - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/AIGCer/article/details/142799336">从秒级到小时级：TikTok等发布首篇面向长视频理解的多模态大语言模型全面综述_tiktok 语音大模型-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/650519771">https://zhuanlan.zhihu.com/p/650519771</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/638103950">多模态超详细解读 (八)：InstructBLIP: 指令微调训练通用视觉语言模型 - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/mieshizhishou/article/details/140719063">【有啥问啥】多模态大模型应用中的Q-Former是什么？_qformer-CSDN博客</a></p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">wolf-ll</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://wolf-ll.github.io/2024/10/13/timechat-a-time-sensitive-multimodal-large-language-model/">http://wolf-ll.github.io/2024/10/13/timechat-a-time-sensitive-multimodal-large-language-model/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">wolf-ll</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/MLLM/">
                                    <span class="chip bg-color">MLLM</span>
                                </a>
                            
                                <a href="/tags/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                                    <span class="chip bg-color">视频理解</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    
    <div class="card" data-aos="fade-up">
    <div id="utteranc-container" class="card-content">
        <script src="https://utteranc.es/client.js"
                repo="wolf-ll/comments"
                issue-term="pathname"
                theme="github-light"
                crossorigin="anonymous"
                async>
        </script>
    </div>
</div>
    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/">
                    <div class="card-image">
                        
                        <img src="/medias/featureimages/15.jpg" class="responsive-img" alt="MVBench">
                        
                        <span class="card-title">MVBench</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            多模态大模型视频理解能力基准
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-11-12
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E8%AE%BA%E6%96%87/" class="post-category">
                                    论文
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/MLLM/">
                        <span class="chip bg-color">MLLM</span>
                    </a>
                    
                    <a href="/tags/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                        <span class="chip bg-color">视频理解</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2024/10/08/springcloud/">
                    <div class="card-image">
                        
                        <img src="/medias/featureimages/9.jpg" class="responsive-img" alt="SpringCloud">
                        
                        <span class="card-title">SpringCloud</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            微服务理论，实践，八股
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-10-08
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%90%8E%E7%AB%AF/" class="post-category">
                                    后端
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%A1%86%E6%9E%B6/">
                        <span class="chip bg-color">框架</span>
                    </a>
                    
                    <a href="/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/">
                        <span class="chip bg-color">微服务</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024</span>
            
            <span id="year">2024</span>
            <a href="/about" target="_blank">wolf-ll</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">228.2k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2024";
                    var startMonth = "4";
                    var startDate = "21";
                    var startHour = "16";
                    var startMinute = "35";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/wolf-ll" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:837691088@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=837691088" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 837691088" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>





    <a href="https://www.zhihu.com/people/zhi-qi-wei-tuo" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/zhi-qi-wei-tuo" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

	
    

    

    
    <script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async="async"></script>
    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
