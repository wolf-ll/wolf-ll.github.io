<!DOCTYPE HTML>
<html lang="zh-CN">
 <!--自定义看板娘-->
  <script src="https://cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script>
  <script src="/live2d-widget/autoload.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"/>


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="MVBench, 后端开发">
    <meta name="description" content="Java | LeetCode | Algorithm">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>MVBench | wolf-ll&#39;s blog</title>
    <link rel="icon" type="image/png" href="/medias/logo.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: #FFF;
        text-align: center;
        /* loaderҳ����ʧ���ý����ķ�ʽ*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid #49b1f5;
        border-right-color: transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid #49b1f5;
        border-right-color: transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: #49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: #2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo���ֶ��� */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ʹ�ý����ķ�������loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },1000); 
        },1000);//ǿ����ʾloading page 1s  
    };
    loaded();
})()
 </script><meta name="generator" content="Hexo 7.2.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="wolf-ll's blog" type="application/atom+xml">
</head>





 <div id="loading-container">
     <p class="loading-text"></p> 
     <div class="loading-image">
         <div></div>
         <div></div>
         <div></div>
         <div></div> 
         <div></div>
     </div>
 </div><body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">wolf-ll&#39;s blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">wolf-ll&#39;s blog</div>
        <div class="logo-desc">
            
            Java | LeetCode | Algorithm
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/wolf-ll/wolf-ll.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/wolf-ll/wolf-ll.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/15.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">MVBench</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/MLLM/">
                                <span class="chip bg-color">MLLM</span>
                            </a>
                        
                            <a href="/tags/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                                <span class="chip bg-color">视频理解</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E8%AE%BA%E6%96%87/" class="post-category">
                                论文
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-11-12
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-01-07
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    8.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    36 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="MVBench-A-Comprehensive-Multi-modal-Video-Understanding-Benchmark"><a href="#MVBench-A-Comprehensive-Multi-modal-Video-Understanding-Benchmark" class="headerlink" title="MVBench: A Comprehensive Multi-modal Video Understanding Benchmark"></a>MVBench: A Comprehensive Multi-modal Video Understanding Benchmark</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>论文介绍了MVBench，这是一个全新的多模态视频理解基准测试，旨在评估多模态大型语言模型（MLLMs）在视频理解方面的能力。</p>
<ul>
<li>目前许多基准测试主要集中在<strong>静态图像任务的空间理解</strong>上，而<strong>忽视了动态视频任务中的时间理解</strong>。MVBench通过20个具有挑战性的<strong>视频任务</strong>来填补这一空白，这些任务无法通过单帧图像有效解决。</li>
<li>论文提出了一种新颖的<strong>静态到动态方法</strong>来定义与时间相关的任务，并将各种静态任务转化为动态任务，从而系统地生成各种视频任务，无需人工参与。</li>
<li>通过任务定义，研究者们自动<strong>将视频注释转换为多项选择的问答（QA）</strong>，以评估每个任务。</li>
<li>MVBench的构建高效且公平，避免了对LLMs的评分偏见。论文开发了一个强大的视频MLLM基线VideoChat2，并通过多样化的指令调整数据进行逐步多模态训练。</li>
<li>在MVBench上表明，现有的MLLMs在时间理解方面远未达到令人满意的水平，而VideoChat2在MVBench上的准确率超过了这些领先模型15%以上。</li>
</ul>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>多模态大模型（MLLM）通过在各种预先训练的LLM中嵌入视觉编码器，推动了视觉-语言学习任务的发展。一个很自然的问题是如何评估这些模型的视觉理解能力，<strong>这种评估对于确认其设计有效性和进一步改进它们以更广泛地理解开放世界的多种模态至关重要。</strong></p>
<p>为了满足这一需求，一些基准测试已经被提出。其主要方法是在各种感知任务上构造QA式以评估MLLM性能。然而，这些基准主要集中在基于图像的理解上，所有的问题都是为静态图像的空间感知设计的（如图一spatial understanding所示）。<strong>因此他们难以评估动态视频中的时间演化，而这对于现实世界中的程式化活动的理解是十分重要的。</strong></p>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20241113183819734.png" alt="image-20241113183819734" style="zoom: 80%;">

<p>尽管最近已经有一些基准来评估视频中的时间感知任务，但它们要么只聚焦于非常基本的视频任务（如SEED-Bench中的行为识别和预测），要么聚焦特定领域（如FunQA）或受限的场景（如Perception Test中的室内场景）。因此，利用这些基准来对mllm的时间理解技能进行全面的评估是有限的。此外，它们通过劳动密集型标注收集，导致昂贵的人工成本。为了解决这些问题，<strong>本文提出了一个多模态视频理解基准（MVBench），它旨在全面评估开放世界中mllm的时间感知能力。</strong>与上面现有的基准相比，MVBench有两种不同的设计：</p>
<ol>
<li><p><strong>引入了从静态到动态的方法（a novel static-to-dynamic method）：</strong></p>
<p>为静态图像任务增加动态演化的时间上下文，得到了20个视频理解任务，这些任务需要对视频的时间维度有深入理解，涵盖了从感知到认知的广泛的时间理解技能。具体来说，作者在之前的多模态基准测试中使用静态图像任务作为定义参考。然后，<strong>用视频中的时间上下文来扩大这些静态任务的问题</strong>，例如，图像中的位置任务可以灵活地转换为视频中的移动方向任务(“男人在舞台上吗？”→“这个人的方向是什么？”)</p>
</li>
<li><p><strong>引入自动标注范式，实现自动问答生成（Automatic QA Generation）：</strong></p>
<p>利用现有的视频基准测试和大型语言模型(LLMs)，<strong>自动将视频注释转换为多项选择的问答对</strong>，用于评估MLLMs的性能。<br>选择了11个公共视频基准测试，并根据任务定义自动生成问题和答案选项。大大降低人工标注成本，涵盖了各种复杂的领域和不同的场景，从第一人称到第三人称的视角，以及从室内到室外的环境。这些基准为MVBench提供了基本事实，保证了评估的公平性和准确性，避免了LLM的有偏评分。</p>
</li>
</ol>
<p>最后，在MVBench上对多个著名的MLLM进行全面评估，结果表明这些图像和视频MLLM在各项任务上还远不能让人满意。因此，作者还开发了一个视频MLLM基线模型，即VideoChat2。该模型桥接了大模型和一个强大的视频基础模型。随后，<strong>引入了一个具有广泛的多模态指令的渐进式训练范式，允许视频和语言之间的有效对齐。</strong>评估表明，VideoChat2在MVBench上显著领先表现最好的VideoChat15%，并且在视频对话和零样本QA基准上（video conversation and zero-shot QA benchmarks）取得了最先进的结果。</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><h3 id="MLLM"><a href="#MLLM" class="headerlink" title="MLLM"></a>MLLM</h3><ul>
<li>多模态LLM（MLLM）旨在增强多种模式的理解和生成能力。开创性模型如Flamingo和PaLM-E无缝地融合了文本和视觉，在一系列多模态任务中展现出优越性。</li>
<li>近期开源的LLM进一步加速了公共MLLM的出现。LLaVA，MiniGPT-4，InstructBLIP提出了一系列视觉指令微调数据。</li>
<li>除了文本和静态图像，一些研究开始挖掘LLM在视频模态中的潜力。VideoChat，VideoChat-GPT和Valley利用LLM生成视频指令微调数据以增强指令遵循能力。</li>
<li>VideoChat2检验MLLM的基本的时间理解能力，为更优的MLLM提供有价值的设计理念。</li>
</ul>
<h3 id="Benchmark"><a href="#Benchmark" class="headerlink" title="Benchmark"></a>Benchmark</h3><ul>
<li><p>传统的视觉语言（VL）benchmark集中在多模态检索和视觉QA。MLLM的发展催化了评估集成视觉语言任务的benchmark。</p>
</li>
<li><p>LVLM-eHub通过与图像相关的查询提供了一个交互式的模型比较平台。其他基准如OwlEval [94], MME [17], SEED-Bench [37],</p>
<p>MM-Vet [97], and MMBench 强调全面的VL能力，引入仅超越模型结构的评估指标。</p>
</li>
<li><p>视频领域有Perception Test，测试了<strong>多模态视频感知和推理</strong>；VideoChatGPT量化了<strong>从视频输入中生成对话的能力</strong>；FunQA通过反直觉和幽默的内容来限制视频推理。</p>
</li>
<li><p>与现有的视频基准相比，MVBench涵盖了广泛的时间任务，强调了<strong>对时间敏感的视频和</strong>对<strong>公共注释的有效使用</strong>，并对mllm的时间理解进行了全面的评估。</p>
</li>
</ul>
<h2 id="MVBench"><a href="#MVBench" class="headerlink" title="MVBench"></a>MVBench</h2><h3 id="时间任务定义"><a href="#时间任务定义" class="headerlink" title="时间任务定义"></a>时间任务定义</h3><p>静态到动态方法，使静态任务适应动态目标。使用静态图像的空间理解任务作为系统地设计从感知到认知的时间任务的参考。从图像benchmark里总结了上述9项空间理解任务，再思考延伸出20项时间理解任务如下：</p>
<ul>
<li><p><strong>Action.</strong> (1) <em>Action Sequence:</em> 检索在特定操作之前或之后发生的事件。 (2) <em>Action Prediction:</em> 根据当前操作推断后续事件。(3) <em>Action Antonym:</em> 将正确的操作与两个错误的操作区分开来。 (4) <em>Fine-grained Action:</em> 从一系列类似选项中确定准确的操作。 (5) <em>Unexpected Action:</em> 检测以幽默、创意或magic为特征的视频中的surprising actions。</p>
</li>
<li><p><strong>Object.</strong> (6) <em>Object Existence:</em> <strong>确定特定事件期间是否存在特定对象。</strong> (7) <em>Object Interaction:</em> 标识参与特定事件的对象。 (8) <em>Object Shuffle:</em> 在遮挡游戏中定位对象的最终位置。</p>
</li>
<li><p><strong>Position.</strong> (9) <em>Moving Direction:</em> 确定特定对象移动的轨迹。 (10) <em>Action Localization:</em> <strong>确定发生特定操作的时间段。</strong></p>
</li>
<li><p><strong>Scene.</strong> (11) <em>Scene transition:</em> 确定视频中场景的过渡方式。</p>
</li>
<li><p><strong>Count.</strong> (12) <em>Action Count:</em> 计算特定操作已执行的次数。(13) <em>Moving Count:</em> 计算执行了特定操作的对象数。</p>
</li>
<li><p><strong>Attribute.</strong> (14) <em>Moving Attribute:</em> 确定特定移动对象在给定时刻的表现/外观。 (15) <em>State Change:</em> <strong>确定某个对象的状态在整个视频中是否发生变化。</strong></p>
</li>
<li><p><strong>Pose.</strong> (16) <em>Fine-grained Pose:</em> 从一系列类似选项中确定准确的姿态类别。</p>
</li>
<li><p><strong>Character.</strong> (17) <em>Character Order:</em> 确定字母的显示顺序。</p>
</li>
<li><p><strong>Cognition.</strong> (18) <em>Egocentric Navigation:</em> Forecast the subsequent action, based on an agent’s current navigation instructions. 根据agent的当前指令预测后续操作。(19) <em>Episodic Reasoning:</em> 对电视连续剧一集中的人物、事件和对象进行推理。 (20) <em>Counterfactual Inference:</em> 思考如果发生某个事件会发生什么。</p>
</li>
</ul>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20241115113421996.png" alt="image-20241115113421996" style="zoom:80%;">

<h3 id="自动QA生成"><a href="#自动QA生成" class="headerlink" title="自动QA生成"></a>自动QA生成</h3><p>在时间任务定义的指导下，为每个任务收集和标注视频。具体来说，图2中设计了一个自动QA生成范式，它有效地将开源视频数据标注转换为评估mllm的多项选择QA。</p>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20241115162755492.png" alt="image-20241115162755492" style="zoom:80%;">

<p><strong>数据过滤</strong></p>
<ul>
<li>考虑到<strong>视频多样性</strong>，仔细选择了11个视频数据集，覆盖广泛的领域和场景，尽可能地对不同的视频设计独立的问题；</li>
<li>考虑到<strong>时序敏感性</strong>，采取每个数据集中合适的视频长度（5~35秒），过短的视频往往动作幅度较小，而过长的视频包含过于复杂的上下文，问题过难会导致无法区分不同模型的能力；</li>
<li>考虑到<strong>问题复杂度</strong>，采取难度适中的问题，如在CLEVRER中，采取<strong>适当条件限制</strong>（排除需要超过10个条件的问题）的问题；如对于时间定位问题，不采用精细的秒级别定位任务，而采用粗略的时间段定位，如发生在视频的开始、中间还是结束。</li>
</ul>
<p><strong>QA生成</strong></p>
<p>之后便来到生成多选题的问题及选项，对于已有多选QA的数据，可以直接采用。但对于没有多选QA的数据，利用ChatGPT来自动生成多选QA格式。</p>
<ul>
<li>对于<strong>问题</strong>，根据任务定义，让ChatGPT生成3-5个对应的问题随机选其一；</li>
<li>对于<strong>选项</strong>，设计两种策略：(a)<strong>基于模版的构造</strong>，设计固定的选项模版，从ground truth annotations中构建候选集（例如，针对<em>Action Antonym</em>任务，包含正确选项，相反选项，不确定选项；在<em>Moving Direction</em>任务中，包含<em>up</em>, <em>down</em>, <em>left</em>, <em>right</em>四个方向以及固定状态），结合GPT匹配生成；(b)<strong>基于LLM的生成</strong>，针对类似<em>Unexpected Action</em>任务，将原始QA输入ChatGPT，并让ChatGPT生成新的问题以及选项。使用多选格式而不是开放格式，保证评估的正确性和公平性（如果引入开放答案，可能导致评估偏差或人工干预）。最终，本文为每个时间理解任务产生了<strong>200对多项选择QA对。</strong></li>
</ul>
<p><strong>问题选项处理</strong></p>
<p>对于每个问题，从可用的候选集中随机抽样三到五个答案选项，调整选项顺序以加强评估的稳健性。为了防止答案泄露，进一步使用LLM保证一个问题的所有答案选项具有相似和合理的长度。</p>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20241116140912529.png" alt="image-20241116140912529" style="zoom:80%;">

<h3 id="evaluation的prompt设计"><a href="#evaluation的prompt设计" class="headerlink" title="evaluation的prompt设计"></a>evaluation的prompt设计</h3><p>对于具体的评测，作者设计了合理的system prompt和高效的answer prompt，其中<strong>system prompt</strong>用于<strong>激发模型的时间理解能力</strong>（见图2右下角），这一提示鼓励mllm仔细检查视频内容来回答问题，通过注意诸如人的动作和姿势，以及物体运动的细节和动作等因素。</p>
<blockquote>
<p><em>Carefully watch the video and pay attention to the <strong>cause and sequence of events, the detail and movement of objects and the action and pose of persons.</strong> Based on your observations, select the best option that accurately addresses the question.</em></p>
</blockquote>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20241117103651589.png" alt="image-20241117103651589" style="zoom:80%;">

<p>由于对话模型的输出倾向于输出完整的句子，难以直接输出选项，如何<strong>从对话的输出中抽取选项</strong>也成了一个难题。MMBench中使用多个模版匹配选项，对于无法匹配的选项，使用ChatGPT进行抽取。然而这种抽取效率低下， 和人类相比，只取得了87%的对齐率。SEED-Bench则比较不同选项的似然，选择最大似然对应的选项作为最终答案，这种方式仍不够直接，并且需要人为修改不同模型的forward函数。本文采取一种更简单直接的方式，通过<strong>构造带括号”()”的选项</strong>，接着显著地通过控制对话模型输出的起始字符”<strong>Best Option: (</strong>“，即<strong>answer prompt</strong>来指导mllm的选项生成，在本文实验里，这种方式不仅可以100%地保证不同模型输出选项，同时能够提高答案的准确率。</p>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20241117103831488.png" alt="image-20241117103831488" style="zoom:80%;">

<h2 id="VideoChat2"><a href="#VideoChat2" class="headerlink" title="VideoChat2"></a>VideoChat2</h2><p>作者在MVBench上评估了现有的图像和视频对话模型（见实验部分表2），结果发现即便是最佳的视频对话模型VideoChat，性能与随机猜测相比也相差无几。分析原因可以发现，目前的视频对话模型存在两大缺陷：</p>
<ul>
<li><strong>缺乏多样的指令微调数据</strong>：由于视频数据难以标注，开源的指令微调数据仍规模较小；</li>
<li><strong>缺乏强视频编码器</strong>：目前主流的视频编码方法仍是选强多模态图像编码器CLIP-ViT，在上面进行时序改良，这难以本质地处理时序上的理解。</li>
</ul>
<p>为了弥补这些差距，本文开发了一个健壮的视频mllm基线模型VideoChat2。</p>
<h3 id="指令微调数据"><a href="#指令微调数据" class="headerlink" title="指令微调数据"></a>指令微调数据</h3><p>为了解决缺乏多样指令调优数据的问题，引入了如图3所示的丰富数据，其中包含了来自34个不同来源的2M个样本。效仿VideoChat和VideoLlama，在指令集中包含了图像和视频数据，以改进训练。</p>
<p>受M3IT的启发，本文以统一的格式重新组织了所有的数据样本，如图3的右下角所示。涉及两个key分别是{“image” or “video”}及{“QA”}。QA中包含instruction，question和answer。M3IT中要求研究人员为每一个数据集设计10组instruction，本文使用ChatGPT来生成指令（根据dataset_description，task_description，instruction_example）来生成。</p>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20241117105738621.png" alt="image-20241117105738621" style="zoom:80%;">

<p>整个指令调优数据集可以粗略地分为6类：</p>
<ul>
<li>conversation：提高多轮对话能力。从LLaVA和VideoChat中收集对话数据；从VideoChatGPT中集成caption数据转为对话格式。</li>
<li>simple caption：提供基本的视觉描述能力。使用广泛使用的COCO和WebVid，以及来自YouCook2的一级视频字幕。</li>
<li>detailed caption：丰富视频细节的全面理解能力。利用MiniGPT-4, LLaVA和VideoChat的详细caption数据。</li>
<li>VQA：提高视觉问答能力。</li>
<li>reasoning：提高不同的推理能力。</li>
<li>classification：提高对目标识别和动作识别的鲁棒性。</li>
</ul>
<h3 id="渐进式跨模态训练范式"><a href="#渐进式跨模态训练范式" class="headerlink" title="渐进式跨模态训练范式"></a>渐进式跨模态训练范式</h3><p>促进mllm的另一个关键因素是如何有效地弥合视觉和语言表征之间的语义差距。为了解决这个问题，作者采用了如图4所示的渐进式多模态训练范式。</p>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20241117170157954.png" alt="image-20241117170157954" style="zoom:80%;">

<p><strong>阶段1：视觉-语言对齐</strong></p>
<p>为了平衡效率和有效性，冻结视觉编码器，<strong>训练灵活的QFormer</strong>。它将冗余的视觉令牌（visual tokens）压缩为更少的查询令牌（query tokens），并<strong>通过多模态损失</strong>（即BLIP2训练的三种损失：视觉文本对比学习（VTC）、视觉文本匹配（VTM）和基于视觉的文本生成（VTG））<strong>将这些查询与文本令牌对齐。</strong>与BLIP2不同，本文选择了预训练过的<strong>UMT-L</strong>作为视觉编码器，因为它具有强大的时空表示学习能力。此外，训练CC3M和CC12M的15M图像字幕，WebVid-10M的10M视频字幕，以增强视频语言建模。</p>
<p><strong>阶段2：视觉-语言连接</strong></p>
<p>在初始对齐之后，将视觉编码器与预先训练过的llm连接起来，以构建视觉-语言理解能力。和BLIP2类似，作者应<strong>用一个线性投影来进一步转换查询标记，并将投影的标记与文本标记连接到LLM中</strong>，用于基于视觉的标题生成（即VTG）。与BLIP2不同的是，视觉编码器在这个阶段是非冻结的，以便更好地与LLM对齐。除了上述第一阶段的训练数据外，这一阶段进一步引入了2M图像caption（COCO、Visual Genome和SBU）和10M视频caption（InternVid），以丰富caption的多样性。</p>
<p><strong>阶段3：指令微调</strong></p>
<p>使用前面所述的指令微调数据进行微调。在冻结的LLM上进行lora低轶微调，通过VTG损失与视觉编码器和QFormer一起调整。此外，借鉴InstructBLIP，<strong>作者在QFormer中也插入了instruction</strong>，用于提取与指令相关的视觉token作为LLM的输入。</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><ul>
<li>视觉编码器：UMT-L</li>
<li>大模型：Vicuna-7B</li>
<li>借鉴BLIP2，使用带有预训练Bert_base的QFormer，阶段1：32个query，阶段2和3：64个query</li>
<li>训练时：每个视频4帧，阶段1有10个epoch，阶段2有1个epoch；第3阶段转为8帧视频的3个epoch。</li>
<li>评估时：输入了16帧的视频，并提供了详细的prompt，以获得更好的结果。</li>
</ul>
<h3 id="MVBench整体评估"><a href="#MVBench整体评估" class="headerlink" title="MVBench整体评估"></a>MVBench整体评估</h3><p>表2展示了在MVBench上的评估结果，现有的图像和视频MLLM表现不佳。VideoChat2在15个任务上取得最佳性能，特别是在动作、物体、场景、属性和姿势识别（action, object, scene, attribute, and pose recognition）等方面表现出色。但也能看到，它在处理移动方向、动作定位、计数等任务上仍有不足。最近的一些图像对话模型，已经开始引入grouding数据增强相关能力，这也是后续视频对话模型可以突破的方向。</p>
<blockquote>
<p>值得一提的是，这里的VideoChat2_text，输入为空白视频，即QFormer输出噪声embedding，模型仅靠文本上下文进行输出，结果居然与前述最强模型接近。这个结果也揭示了<strong>目前对话模型，在时序理解任务上，仍有很大的不足</strong>。</p>
</blockquote>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20241117104639154.png" alt="image-20241117104639154" style="zoom:80%;">

<p>此外，作者还评估了功能强大的GPT-4V。结果表明，GPT-4V取得了令人满意的性能，证明了其时间理解能力，而VideoChat2超过了它，准确率提高了16.9%。这进一步强调了模型在处理更广泛的任务方面的优越性。</p>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20241127143347889.png" alt="image-20241127143347889" style="zoom:80%;">

<h3 id="更多比较"><a href="#更多比较" class="headerlink" title="更多比较"></a>更多比较</h3><p>仿照Video-chatgpt，本文使用ChatGPT在视频mllm之间进行定量比较。</p>
<p>（1）<strong>视频对话</strong>：表3显示了在Video-chatgpt中的基准上的结果。与VideoChatGPT相比，我VideoChat2在所有指标上都表现出了卓越的性能，在信息正确性、上下文和时间理解方面都取得了明显的进步。这表明，VideoChat2更<strong>擅长理解空间和时间细节，并提供一致和可靠的反应。</strong></p>
<p>（2）<strong>零样本视频QA</strong>：表4列出了视频QA数据集（Video question answering via gradually refined attention over appearance and motion. 及 Activitynet-qa: A dataset for understanding complex web videos via question answering.）上的结果，VideoChat2超过了所有其他方法，特别是在理解ActivityNet中的长视频方面。</p>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20241127114104593.png" alt="image-20241127114104593" style="zoom:80%;">

<p>图5中进一步进行了定性比较，其中VideoChat2提供了一个精确而彻底的响应。</p>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20241127114508886.png" alt="image-20241127114508886" style="zoom:80%;">

<h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h3><ul>
<li><strong>指令微调数据</strong>：随着数据多样性和数量的增加，性能显著提高，其中<strong>视频数据的贡献大于图像数据</strong>（50.5% vs. 42.1%）。考虑到COCO和WebVid的简单caption数据中潜在的冗余性，对它们进行了随机压缩。这只对性能产生很小的影响（50.7% vs. 51.1%），但加速了微调1.7×。</li>
<li><strong>架构</strong>：（1）<strong>视觉编码器</strong>：表6中，使用本文构建的指令数据集+EVA-CLIP-g获得与原始VideoChat中模型相比6.9%的性能提升（42.4% vs 35.5%）。用UMT-L进行的进一步替换额外提高了6.2%的性能；（2）<strong>LLM</strong>：合并更大和更新的llm在结果中提供了一个最低限度的改进，这表明<strong>MVBench主要依赖于视觉编码器</strong>。值得注意的是，<strong>LoRA不断提高结果，可能是由于它增强了模型指令遵循的能力。</strong></li>
<li><strong>训练方法</strong>：只微调线性投影层，冻结视觉编码器和QFormer（参考MiniGPT-4），结果不佳（见表7，38.5%）。解冻Qformer，获得额外8.5%的性能提升；解冻视觉编码器获得更多的提升。</li>
<li><strong>提示设计</strong>：system prompt揭示了任务需求，增强任务完成能力。提取选项时，不同于不稳定的ChatGPT-extracting methods，和更耗时的log-likelihood comparisons，本文使用一种简单有效的answer prompt。表9证明了它能够准确地捕获选项，并提高了跨各种mllm的响应精度。VideoChat2即使没有提示，也能更好地按照指令返回选项。</li>
</ul>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20241127113600397.png" alt="image-20241127113600397" style="zoom:80%;">

<p>对于QFormer，在第二第三阶段引入了额外可学习的token，用于和LLM对齐，结果显示<strong>额外引入64个token效果最佳</strong>。并且<strong>在QFormer中插入instruction引导，结果提升明显</strong>，而继续插入question则有副作用。过长的上下文（“指令+问题”）可能很难实现QFormer的信息提取。</p>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20241127155131928.png" alt="image-20241127155131928" style="zoom:80%;">

<p>对于训练和测试输入，实验表明训练使用8帧，测试使用16帧效果较好，训练开销也较小。但<strong>使用大分辨率，在MVBench上并没有提升，即增加分辨率并不能提高性能；然而，增加帧数可以提高，侧面验证了MVBench更依赖于模型的时序理解能力</strong>。</p>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20241127161900211.png" alt="image-20241127161900211" style="zoom:80%;">

<h3 id="定性结果"><a href="#定性结果" class="headerlink" title="定性结果"></a>定性结果</h3><img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20241127162102966.png" alt="image-20241127162102966" style="zoom:80%;">

<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20241127162127244.png" alt="image-20241127162127244" style="zoom:80%;">

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文介绍了MVBench，一个评估mllm的时间理解能力的综合基准。此外，本文针对现有视频对话模型的缺陷，构造了更丰富的指令微调数据，提出了一个健壮的视频MLLM基线模型，VideoChat2，在MVBench上比领先的模型表现超过15%。我们广泛的分析进一步指导了MLLM的时间理解的设计。</p>
<h2 id="项目配置"><a href="#项目配置" class="headerlink" title="==项目配置=="></a>==项目配置==</h2><h2 id="数据相关"><a href="#数据相关" class="headerlink" title="数据相关"></a>数据相关</h2><h3 id="标签"><a href="#标签" class="headerlink" title="标签"></a>标签</h3><p>以JSON格式提供了一个包含2M数据注释的综合数据集。annotation示例如下：</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token property">"image"</span><span class="token operator">:</span> <span class="token string">"two_col_103562.png"</span><span class="token punctuation">,</span> <span class="token property">"QA"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token property">"i"</span><span class="token operator">:</span> <span class="token string">"Examine the chart's visual features and the underlying data table closely to provide an accurate answer to the question."</span><span class="token punctuation">,</span> <span class="token property">"q"</span><span class="token operator">:</span> <span class="token string">"As of 2021, how many championship titles had Ferrari won?"</span><span class="token punctuation">,</span> <span class="token property">"a"</span><span class="token operator">:</span> <span class="token string">"The answer is 16."</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span> 
 
 <span class="token punctuation">{</span><span class="token property">"image"</span><span class="token operator">:</span> <span class="token string">"two_col_2954.png"</span><span class="token punctuation">,</span> <span class="token property">"QA"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token property">"i"</span><span class="token operator">:</span> <span class="token string">"Analyze the visual and data components of the chart carefully and answer the question based on both the graphical representation and numerical data provided."</span><span class="token punctuation">,</span> <span class="token property">"q"</span><span class="token operator">:</span> <span class="token string">"What game topped the charts with 512.3 million hours watched on Twitch in the first half of 2019?"</span><span class="token punctuation">,</span> <span class="token property">"a"</span><span class="token operator">:</span> <span class="token string">"The answer is League of Legends."</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span> .....<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>视频分类：</p>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20241129145657121.png" alt="image-20241129145657121" style="zoom:80%;">

<p>视频caption生成：</p>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20241129145746658.png" alt="image-20241129145746658" style="zoom:80%;">

<h3 id="数据源"><a href="#数据源" class="headerlink" title="数据源"></a>数据源</h3><p><strong>图像数据源</strong>：</p>
<p>M3IT（<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/MMInstruction/M3IT%EF%BC%89%EF%BC%8C%E9%80%9A%E8%BF%87%E4%BB%A5%E4%B8%8B%E6%96%B9%E5%BC%8F%E8%BF%87%E6%BB%A4%E5%87%BA%E8%B4%A8%E9%87%8F%E8%BE%83%E4%BD%8E%E7%9A%84%E6%95%B0%E6%8D%AE%EF%BC%9A">https://huggingface.co/datasets/MMInstruction/M3IT），通过以下方式过滤出质量较低的数据：</a></p>
<ul>
<li>纠正拼写错误：大多数标点符号使用不正确的句子都得到了纠正。</li>
<li>改写错误答案：ChatGPT生成的一些回复，如“对不起，…”，是不正确的。这些用GPT-4重新表述。</li>
</ul>
<p><strong>视频数据源：</strong></p>
<ul>
<li>VideoChat（<a target="_blank" rel="noopener" href="https://github.com/OpenGVLab/InternVideo/tree/main/Data/instruction_data%EF%BC%89%EF%BC%9A%E5%9F%BA%E4%BA%8EInternVid%E5%88%9B%E5%BB%BA%E4%BA%86%E9%A2%9D%E5%A4%96%E7%9A%84%E6%8C%87%E4%BB%A4%E6%95%B0%E6%8D%AEinstruction%EF%BC%8C%E5%B9%B6%E4%BD%BF%E7%94%A8GPT-4%E5%8E%8B%E7%BC%A9%E7%8E%B0%E6%9C%89%E6%95%B0%E6%8D%AE%E3%80%82">https://github.com/OpenGVLab/InternVideo/tree/main/Data/instruction_data）：基于InternVid创建了额外的指令数据instruction，并使用GPT-4压缩现有数据。</a></li>
<li>VideoChatGPT（<a target="_blank" rel="noopener" href="https://github.com/mbzuai-oryx/Video-ChatGPT/tree/main/data%EF%BC%89%EF%BC%9A%E5%8E%9F%E5%A7%8Bcaption%E6%95%B0%E6%8D%AE%E5%9F%BA%E4%BA%8E%E7%9B%B8%E5%90%8C%E7%9A%84VideoID%E8%BD%AC%E6%8D%A2%E4%B8%BA%E5%AF%B9%E8%AF%9D%E6%95%B0%E6%8D%AE%E3%80%82">https://github.com/mbzuai-oryx/Video-ChatGPT/tree/main/data）：原始caption数据基于相同的VideoID转换为对话数据。</a></li>
<li>Kinetics-710（<a target="_blank" rel="noopener" href="https://github.com/OpenGVLab/UniFormerV2/blob/main/DATASET.md%EF%BC%89%E5%92%8CSthSthV2%EF%BC%88[Datasets](https://www.qualcomm.com/developer/artificial-intelligence/datasets)%EF%BC%89%EF%BC%9A%E9%80%89%E9%A1%B9%E5%80%99%E9%80%89%E6%98%AF%E6%A0%B9%E6%8D%AEUMT%E5%89%8D20%E5%90%8D%E7%9A%84%E9%A2%84%E6%B5%8B%E7%94%9F%E6%88%90%E7%9A%84%E3%80%82">https://github.com/OpenGVLab/UniFormerV2/blob/main/DATASET.md）和SthSthV2（[Datasets](https://www.qualcomm.com/developer/artificial-intelligence/datasets)）：选项候选是根据UMT前20名的预测生成的。</a></li>
<li>NExTQA（<a target="_blank" rel="noopener" href="https://github.com/doc-doc/NExT-QA%EF%BC%89%EF%BC%9A%E5%8E%9F%E5%A7%8B%E5%8F%A5%E5%AD%90%E4%B8%AD%E7%9A%84%E6%8B%BC%E5%86%99%E9%94%99%E8%AF%AF%E5%B7%B2%E8%A2%AB%E7%BA%A0%E6%AD%A3%E3%80%82">https://github.com/doc-doc/NExT-QA）：原始句子中的拼写错误已被纠正。</a></li>
<li>CLEVRER（<a target="_blank" rel="noopener" href="https://clevrer.csail.mit.edu/%EF%BC%89%EF%BC%9A%E5%AF%B9%E4%BA%8E%E5%8D%95%E9%A1%B9%E9%80%89%E6%8B%A9%E9%A2%98%EF%BC%8C%E5%8F%AA%E4%BD%BF%E7%94%A8%E4%BA%86%E4%B8%8E%E9%A2%9C%E8%89%B2/%E6%9D%90%E6%96%99/%E5%BD%A2%E7%8A%B6%E6%9C%89%E5%85%B3%E7%9A%84%E9%97%AE%E9%A2%98%E3%80%82%E5%A4%9A%E9%A1%B9%E9%80%89%E6%8B%A9%E9%A2%98%E5%88%99%E5%88%A9%E7%94%A8%E4%BA%86%E6%89%80%E6%9C%89%E6%95%B0%E6%8D%AE%E3%80%82">https://clevrer.csail.mit.edu/）：对于单项选择题，只使用了与颜色/材料/形状有关的问题。多项选择题则利用了所有数据。</a></li>
<li>WebVid（<a target="_blank" rel="noopener" href="https://maxbain.com/webvid-dataset/%EF%BC%89%EF%BC%9A%E9%80%89%E6%8B%A9%E9%9D%9E%E9%87%8D%E5%8F%A0%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E5%AD%97%E5%B9%95%E5%92%8CQA%E3%80%82">https://maxbain.com/webvid-dataset/）：选择非重叠数据进行字幕和QA。</a></li>
<li>YouCook2（<a target="_blank" rel="noopener" href="https://youcook2.eecs.umich.edu/%EF%BC%89%EF%BC%9A%E6%A0%B9%E6%8D%AE%E5%AE%98%E6%96%B9%E7%9A%84%E5%AF%86%E9%9B%86caption%EF%BC%8C%E5%8E%9F%E5%A7%8B%E8%A7%86%E9%A2%91%E8%A2%AB%E6%88%AA%E6%96%AD%E3%80%82">https://youcook2.eecs.umich.edu/）：根据官方的密集caption，原始视频被截断。</a></li>
<li>TextVR（[callsys/TextVR: <a target="_blank" rel="noopener" href="https://github.com/callsys/textvr">PR 2024] A large Cross-Modal Video Retrieval Dataset with Reading Comprehension</a>）：所有数据均未经修改。</li>
<li>TGIF（<a target="_blank" rel="noopener" href="https://github.com/YunseokJANG/tgif-qa">YunseokJANG/tgif-qa: Repository for our CVPR 2017 and IJCV: TGIF-QA</a>）：只使用了TGIF${frame}$和TGIF${Transition}$子集。</li>
<li>EgoQA（<a target="_blank" rel="noopener" href="https://ego4d-data.org/">Egocentric 4D Perception (EGO4D)</a>）：一些以自我为中心的QA是从Ego4D数据中生成的。</li>
</ul>
<p>对于所有数据集，任务指令都是使用GPT-4自动生成的。</p>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><h3 id="conda配置"><a href="#conda配置" class="headerlink" title="conda配置"></a>conda配置</h3><ul>
<li>git clone拷贝远程仓库超时：设置全局代理，clash打开允许局域网接入。注意代理ip是本机电脑ip，不是服务器ip。</li>
</ul>
<p><strong>准备训练环境：</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">conda create <span class="token parameter variable">-n</span> videochat2 <span class="token assign-left variable">python</span><span class="token operator">=</span><span class="token number">3.9</span>
conda activate videochat2
pip <span class="token function">install</span> <span class="token parameter variable">-r</span> requirements.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<ul>
<li><p><strong>注意这里pip install可能是系统的pip，而不是环境的pip，会导致当前虚拟环境并没有相应依赖</strong>：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_44856695/article/details/131378398">如何在conda环境中正确地使用pip_在conda构建的虚拟环境下可以进行pip操作吗-CSDN博客</a></p>
</li>
<li><p>CondaHTTPError: HTTP 000 CONNECTION FAILED</p>
<ul>
<li>conda换清华源：</li>
</ul>
</li>
</ul>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">conda config <span class="token parameter variable">--add</span> channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/
conda config <span class="token parameter variable">--add</span> channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda config <span class="token parameter variable">--add</span> channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
conda config <span class="token parameter variable">--append</span> channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/fastai/
conda config <span class="token parameter variable">--append</span> channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/
conda config <span class="token parameter variable">--append</span> channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/
 
conda config <span class="token parameter variable">--set</span> show_channel_urls <span class="token function">yes</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<ul>
<li><p>修改conda配置信息：<code>vim ~/.condarc</code>，<strong>删除 - defaults（重要！！）</strong> 增加 ssl_verify: false。保存后重新创建环境</p>
</li>
<li><p>ModuleNotFoundError: No module named ‘torch’</p>
<ul>
<li>离线下载对应版本：<a target="_blank" rel="noopener" href="https://download.pytorch.org/whl/torchvision/">download.pytorch.org/whl/torchvision/</a></li>
</ul>
</li>
</ul>
<h3 id="阶段1训练"><a href="#阶段1训练" class="headerlink" title="阶段1训练"></a>阶段1训练</h3><p> Download <a target="_blank" rel="noopener" href="https://huggingface.co/OpenGVLab/videochat2/resolve/main/l16_25m.pth">UMT-L/16</a> model and set <code>pretrained</code> in <a target="_blank" rel="noopener" href="https://github.com/wolf-ll/Ask-Anything/blob/main/video_chat2/scripts/videochat_vicuna/config_7b_stage1.py">stage1_config</a></p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">bash</span> scripts/videochat_vicuna/run_7b_stage1.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<ul>
<li><p>AttributeError: module ‘numpy’ has no attribute ‘float’.</p>
<ul>
<li>重新安装<code>numpy</code>。出现这个问题是因为np.float从1.24起被删除。所用的代码是依赖于旧版本的Numpy。您可以将你的Numpy版本降级到1.23.5.</li>
</ul>
</li>
</ul>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">conda <span class="token function">install</span> <span class="token assign-left variable">numpy</span><span class="token operator">==</span><span class="token number">1.23</span>.5<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<ul>
<li><p>linux环境下 python import不了自定义的包，即无法找到项目路径。</p>
<ul>
<li>手动导入项目根路径：</li>
</ul>
</li>
</ul>
 <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> sys <span class="token punctuation">,</span> os
base_dir <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span>base_dir<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<ul>
<li><strong>衍生报错：</strong>Traceback (most recent call last):  File “/home/bailey/Code/wyf/Ask-Anything/video_chat2/tasks/train_qformer.py”, line 298, in &lt;module&gt;。。。 File “/home/bailey/Code/wyf/Ask-Anything/video_chat2/utils/config_utils.py”, line 180, in setup_main    Config.dump(config, os.path.join(config.output_dir, “config.json”))。。。。**TypeError: Object of type module is not JSON serializable Traceback (most recent call last):**。。。<ul>
<li>本质是<strong>在<code>config</code>对象当中包含了对 Python 模块对象的引用，而这些引用与正在执行的操作（JSON 序列化和深拷贝）不兼容。</strong>因此需要<strong>去掉config对象中的sys和os这两个key对应的元素</strong>（这俩key的value都是module）</li>
</ul>
</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">filter_module_refs</span><span class="token punctuation">(</span>obj<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>obj<span class="token punctuation">,</span> <span class="token builtin">dict</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 对于字典类型，遍历每个键值对，对值进行递归处理</span>
        <span class="token keyword">return</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> filter_module_refs<span class="token punctuation">(</span>v<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> obj<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>v<span class="token punctuation">,</span> types<span class="token punctuation">.</span>ModuleType<span class="token punctuation">)</span><span class="token punctuation">}</span>
    <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>obj<span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 对于列表类型，遍历每个元素，对元素进行递归处理</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span>filter_module_refs<span class="token punctuation">(</span>element<span class="token punctuation">)</span> <span class="token keyword">for</span> element <span class="token keyword">in</span> obj <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>element<span class="token punctuation">,</span> types<span class="token punctuation">.</span>ModuleType<span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token comment"># 如果不是字典也不是列表，直接返回该元素（非模块类型的都返回）</span>
        <span class="token keyword">return</span> obj <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>obj<span class="token punctuation">,</span> types<span class="token punctuation">.</span>ModuleType<span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token boolean">None</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<ul>
<li><p><strong>衍生报错</strong>：在train_former197行set up model内部进行deepcopy时，报错 y[deepcopy(key, memo)] = deepcopy(value, memo)<br>  File “/home/bailey/anaconda3/envs/videochat2/lib/python3.9/copy.py”, line 161, in deepcopy<br>rv = reductor(4)<br>TypeError: <strong>cannot pickle ‘module’ object</strong>。。。</p>
<ul>
<li>本质还是因为python 试图序列化一个模块对象，但模块对象是不可序列化的。</li>
<li>解决思路：在train_former.py下改了很多次config对象都没有用，最后在utils/config_utils.py的<strong>Config.dump()前去掉config对象中的模块对象</strong>就解决了。</li>
<li>且这样改了以后，Found module object under key的提示会出现两次，也就是两个子线程分别去掉了模块对象，之后才在主线程中dump</li>
</ul>
</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 这个判断module object的操作放在判断main进程前面</span>
   <span class="token keyword">for</span> key<span class="token punctuation">,</span> value <span class="token keyword">in</span> config<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
       <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>value<span class="token punctuation">,</span> types<span class="token punctuation">.</span>ModuleType<span class="token punctuation">)</span><span class="token punctuation">:</span>
           <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Found module object under key: </span><span class="token interpolation"><span class="token punctuation">{</span>key<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
           config<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span>

   <span class="token keyword">if</span> is_main_process<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
       setup_output_dir<span class="token punctuation">(</span>config<span class="token punctuation">.</span>output_dir<span class="token punctuation">,</span> excludes<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"code"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
       setup_logger<span class="token punctuation">(</span>output<span class="token operator">=</span>config<span class="token punctuation">.</span>output_dir<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"vindlu"</span><span class="token punctuation">)</span>
       <span class="token comment"># logger.info(f"config: {Config.pretty_text(config)}")</span>
       Config<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>config<span class="token punctuation">,</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>config<span class="token punctuation">.</span>output_dir<span class="token punctuation">,</span> <span class="token string">"config.json"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
   <span class="token keyword">return</span> config<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<ul>
<li><p>apt-get install报错文件尺寸不符：apt-get换国内镜像源</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_40765537/article/details/105936653">Ubuntu中apt-get命令以及修改apt-get镜像源-CSDN博客</a></li>
</ul>
</li>
<li><p>libcusparse.so.11: cannot open shared object file: No such file or dir报错：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_42727728/article/details/123857908">【最快解决方案】安装torch-geometric报错 libcusparse.so.11: cannot open shared object file: No such file or dir_oserror: libcusparse.so.11: cannot open shared obj-CSDN博客</a></p>
<ul>
<li>先<code>locate libcusparse.so.11</code>找一下服务器有没有对应文件，有的话直接复制到这个博客中说的路径下（发现bailey机器上libcusparse.so.11只有20kb，有一个libcusparse.so.11.7.4.91文件200+mb，把这俩一起复制过去也不行，最后用的llama项目虚拟环境下200+m的后缀11的文件替换就行了</li>
</ul>
</li>
<li><p>Failed to load image Python extension: libtorch_cuda_cu.so</p>
<ul>
<li>pytorch和torchvision的版本问题</li>
</ul>
</li>
<li><p><strong>ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 3938937) of binary:</strong> </p>
<ul>
<li>本来以为是PyTorch 的 CUDA 版本与系统上的 CUDA 版本不兼容的问题。从原来的<code>torch==1.13.1+cu117</code>换成<code>torch==1.12.0+cu113</code>，但问题依然存在。（系统cuda为11.5）</li>
</ul>
</li>
</ul>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> <span class="token assign-left variable">torch</span><span class="token operator">==</span><span class="token number">1.12</span>.0+cu113 <span class="token assign-left variable">torchvision</span><span class="token operator">==</span><span class="token number">0.13</span>.0+cu113 <span class="token assign-left variable">torchaudio</span><span class="token operator">==</span><span class="token number">0.12</span>.0 --extra-index-url https://download.pytorch.org/whl/cu113<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<ul>
<li>而且torch降低为1.12以后，与peft冲突（peft 0.4.0 requires torch&gt;=1.13.0），且bitsandbytes和cuda版本又会不匹配</li>
<li>最后torch又装回1.13.1了，cuda11.7（各种版本下载对应：<a target="_blank" rel="noopener" href="https://pytorch.org/get-started/previous-versions/">Previous PyTorch Versions | PyTorch</a>）</li>
</ul>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> <span class="token assign-left variable">torch</span><span class="token operator">==</span><span class="token number">1.13</span>.1+cu117 <span class="token assign-left variable">torchvision</span><span class="token operator">==</span><span class="token number">0.14</span>.1+cu117 <span class="token assign-left variable">torchaudio</span><span class="token operator">==</span><span class="token number">0.13</span>.1 --extra-index-url https://download.pytorch.org/whl/cu117<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<ul>
<li>wandb：命令行输入<code>wandb login</code>在官网登录，并将api key复制回命令行</li>
</ul>
<h4 id="bert相关"><a href="#bert相关" class="headerlink" title="bert相关"></a>bert相关</h4><ul>
<li><p>在shared_utils_qformer中setup_model时，BertTokenizer.from_pretrained(config.model.text_encoder.pretrained, local_files_only=True)报错   <strong>OSError: Can’t load tokenizer for ‘bert-base-uncased’.</strong> If you were trying to load it from ‘<a target="_blank" rel="noopener" href="https://huggingface.co/models">https://huggingface.co/models</a>‘, make sure you don’t have a local directory with the same name. Otherwise, make sure ‘bert-base-uncased’ is the correct path to a directory containing all relevant files for a BertTokenizer tokenizer.</p>
<ul>
<li><p>原因：主机<strong>或服务器</strong>不能访问<a target="_blank" rel="noopener" href="https://huggingface.co/%E9%A1%B5%E9%9D%A2%EF%BC%8C%E5%9B%A0%E6%AD%A4%E4%B8%8D%E8%83%BD%E4%B8%8B%E8%BD%BD%E7%9B%B8%E5%BA%94%E7%9A%84%E6%9D%83%E9%87%8D%E3%80%82%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%EF%BC%9A%E6%89%8B%E5%8A%A8%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E5%88%B0%E6%9C%AC%E5%9C%B0%E3%80%82">https://huggingface.co/页面，因此不能下载相应的权重。解决方法：手动下载文件到本地。</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_47187147/article/details/140004137">OSError: Can‘t load tokenizer for ‘bert-base-uncased‘. If you were trying to load it from_oserror: can’t load tokenizer for ‘bert-base-uncas-CSDN博客</a></p>
</li>
<li><p>下载后放到tasks/bert-base-uncased路径，修改configs/model.py</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">TextEncoders<span class="token punctuation">[</span><span class="token string">"bert"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>
    name<span class="token operator">=</span><span class="token string">"bert_base"</span><span class="token punctuation">,</span>
    pretrained<span class="token operator">=</span><span class="token string">"/home/…………/tasks/bert-base-uncased/"</span><span class="token punctuation">,</span>
    ………………<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
</ul>
</li>
<li><p>**’BertTokenizer’ object has no attribute ‘vocab’**：修改models/bert/tokenization_bert.py文件，将self.vocab = load_vocab(vocab_file)从init方法后移到前面去（参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/bitttiolkk/article/details/136612497">Debug：AttributeError: ‘BertTokenizer‘ object has no attribute ‘vocab‘_attributeerror: ‘berttokenizer’ object has no attr-CSDN博客</a>）</p>
</li>
<li><p>OSError: We couldn’t connect to ‘<a target="_blank" rel="noopener" href="https://huggingface.co/">https://huggingface.co</a>‘ to load this file, couldn’t find it in the cached files and it looks like bert-base-uncased is not the path to a directory containing a file named config.json.</p>
</li>
</ul>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20250103205905009.png" alt="image-20250103205905009" style="zoom:67%;">

<blockquote>
<p>使用 .from_pretrained(“xxxxx”)方法加载，本地加载bert需要修改两个地方，一是tokenizer部分，二是model部分：<br>step1、导包： from transformers import BertModel，BertTokenizer<br>step2、载入词表： tokenizer = BertTokenizer.from_pretrained(“./bert_localpath/“) 这里要注意！！除了你自己建的文件夹名外，后面一定要加个/，才能保证该方法找到咱的vocab.txt<br>step3、载入模型： bert = BertModel.from_pretrained(“./bert_localpath”) 然后，这个地方又不需要加上/</p>
</blockquote>
<h4 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h4><p><a target="_blank" rel="noopener" href="https://github.com/salesforce/LAVIS/blob/main/lavis/datasets/download_scripts/DownloadConceptualCaptions/download_data_cc3m.py">LAVIS/lavis/datasets/download_scripts/DownloadConceptualCaptions/download_data_cc3m.py at main · salesforce/LAVIS</a></p>
<p>—- 最好别用这个下，开了多线程电脑会卡，内存可能不够</p>
<p><a target="_blank" rel="noopener" href="https://opensource.salesforce.com/LAVIS//latest/getting_started.html#auto-downloading-and-loading-datasets">Dataset Zoo — LAVIS documentation</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/rom1504/img2dataset/blob/main/dataset_examples/cc3m.md">img2dataset/dataset_examples/cc3m.md at main · rom1504/img2dataset</a></p>
<h4 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h4><p>dataset/init.py</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_media_type</span><span class="token punctuation">(</span>dataset_config<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset_config<span class="token punctuation">)</span> <span class="token operator">&gt;=</span> <span class="token number">3</span> <span class="token keyword">and</span> dataset_config<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"video"</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token string">"video"</span>	<span class="token comment"># 视频数据集，由标注+源数据+类型标记video构成</span>
    <span class="token keyword">elif</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset_config<span class="token punctuation">)</span> <span class="token operator">&gt;=</span> <span class="token number">3</span> <span class="token keyword">and</span> dataset_config<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"text"</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token string">"text"</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token string">"image"</span>	<span class="token comment"># 图像数据，list里只有标注+源数据</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>dataset config.json</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token property">"train_file"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token punctuation">[</span>
      <span class="token string">"annotation/anno_pretrain/webvid_10m_train.json"</span><span class="token punctuation">,</span>
      <span class="token string">"annotation/videos_images/webvid_10m"</span><span class="token punctuation">,</span>
      <span class="token string">"video"</span>	
    <span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span>
      <span class="token string">"annotation/anno_pretrain/cc3m_train.json"</span><span class="token punctuation">,</span>
      <span class="token string">"annotation/videos_images/cc3m"</span>
    <span class="token punctuation">]</span>
  <span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token property">"test_file"</span><span class="token operator">:</span> <span class="token punctuation">{</span>
    <span class="token property">"msrvtt_1k_test"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
      <span class="token string">"annotation/anno_pretrain/msrvtt_test1k.json"</span><span class="token punctuation">,</span>
      <span class="token string">"annotation/videos_images/MSRVTT_Videos"</span><span class="token punctuation">,</span>
      <span class="token string">"video"</span>
    <span class="token punctuation">]</span>
  <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token property">"test_types"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token string">"msrvtt_1k_test"</span>
  <span class="token punctuation">]</span><span class="token punctuation">,</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>pt_dataset.py</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">PTImgTrainDataset</span><span class="token punctuation">(</span>ImageVideoBaseDataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    media_type <span class="token operator">=</span> <span class="token string">"image"</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> ann_file<span class="token punctuation">,</span> transform<span class="token punctuation">,</span> pre_text<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>ann_file<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">3</span> <span class="token keyword">and</span> ann_file<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"video"</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>media_type <span class="token operator">=</span> <span class="token string">"video"</span>  
            self<span class="token punctuation">.</span>media_name <span class="token operator">=</span> <span class="token string">"key"</span>		<span class="token comment"># 自己做的数据集，json文件里面对应图名称的是key</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>media_type <span class="token operator">=</span> <span class="token string">"image"</span>
            self<span class="token punctuation">.</span>media_name <span class="token operator">=</span> <span class="token string">"key"</span>
        self<span class="token punctuation">.</span>label_file<span class="token punctuation">,</span> self<span class="token punctuation">.</span>data_root <span class="token operator">=</span> ann_file<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span>
        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"=========label file : </span><span class="token interpolation"><span class="token punctuation">{</span>self<span class="token punctuation">.</span>label_file<span class="token punctuation">}</span></span><span class="token string">, data root : </span><span class="token interpolation"><span class="token punctuation">{</span>self<span class="token punctuation">.</span>data_root<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        <span class="token comment"># 对于第一阶段训练， =========label file : annotation/anno_pretrain/cc3m_train.json, data root : annotation/videos_images/cc3m     =========label file : annotation/anno_pretrain/webvid_10m_train.json, data root : annotation/videos_images/webvid_10m</span>

        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">'Load json file'</span><span class="token punctuation">)</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>label_file<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>anno <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>num_examples <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>anno<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>transform <span class="token operator">=</span> transform
        self<span class="token punctuation">.</span>pre_text <span class="token operator">=</span> pre_text
        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Pre-process text: </span><span class="token interpolation"><span class="token punctuation">{</span>pre_text<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">get_anno</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>	<span class="token comment"># 针对自己做的数据集做一些特定处理</span>
        <span class="token keyword">if</span> <span class="token string">"cc3m"</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>label_file<span class="token punctuation">:</span>
            filename <span class="token operator">=</span> self<span class="token punctuation">.</span>anno<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>media_name<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">".jpg"</span>
        <span class="token keyword">elif</span> <span class="token string">"webvid"</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>label_file<span class="token punctuation">:</span>
            filename <span class="token operator">=</span> self<span class="token punctuation">.</span>anno<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>media_name<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">".mp4"</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            filename <span class="token operator">=</span> self<span class="token punctuation">.</span>anno<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>media_name<span class="token punctuation">]</span>
        caption <span class="token operator">=</span> self<span class="token punctuation">.</span>anno<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"caption"</span><span class="token punctuation">]</span>
        anno <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"image"</span><span class="token punctuation">:</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>data_root<span class="token punctuation">,</span> filename<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"caption"</span><span class="token punctuation">:</span> caption<span class="token punctuation">}</span>
        <span class="token keyword">return</span> anno<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>evaluate text-encoder修改（原来是None）：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># tasks/retrieval_utils</span>
text_encoder <span class="token operator">=</span> model<span class="token punctuation">.</span>get_text_encoder<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># models/videochat2_qformer.py</span>
<span class="token keyword">def</span> <span class="token function">get_text_encoder</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> build_bert<span class="token punctuation">(</span>self<span class="token punctuation">.</span>config<span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token comment"># models/bert/builder.py</span>
<span class="token keyword">def</span> <span class="token function">build_bert</span><span class="token punctuation">(</span>model_config<span class="token punctuation">,</span> pretrain<span class="token punctuation">,</span> checkpoint<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""build text encoder.

    Args:
        model_config (dict): model config.
        pretrain (bool): Whether to do pretrain or finetuning.
        checkpoint (bool): whether to do gradient_checkpointing.

    Returns: TODO

    """</span>
    bert_config <span class="token operator">=</span> BertConfig<span class="token punctuation">.</span>from_json_file<span class="token punctuation">(</span>model_config<span class="token punctuation">.</span>text_encoder<span class="token punctuation">.</span>config<span class="token punctuation">)</span>
    bert_config<span class="token punctuation">.</span>encoder_width <span class="token operator">=</span> model_config<span class="token punctuation">.</span>vision_encoder<span class="token punctuation">.</span>d_model
    bert_config<span class="token punctuation">.</span>gradient_checkpointing <span class="token operator">=</span> checkpoint
    bert_config<span class="token punctuation">.</span>fusion_layer <span class="token operator">=</span> model_config<span class="token punctuation">.</span>text_encoder<span class="token punctuation">.</span>fusion_layer

    <span class="token keyword">if</span> <span class="token keyword">not</span> model_config<span class="token punctuation">.</span>multimodal<span class="token punctuation">.</span>enable<span class="token punctuation">:</span>
        bert_config<span class="token punctuation">.</span>fusion_layer <span class="token operator">=</span> bert_config<span class="token punctuation">.</span>num_hidden_layers

    <span class="token keyword">if</span> pretrain<span class="token punctuation">:</span>
        text_encoder<span class="token punctuation">,</span> loading_info <span class="token operator">=</span> BertForMaskedLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
            model_config<span class="token punctuation">.</span>text_encoder<span class="token punctuation">.</span>pretrained<span class="token punctuation">,</span>
            config<span class="token operator">=</span>bert_config<span class="token punctuation">,</span>
            output_loading_info<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        text_encoder<span class="token punctuation">,</span> loading_info <span class="token operator">=</span> BertModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
            model_config<span class="token punctuation">.</span>text_encoder<span class="token punctuation">.</span>pretrained<span class="token punctuation">,</span>
            config<span class="token operator">=</span>bert_config<span class="token punctuation">,</span>
            add_pooling_layer<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
            output_loading_info<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">return</span> text_encoder
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h5 id="张量设备"><a href="#张量设备" class="headerlink" title="张量设备"></a>张量设备</h5><p><strong>训练时</strong></p>
<p>output = text_encoder( …………)  执行这个操作时报错  Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:1! (when checking argument for argument mat1 in method wrapper_addmm)</p>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20250105172608783.png" alt="image-20250105172608783" style="zoom: 50%;">

<p><strong>evaluate时</strong></p>
<p>RuntimeError: indices should be either on cpu or on the same device as the indexed tensor (cpu)</p>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20250106130038364.png" alt="image-20250106130038364" style="zoom:50%;">

<h5 id="数据维度"><a href="#数据维度" class="headerlink" title="数据维度"></a>数据维度</h5><p>clip计算相似分数时报错：</p>
<pre class="line-numbers language-cmd" data-language="cmd"><code class="language-cmd">
Traceback (most recent call last):
  File "/home/bailey/Code/wyf/Ask-Anything/video_chat2/tasks/train_qformer.py", line 302, in &lt;module&gt;
    main(cfg)
  File "/home/bailey/Code/wyf/Ask-Anything/video_chat2/tasks/train_qformer.py", line 232, in main
    res = evaluation_wrapper(
  File "/home/bailey/anaconda3/envs/videochat2/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/bailey/Code/wyf/Ask-Anything/video_chat2/tasks/retrieval_utils.py", line 75, in evaluation_wrapper
    i2t_x, t2i_x, i2t_emb, t2i_emb = evaluation(
  File "/home/bailey/anaconda3/envs/videochat2/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/bailey/Code/wyf/Ask-Anything/video_chat2/tasks/retrieval_utils.py", line 258, in evaluation
    score = model.itm_head(itm_embeds)[:, 1]
  File "/home/bailey/anaconda3/envs/videochat2/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/bailey/anaconda3/envs/videochat2/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (128x768 and 1536x2)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>具体来说，**<code>itm_embeds</code>** 的形状为 <code>(128, 768)</code>，而 <strong><code>itm_head</code></strong> 的权重矩阵的形状为 <code>(1536, 2)</code>，这两者的维度不匹配，无法进行矩阵乘法。</p>
<p>在videochat2_qformer里面可以看到，配置vtm_cat_text_cls=true，会使得矩阵形状变成2倍。因此在配置文件里把这个改成false即可。</p>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20250106002754122.png" alt="image-20250106002754122" style="zoom:50%;">

<h4 id="阶段一训练结果"><a href="#阶段一训练结果" class="headerlink" title="阶段一训练结果"></a>阶段一训练结果</h4><p>原始数据量：（本机路径D:\AMLLM-Video\annotation）</p>
<ul>
<li><p>图像cc3m  20184张</p>
</li>
<li><p>视频MSRVTT 10000个</p>
</li>
<li><p>视频webvid  1809个</p>
</li>
</ul>
<p>训练用cc3m和webvid，测试用了MSRVTT中的1000条数据。</p>
<img src="/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/image-20250106150125960.png" alt="image-20250106150125960" style="zoom:67%;">

<h3 id="阶段2训练"><a href="#阶段2训练" class="headerlink" title="阶段2训练"></a>阶段2训练</h3><p>新增数据集InternVID，见MLLM-Code。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/yang_daxia/article/details/139950072">论文阅读MVBench: A Comprehensive Multi-modal Video Understanding Benchmark-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/669658267">CVPR2024 Highlight] MVBench多模态视频理解能力的全面评测 - 知乎</a></p>
<p>代码： <a target="_blank" rel="noopener" href="https://github.com/OpenGVLab/Ask-Anything/tree/main/video_chat2">Ask-Anything/video_chat2 at main · OpenGVLab/Ask-Anything</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/260034241">『技术随手学』解决CondaHTTPError: HTTP 000 CONNECTION 问题 - 知乎</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/kekechengxiao/article/details/134491661">import torchModuleNotFoundError: No module named ‘torch‘_import torch 找不到模块-CSDN博客</a></p>
<p>conda中使用pip的问题：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_44856695/article/details/131378398">如何在conda环境中正确地使用pip_在conda构建的虚拟环境下可以进行pip操作吗-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/get-started/previous-versions/">Previous PyTorch Versions | PyTorch</a></p>
<p>wandb使用：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_40507857/article/details/112791111">wandb: 深度学习轻量级可视化工具入门教程_wandb教程-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_42730750/article/details/119249193">Pycharm远程连接服务器进行代码的运行与调试_remote sdk is saved in idesetting-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_47187147/article/details/140004137">OSError: Can‘t load tokenizer for ‘bert-base-uncased‘. If you were trying to load it from_oserror: can’t load tokenizer for ‘bert-base-uncas-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/google-bert/bert-base-uncased/tree/main">google-bert/bert-base-uncased at main</a></p>
<p>[<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_57972634/article/details/143758599">实验日志·已解决] 如何下载 + 加载本地的BERT预训练模型 （OSError: Can‘t load tokenizer for ‘bert-base-uncased‘.）_本地加载bert-base包-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_56438555/article/details/144110166">（超全方法）尝试解决问题：torch.cuda.OutOfMemoryError: CUDA out of memory._torch.outofmemoryerror: cuda out of memory.-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41185868/article/details/137062748">LLMs之Mistral：Mistral 7B v0.2的简介、安装和使用方法、案例应用之详细攻略_mistral-7b-instruct-v0.2-CSDN博客</a></p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">wolf-ll</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://wolf-ll.github.io/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/">http://wolf-ll.github.io/2024/11/12/mvbench-a-comprehensive-multi-modal-video-understanding-benchmark/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">wolf-ll</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/MLLM/">
                                    <span class="chip bg-color">MLLM</span>
                                </a>
                            
                                <a href="/tags/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                                    <span class="chip bg-color">视频理解</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    
    <div class="card" data-aos="fade-up">
    <div id="utteranc-container" class="card-content">
        <script src="https://utteranc.es/client.js"
                repo="wolf-ll/comments"
                issue-term="pathname"
                theme="github-light"
                crossorigin="anonymous"
                async>
        </script>
    </div>
</div>
    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2024/11/18/vue/">
                    <div class="card-image">
                        
                        <img src="/medias/featureimages/16.jpg" class="responsive-img" alt="Vue">
                        
                        <span class="card-title">Vue</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            前端三件套+Vue简要笔记整理
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-11-18
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%89%8D%E7%AB%AF/" class="post-category">
                                    前端
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%A1%86%E6%9E%B6/">
                        <span class="chip bg-color">框架</span>
                    </a>
                    
                    <a href="/tags/%E5%89%8D%E7%AB%AF/">
                        <span class="chip bg-color">前端</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2024/10/13/timechat-a-time-sensitive-multimodal-large-language-model/">
                    <div class="card-image">
                        
                        <img src="/medias/featureimages/10.jpg" class="responsive-img" alt="TimeChat">
                        
                        <span class="card-title">TimeChat</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            基于视频滑窗Q-Former的时序感知的视频大模型
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-10-13
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E8%AE%BA%E6%96%87/" class="post-category">
                                    论文
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/MLLM/">
                        <span class="chip bg-color">MLLM</span>
                    </a>
                    
                    <a href="/tags/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                        <span class="chip bg-color">视频理解</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <span id="year">2024</span>
            <a href="/about" target="_blank">wolf-ll</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">297.7k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2024";
                    var startMonth = "4";
                    var startDate = "21";
                    var startHour = "16";
                    var startMinute = "35";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/wolf-ll" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:837691088@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=837691088" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 837691088" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>





    <a href="https://www.zhihu.com/people/zhi-qi-wei-tuo" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/zhi-qi-wei-tuo" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

	
    

    

    
    <script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async="async"></script>
    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
