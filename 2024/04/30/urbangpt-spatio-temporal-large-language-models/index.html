<!DOCTYPE HTML>
<html lang="zh-CN">
 <!--自定义看板娘-->
  <script src="https://cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script>
  <script src="/live2d-widget/autoload.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"/>


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="UrbanGPT: Spatio-Temporal Large Language Models, 后端开发">
    <meta name="description" content="Java | LeetCode | Algorithm">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>UrbanGPT: Spatio-Temporal Large Language Models | wolf-ll&#39;s blog</title>
    <link rel="icon" type="image/png" href="/medias/logo.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: #FFF;
        text-align: center;
        /* loaderҳ����ʧ���ý����ķ�ʽ*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid #49b1f5;
        border-right-color: transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid #49b1f5;
        border-right-color: transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: #49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: #2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo���ֶ��� */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ʹ�ý����ķ�������loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },1000); 
        },1000);//ǿ����ʾloading page 1s  
    };
    loaded();
})()
 </script><meta name="generator" content="Hexo 7.2.0"><link rel="alternate" href="/atom.xml" title="wolf-ll's blog" type="application/atom+xml">

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>





 <div id="loading-container">
     <p class="loading-text"></p> 
     <div class="loading-image">
         <div></div>
         <div></div>
         <div></div>
         <div></div> 
         <div></div>
     </div>
 </div><body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">wolf-ll&#39;s blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">wolf-ll&#39;s blog</div>
        <div class="logo-desc">
            
            Java | LeetCode | Algorithm
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/wolf-ll/wolf-ll.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/wolf-ll/wolf-ll.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/1.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">UrbanGPT: Spatio-Temporal Large Language Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/LLM/">
                                <span class="chip bg-color">LLM</span>
                            </a>
                        
                            <a href="/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/">
                                <span class="chip bg-color">时间序列</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E8%AE%BA%E6%96%87/" class="post-category">
                                论文
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-04-30
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2024-05-15
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    14k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    53 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="UrbanGPT-Spatio-Temporal-Large-Language-Models"><a href="#UrbanGPT-Spatio-Temporal-Large-Language-Models" class="headerlink" title="UrbanGPT: Spatio-Temporal Large Language Models"></a>UrbanGPT: Spatio-Temporal Large Language Models</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p><strong>时空预测旨在对不断变化的动态城市场景进行预测和洞察，涵盖了时间和空间两个维度。</strong>它的目的是预测城市生活的不同方面的未来模式、趋势和事件，包括交通运输、人口流动和犯罪率等。尽管大量研究都致力于开发神经网络技术来准确预测时空数据，但需要注意的是，<strong>许多方法严重依赖于有足够的标记数据来生成精确的时空表示</strong>。不幸的是，<strong>数据稀缺</strong>的问题在实际的城市感知场景中是普遍存在的。在某些情况下，从下游场景中收集任何标记数据变得具有挑战性，这进一步加剧了问题。因此，有必要建立一个时空模型，能够在不同的时空学习场景中表现出强大的泛化能力。</p>
<p>受大语言模型（LLMs）的显著成就的启发，我们的目标是<strong>创建一个时空LLM，能够在广泛的下游城市任务中表现出特殊的泛化能力。</strong>为了实现这一目标，我们提出了UrbanGPT，它无缝地<strong>集成了一个时空依赖编码器与指令微调范式</strong>。这种集成使llm能够理解复杂的时间和空间相互依赖，促进在数据稀缺下进行更全面和准确的预测。为了验证我们的方法的有效性，我们在各种公共数据集上进行了广泛的实验，包括不同的时空预测任务。结果一致表明，我们的UrbanGPT，以其精心设计的架构，始终优于最先进的基准模型。这些发现突出了为时空学习建立大型语言模型的潜力，特别是在标记数据稀缺的零样本场景中。</p>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>时空预测的动机源于对准确预测和获取城市环境动态本质的渴望。通过对时间和空间上不断变化的动态进行分析和理解，时空预测使我们能够预测未来城市生活各个方面的模式、趋势以及各种事件。这在城市计算领域至关重要，因为预测交通模式可以优化交通流量、减少拥堵，增强整体城市流动性[17,30]。此外，预测人口流动有助于有效的城市规划和资源分配[6,19]。再者，预测犯罪的能力可以极大地提高公共安全[31]。时空预测在塑造更智能、更高效的城市方面扮演着关键角色，最终提升城市生活质量。</p>
<p>在时空预测领域常用的各种神经网络架构是十分重要的。这些架构旨在捕捉和建模数据中空间和时间维度之间复杂的关系。其中一种广泛采用的架构是卷积神经网络（CNN）[14, 38, 44]，它通过对输入数据应用卷积滤波器，可以有效地提取空间特征。另一类时空神经网络是循环神经网络（RNN）系列[1, 33, 42]。这些时空RNN非常适合通过维护一个可以随时间保留信息的记忆状态来实现时间依赖关系的捕捉。最近，图神经网络（GNNs）在时空预测中的应用急剧增加[35, 39, 46]。<strong>GNNs在建模数据中的复杂空间关系方面表现出色，其中每个节点对应一个空间位置，边捕捉它们之间的连接关系。</strong></p>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p><strong>挑战1：标注数据稀缺，数据无法迁移到新场景，重新训练开销巨大</strong>：虽然时空神经网络技术已被证明非常有效，但它们严重依赖于大量标记数据以生成准确的预测。实际城市场景中普遍存在数据稀缺问题，例如，由于成本高昂，在整个城市空间部署传感器来监控全市交通量或空气质量是不切实际的。此外，<strong>现有模型在应对新地区或城市预测任务时不具备良好的泛化能力，需重新训练以生成时空表征。</strong></p>
<p><strong>挑战2：LLMs和现有时空模型缺乏零样本场景下的泛化能力：</strong>如图1所示，大语言模型LLaMA可根据输入文本对流量模式进行推断。然而，它在处理具有复杂时空依赖性的<strong>数字时间序列数</strong>据方面的局限性有时会导致相反的预测结果。另一方面，预训练的基线模型能够很好地编码时空依赖关联。然而，<strong>它可能会由于对源数据集的过拟合导致其在零样本场景下表现不佳。</strong></p>
<p><strong>挑战3：如何将LLMs的出色推理能力扩展到时空预测场景</strong>：时空数据的独特特征与LLMs中所编码的知识之间存在差距，如何减少这一差距进而建立在广泛的城市任务中具有出色的泛化能力时空大语言模型是一项重大挑战。</p>
<h3 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h3><p><strong>（1） 据我们所知，这是首次尝试</strong>开发一种能够在不同数据集上预测各种城市现象的时空大语言模型，尤其是在训练样本受限的情况下。</p>
<p><strong>（2）提出了时空预测模型UrbanGPT</strong>：我们提出了UrbanGPT，一种专门针对时空预测而定制的大型语言模型。UrbanGPT的核心是<strong>一种新的时空指令调整范式</strong>，它寻求将时间和空间的复杂依赖关系与llm的知识空间相结合。</p>
<ul>
<li>在我们的UrbanGPT框架中，我们首先合并了一个<strong>时空依赖编码器</strong>，它<strong>利用了一个多层的时间卷积网络以捕捉时间动态。</strong></li>
<li>然后，我们的模型涉及到<strong>对齐文本和时空信息</strong>，以使语言模型能够有效地注入时空上下文信号。这是通过使用一个<strong>轻量级对齐模块</strong>来实现的。其结果是，通过整合来自文本和时空领域的有价值的信息，生成更具表达性的语义表示</li>
<li><strong>通过将时空依赖编码器无缝集成到指令微调范式中，有效地将时空上下文与大语言模型相结合。</strong></li>
</ul>
<p>为了展示我们提出的模型的优越的预测性能，我们将其与大型语言模型（LLaMA- 70B）和时空图神经网络（STGCN）进行了比较。</p>
<ul>
<li>大型语言模型LLaMA可以从输入的文本中有效地推断出流量模式。然而，<strong>它在处理具有复杂时空依赖性的数字-时间序列数据方面具有局限性，有时会导致相反的交通趋势预测。</strong></li>
<li>另一方面，预先训练的基线模型显示了对时空依赖性的强烈理解。然而，<strong>它可能会对源数据集进行过拟合，并且在零样本场景下表现不佳，这表明它对现有时空预测模型的泛化能力有限</strong>。</li>
<li>相比之下，我们提出的模型实现了对特定领域的时空知识和语言建模能力的和谐集成。这使我们能够在数据匮乏的情况下做出更准确和可靠的预测</li>
</ul>
<img src="/2024/04/30/urbangpt-spatio-temporal-large-language-models/image-20240318132230618.png" alt="image-20240318132230618" style="zoom:80%;">

<p>图1：与大型语言模型（LLaMA-70B）和时空图神经网络（STGCN）相比，该模型在零样本交通流预测场景中具有优越的预测性能。</p>
<p><strong>(3) 在现实世界数据上进行的大量实验</strong>证明了本文提出的UrbanGPT在零样本时空学习场景中具有出色的泛化能力。这些发现突显了该模型的强大泛化能力，表明它在准确预测和理解时空模式方面的有效性，即使在零样本场景下也是如此。</p>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h3 id="时空数据-Spatio-Temporal-Data"><a href="#时空数据-Spatio-Temporal-Data" class="headerlink" title="时空数据 Spatio-Temporal Data."></a>时空数据 <strong>Spatio-Temporal Data</strong>.</h3><p><strong>时空数据</strong>可以表示为三维张量<strong>：X∈R^𝑅×𝑇×𝐹</strong>。张量中的每个元素<strong>X𝑟、𝑡、𝑓</strong>都对应于在第𝑟个区域的第𝑡个时间间隔上的第𝑓个特征的值。</p>
<ul>
<li>考虑预测一个城市地区的出租车交通模式。在这种情况下，数据可以表示从𝑡到𝑡−1的给定时间段（例如，30分钟的间隔）内，特定区域（例如，第𝑟个空间区域）内出租车的流入和流出。‘</li>
</ul>
<h3 id="时空预测-Spatio-Temporal-Forecasting"><a href="#时空预测-Spatio-Temporal-Forecasting" class="headerlink" title="时空预测 Spatio-Temporal Forecasting"></a>时空预测 <strong>Spatio-Temporal Forecasting</strong></h3><p><strong>时空预测</strong>：在时空预测任务中，一个常见的场景是利用历史数据来预测未来的趋势。具体来说，其目标是根据从前面的𝐻步骤中获得的信息来预测下一个𝑃时间步长的数据。</p>
<img src="/2024/04/30/urbangpt-spatio-temporal-large-language-models/image-20240318153916911.png" alt="image-20240318153916911">

<p>函数𝑓（·）代表了一个利用历史数据进行有效训练的时空预测模型。时空预测任务主要可分为两大类：</p>
<ul>
<li><strong>回归预测</strong>，包括预测交通流量或出租车需求等连续值；</li>
<li><strong>分类预测</strong>，其目标是分类犯罪发生预测等事件。</li>
</ul>
<p>为了优化函数f，基于时空场景的具体特征使用了不同的损失函数</p>
<h3 id="时空零样本学习-Zero-Shot-Learning"><a href="#时空零样本学习-Zero-Shot-Learning" class="headerlink" title="时空零样本学习 Zero-Shot Learning"></a>时空零样本学习 <strong>Zero-Shot Learning</strong></h3><p>尽管目前的时空学习方法是有效的，但它们在有效地推广到各种下游时空学习场景时经常遇到困难。在本研究中，我们的重点是解决时空零样本场景的挑战，我们的目标是<strong>学习下游时空预测数据集或任务里没见过的数据</strong>。这可以正式定义如下：</p>
<img src="/2024/04/30/urbangpt-spatio-temporal-large-language-models/image-20240318155213668.png">

<p>在这个特殊的场景中，预测函数𝑓ˆ（·）负责预测以前没有遇到过的下游任务的时空数据˜X。需要注意的是，模型𝑓ˆ（·）并不是针对目标数据进行专门训练的。</p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><img src="/2024/04/30/urbangpt-spatio-temporal-large-language-models/image-20240318210558121.png">

<p>图2：所提出的时空语言模型UrbanGPT的总体架构。</p>
<h3 id="时空依赖编码器"><a href="#时空依赖编码器" class="headerlink" title="时空依赖编码器"></a>时空依赖编码器</h3><ul>
<li><p>集成一个包含多层次时间卷积网络（ a multi-level temporal convolutional network.）的时空编码器来增强大型语言模型在时空上下文中捕获时间依赖性的能力。</p>
</li>
<li><p>具体来说，我们的时空编码器由两个关键组件组成：<strong>门控扩散（空洞）卷积层（</strong>a gated dilated convolution layer ）和<strong>多层次关联注入层</strong>（a multi-level correlation injection layer）</p>
<img src="/2024/04/30/urbangpt-spatio-temporal-large-language-models/image-20240318201003133.png">
</li>
<li><p>初始化时空嵌入：Er∈R^T×d。这种嵌入是通过一个线性层来增强原始数据X而获得的。</p>
</li>
<li><p>为了解决梯度消失的问题，我们使用了一个E𝑟切片，表示为Er‘，由扩张的卷积核的大小决定。<strong>该切片用于执行残差操作。</strong></p>
</li>
<li><p>使用<strong>一维扩散卷积核</strong>W¯k，<img src="https://latex.csdn.net/eq?%5Cbar%7B%5Ctextbf%7BW%7D%7D_g%5Cin%5Cmathbb%7BR%7D%5E%7BT_g%5Ctimes%20d_%7Bin%7D%5Ctimes%20d_%7Bout%7D%7D" alt="\bar{\textbf{W}}_g\in\mathbb{R}^{T_g\times d_{in}\times d_{out}}">编码时间关联，相应偏置项bk，bg属于R^dout。Sigmoid激活函数δ用于控制多层卷积运算的信息保留程度。在进行门控时间扩张卷积层编码后，我们能够有效地捕获<strong>多个时间步长中的时间依赖性</strong>，从而生成时间表示。</p>
</li>
<li><p><strong>这些表示包含不同级别的时间依赖关系</strong>，反映了各种具有粒度感知的<strong>时间演化模式</strong>。为了保留这些信息模式，我们引入了一个多层次关联注入层</p>
</li>
</ul>
<img src="/2024/04/30/urbangpt-spatio-temporal-large-language-models/image-20240318202940267.png">

<ul>
<li>其中Ws∈R^Ts×dout×d′out是形如W¯k的卷积核，经过L层编码后，我们<strong>使用一个简单的非线性层融合门控扩散卷积层和多层次关联注入层的结果</strong>，<strong>最终的时空依赖性表征表示为</strong>Ψ~∈R^R×T×d</li>
<li>为了处理下游可能出现的各种城市场景集，本文提出的时空编码器在<strong>建模空间相关性时独立于图结构</strong>。因为在零样本预测环境中，实体之间的空间关系可能是未知的或难以确定的。通过不依赖于显式的图结构，我们的编码器可以有效地处理广泛的城市场景，在这些场景中，空间相关性和依赖性可能会发生变化，或者很难预先定义。这种灵活性使我们的模型能够适应并表现良好，确保其在广泛的城市环境中的适用性。</li>
</ul>
<h3 id="时空指令微调"><a href="#时空指令微调" class="headerlink" title="时空指令微调"></a>时空指令微调</h3><h4 id="时空文本对齐"><a href="#时空文本对齐" class="headerlink" title="时空文本对齐"></a>时空文本对齐</h4><ul>
<li>为了<strong>使语言模型能够有效地理解时空模式，对齐文本信息和时空信息是至关重要的。这种对齐允许融合不同模态，从而产生信息更丰富的表示</strong>。</li>
<li>通过整合来自文本和时空领域的上下文特征，我们可以<strong>捕获互补信息</strong>，提取更具表达力和意义的更高层次的语义表示。为了实现这一目标，我们使用了一个<strong>轻量级的对齐模块来投影时空依赖表示˜Ψ</strong>。这个投影涉及到使用线性层参数W𝑝∈R^𝑑×𝑑𝐿和b𝑝∈R^𝑑𝐿，其中𝑑𝐿表示语言模型（llm）中常用的隐藏维度。</li>
<li>所得到的投影，表示为H∈R^𝑅×𝐹×𝑑𝐿，在指令中使用特殊的标记表示为： <st_start>，<st_his>，…，<st_his>，<st_end>。在这里，<st_start>和<st_end>作为标识时空的开始和结束的标识符。<strong>这些标识符可以通过扩展其词汇量来包含在大语言模型中</strong>。占位符<st_his>表示时空标记，并<strong>对应于隐藏层中的投影H</strong>。通过使用该技术，该模型获得了<strong>识别时空依赖性</strong>的能力，从而提高了其在城市场景中成功执行时空预测任务的熟练程度。</st_his></st_end></st_start></st_end></st_his></st_his></st_start></li>
</ul>
<h4 id="时空提示词（prompt）指令"><a href="#时空提示词（prompt）指令" class="headerlink" title="时空提示词（prompt）指令"></a>时空提示词（prompt）指令</h4><ul>
<li><p>在时空预测的场景中，<strong>时间和空间信息都包含了有价值的语义细节</strong>，有助于模型理解特定上下文的时空模式。例如，清晨和高峰时间段的交通流量有很大的不同，并且商业区和住宅区之间的交通模式也存在差异。因此，<strong>将时间和空间信息表示为提示文本对时空预测任务是有益的</strong>。</p>
</li>
<li><p>我们利用大语言模型的文本理解能力来编码这些信息。在UrbanGPT框架中，我们<strong>集成了多粒度的时间信息和空间细节，作为大语言模型的指令输入</strong>。</p>
<ul>
<li>时间信息包括一周的日期和时间，一天的时间等因素。</li>
<li>而<strong>区域信息包括城市、行政区域和附近的兴趣点（POI）数据等</strong>，如图3所示。</li>
<li>通过合并这些不同的元素，UrbanGPT能够<strong>识别和理解复杂的时空环境下不同区域和时段的时空模式</strong>，从而增强其零样本推理能力。</li>
</ul>
</li>
</ul>
<p>时空信息指令文本的设计如图3所示。图3：编码时间和位置感知信息的时空提示指令的说明。</p>
<img src="/2024/04/30/urbangpt-spatio-temporal-large-language-models/image-20240318210901930.png">

<h4 id="LLM的时空指令微调"><a href="#LLM的时空指令微调" class="headerlink" title="LLM的时空指令微调"></a>LLM的时空指令微调</h4><p>使用指令微调LLMs以生成文本格式的时空预测存在两个挑战。</p>
<ul>
<li>首先，<strong>时空预测通常依赖于数值数据，其结构和模式与语言模型擅长处理的自然语言不同，后者侧重于语义和句法关系</strong>。</li>
<li>其次，<strong>LLMs通常使用多分类损失进行预训练以预测词汇，从而得到潜在结果的概率分布。而回归任务则需要连续值分布。</strong><ul>
<li>也就是说llm是一个词一个词的预测，而回归任务需要直接得到一组连续的数值分布</li>
</ul>
</li>
</ul>
<p>为了解决这些挑战，UrbanGPT采用了一种不同的策略，===<strong>不直接预测未来的时空值，而是生成辅助预测过程的预测标记</strong>（token）===。</p>
<p><strong>这些标记随后通过回归层，将隐藏表示映射为生成更准确的预测值</strong>：</p>
<p><strong>（STLlama  409-433）</strong></p>
<img src="/2024/04/30/urbangpt-spatio-temporal-large-language-models/image-20240318211556936.png">

<p>预测结果，记为ˆY𝑟，𝑓∈R^𝑃，使用<strong>线性整流激活函数（ReLU），用𝜎表示</strong>。<strong>预测标记的隐藏表示，表示为Γ𝑟，𝑓∈R^𝑑𝐿</strong>，<strong>作为大型语言模型（LLMs）词汇表中的一个新术语被引入</strong>。回归层使用权重矩阵W1∈R𝑑‘×𝑑𝐿、W2∈R𝑑’×𝑑𝐿和W3∈R𝑃×2𝑑‘表示，其中[·，·]表示连接操作。**虽然预测token的概率分布保持相对稳定，但其隐藏的表征包含了丰富的时空上下文属性，从而捕获了动态的时空相互依赖性。这使得我们的模型能够通过利用这些上下文信息来提供精确的预测。</p>
<h3 id="模型优化"><a href="#模型优化" class="headerlink" title="模型优化"></a>模型优化</h3><ul>
<li>在基线模型[1,7]的基础上，我们采用<strong>绝对误差损失作为回归损失函数</strong>。这种选择使我们能够有效地处理各种城市场景中的预测。</li>
<li>此外，我们引入了一个分类损失作为一个联合损失，以满足不同的任务需求。</li>
<li>为了确保最佳的性能，我们的模型会<strong>根据特定的任务输入来优化不同的损失</strong>。例如，我们对交通流量预测等任务使用回归损失，而对犯罪预测等任务使用分类损失。这种方法使我们的模型能够有效地解决每个任务所带来的独特挑战</li>
</ul>
<img src="/2024/04/30/urbangpt-spatio-temporal-large-language-models/image-20240318224114032.png" alt="image-20240318224114032" style="zoom: 67%;">

<p>这里，𝑦𝑖表示来自ˆY的一个样本，𝑁表示样本总数，计算为𝑅、𝑇和𝐹的乘积。我们在我们的模型中使用了各种损失函数，包括Lc–二元交叉熵损失；L𝑟表示回归损失，以及在我们的时空语言模型中采用的交叉熵损失。为了从预测中获取概率分布，我们使用了用𝛿表示的sigmoid激活函数。这些损失函数在我们的模型中都扮演着特定的角色，使我们能够根据需要有效地处理分类、回归和语言建模任务。</p>
<h3 id="超参数"><a href="#超参数" class="headerlink" title="超参数"></a>超参数</h3><p>超参数设置。时间编码器中膨胀卷积核的参数设置如下：𝑑𝑖𝑛、𝑑𝑜𝑢𝑡、𝑑‘𝑜𝑢𝑡均设置为32，膨胀因子为1。对于我们的预测任务，我们的目标是基于之前的12个步骤来预测数据的下一个12个步骤。历史记录长度（𝐻）和预测记录长度（𝑃）均设置为12。投影层参数配置为𝑑设置为64，𝑑𝐿设置为4096。最后，将回归层的隐层参数𝑑‘设置为128。</p>
<h2 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h2><p>关键问题：</p>
<ul>
<li>RQ1：UrbanGPT在不同的零样本时空预测任务中的性能和泛化能力是什么？</li>
<li>RQ2：与现有的时空模型相比，UrbanGPT在经典监督场景中的表现如何？</li>
<li>RQ3：提出的关键组件为提高我们的UrbanGPT模型的能力带来了哪些具体的贡献？</li>
<li>RQ4：所提出的模型能否稳健地处理不同时空模式的预测情景？</li>
</ul>
<h3 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h3><h4 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h4><ul>
<li><p>为了评估所提出的模型在预测不同城市计算场景的时空模式方面的有效性，我们使用四个不同的数据集进行了实验：纽约出租车、纽约自行车、纽约犯罪和芝加哥出租车。</p>
</li>
<li><p><strong>为了便于分析，我们根据经纬度信息将城市划分为类似网格的区域。</strong>在特定的时间间隔内，我们汇总了每个区域的统计测量值。</p>
</li>
<li><p>例如，这涉及到计算区域A30分钟周期内的出租车流入和流出的数量，或确定区域B一天内的盗窃事件的数量。此外，利用不同区域的纬度和经度，兴趣点（POIs）数据可以通过地图服务提供的api获得。</p>
</li>
</ul>
<p>纽约市的出租车数据集包含263个区域，每个区域的面积约为3公里x3公里。该数据集的时间采样间隔为30分钟。纽约自行车和纽约犯罪数据集包括2162个地区，每个地区都由一个1公里x1公里的网格代表。纽约自行车的采样间隔也是30分钟，而纽约犯罪的采样间隔是1天。所有数据集涵盖了纽约市从2016年1月1日至2021年12月31日的时间段。芝加哥出租车数据集包括77个区域，每个区域的长度约为4公里x4公里。该数据集包括从2021年1月1日至2021年12月31日期间的所有出租车数据，时间采样间隔为30分钟。</p>
<h4 id="评估协议"><a href="#评估协议" class="headerlink" title="评估协议"></a>评估协议</h4><p>为了研究大型语言模型在分析不同地区的不同时空数据方面的能力，我们选择了来自纽约市不同地区的出租车、自行车和犯罪数据的一个子集作为我们的训练集。</p>
<p><strong>零样本学习场景：</strong>我们通过预测来自纽约市甚至芝加哥那些<strong>在训练阶段未见过的地区的未来时空数据</strong>来评估模型的性能。</p>
<p><strong>监督学习场景：</strong>我们使用来自训练集相同区域的未来数据来评估该模型。</p>
<ul>
<li><p><strong>回归任务</strong>：我们在所有基线模型上保持了一致的训练和测试方法。</p>
</li>
<li><p>在涉及犯罪数据的<strong>分类任务</strong>时，我们使用二元交叉熵作为损失函数对模型进行训练和测试。</p>
</li>
</ul>
<p>我们的实验是使用稳健的vicuna-7b [49]作为UrbanGPT的基础大型语言模型进行的。关于我们的方法和实验设置的更全面的理解，请参阅附录中的详细信息。</p>
<h4 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h4><ul>
<li><p>对于回归任务，我们使用MAE（平均绝对误差）和RMSE（均方根误差）作为评价度量。这些指标量化了预测结果和实际标签之间的差异，较低的值表明优越的性能[11,48]。</p>
</li>
<li><p>在分类任务的情况下，我们使用召回率和Macro-F1作为评估指标来评估绩效。召回度量了模型正确识别积极实例的能力，而Macro-F1是一个综合的性能度量，它结合了精度和召回率，提供了分类精度[10,29]的总体度量。</p>
</li>
</ul>
<h4 id="基线模型"><a href="#基线模型" class="headerlink" title="基线模型"></a>基线模型</h4><p>我们与10个高级模型进行了彻底的比较：</p>
<p>（1）在基于rnn的时空预测方法类别中，我们将我们提出的方法与AGCRN [1]、DMVSTNET [38]和ST-LSTM [32]进行了比较。这些方法利用rnn进行建模和预测。</p>
<ul>
<li>ST-LSTM[32]：它结合了长短期记忆来捕获时空数据中的时间依赖性。</li>
<li>AGCRN[1]：rnn被用来捕获时间相关性，允许表示随着时间的推移的进化模式。</li>
<li>DMVSTNET[38]：在这种方法中，rnn被用来有效地建模时间依赖关系，捕获随时间演变的模式。此外，利用卷积网络和全连接层来捕获局部空间相关性，并建立有意义的空间关系。</li>
</ul>
<p>（2）基于gnn的时空模型主要利用图神经网络来捕获空间相关性，并整合时间编码器来捕获时空关系。我们与这类模型进行了比较，包括GWN [36]，MTGNN [35]，STSGCN [25]，TGCN [46]，和STGCN [41].</p>
<ul>
<li>GWN[36]：它结合了一个可学习的图结构和一维卷积来有效地学习时空依赖关系。</li>
<li>MTGNN[35]：它利用一个可学习的图结构来建模多元的时间相关性。MTGNN使用一维膨胀卷积来生成时间表示。</li>
<li>TGCN[46]：该模型结合了图神经网络（GNNs）进行空间相关建模和递归神经网络（RNNs）进行时间相关建模。</li>
<li>STGCN[41]：它分别使用门控时间卷积和gnn来建模时间和空间依赖性。</li>
<li>STSGCN[25]：它引入了一个时空图的构造来学习相邻时间步长之间的空间相关性。</li>
</ul>
<p>（3）在基于注意的时空模型类别中，该方法采用注意机制来建模时空相关性。我们在这一类中比较的模型是ASTGCN [7]和STWA [5]。</p>
<ul>
<li>ASTGCN[7]：该方法采用注意机制来捕获多粒度的时间相关特征。</li>
<li>STWA[5]：该模型将个性化的时间和空间参数纳入注意模块，允许对动态时空相关性的建模</li>
</ul>
<h3 id="零样本预测性能（RQ1）"><a href="#零样本预测性能（RQ1）" class="headerlink" title="零样本预测性能（RQ1）"></a>零样本预测性能（RQ1）</h3><h4 id="相同城市内未见区域的预测"><a href="#相同城市内未见区域的预测" class="headerlink" title="相同城市内未见区域的预测"></a>相同城市内未见区域的预测</h4><p>跨区域场景需要使用来自城市内某些区域的数据来<strong>预测模型没有遇到的其他区域的未来情况</strong>。通过对模型在跨区域预测中的表现的全面分析，我们可以注意到三个重要的观察结果：</p>
<p><strong>（1）优越的零样本预测性能。</strong>表1中的结果突出了所提出的模型在不同数据集上的<strong>回归和分类任务</strong>中的卓越性能，超过了零样本预测中的基线模型。UrbanGPT的成功可以归因于两个关键因素。</p>
<ul>
<li><strong>时空-文本对齐。</strong>时空上下文信号与语言模型的文本理解能力的对齐对模型成功起着关键作用。这种融合使模型能够有效地<strong>利用从时空信号中编码的城市动态和由大语言模型提供的对文本上下文的全面理解</strong>，从而扩展了模型在零样本场景的预测能力。</li>
<li><strong>时空指令微调。</strong>自适应调整过程使LLMs能够有效地整合指令中的关键信息，增强其对空间和时间因素之间复杂关系和依赖性的理解。 通过将时空指令微调与时空依赖编码器无缝合并， UrbanGPT成功地保留了<strong>通用且可转移的时空知识</strong>，进而实现零样本场景中的精确预测。</li>
</ul>
<p><strong>（2）增强了对城市语义的理解。</strong>城市语义提供了对多样的空间和时间特性的重要见解。所提出的方法在各种数据集上对模型进行训练，<strong>丰富其对不同时段和地理位置的时空动态的理解。</strong>相比之下，<strong>基准模型往往优先考虑编码时空依赖关系，忽视了区域、时段和数据类别之间的语义差异。</strong>通过将全面的语义信息注入UrbanGPT中，我们显著增强了其在先前未见的区域中进行准确零样本预测的能力。</p>
<p><strong>（3）稀疏数据场景中的性能提升。</strong>稀疏数据环境中预测时空模式是具有挑战性的，因为<strong>当数据点稀缺时，模型容易出现过拟合</strong>。在预测犯罪等情况下，数据通常是稀疏的，在这一条件下，基线在跨区域预测任务中表现困难，导致召回率低，表明可能存在过拟合的问题。为了克服这个限制，我们的模型<strong>通过使用有效的时空指令微调范式，将时空学习与大语言模型相结合。通过融入丰富的语义见解，所提出的方法增强了模型的时空表示能力，使其能够有效处理稀疏数据，并实现改进的预测准确性。</strong></p>
<img src="/2024/04/30/urbangpt-spatio-temporal-large-language-models/image-20240319140723091.png">

<h4 id="跨城市预测任务"><a href="#跨城市预测任务" class="headerlink" title="跨城市预测任务"></a>跨城市预测任务</h4><p>为评估模型在跨城市预测任务中的性能，我们对芝加哥出租车数据集进行了测试（该数据集没有出现在训练阶段）。如图4所示，结果显示模型在每个时间步长都始终优于比较方法，这说明UrbanGPT能够对跨城市知识进行有效的转移。通过整合时空编码器与时空指令微调范式，模型有效地捕获了普遍及特殊的时空模式。此外，通过考虑不同的地理信息和时间因素以及学到的转移知识，模型具备将相似功能区域和历史时期所表现出的时空模式进行关联的能力，使其能够做出更准确的预测。</p>
<ul>
<li><strong>多步预测的一致性</strong>：我们的模型<strong>在每个时间步长上始终优于比较方法</strong>。值得注意的是，它在短期和长期的时空预测中都保持了显著的优势，证明了我们提出的模型在跨城市预测场景中的鲁棒性。</li>
<li><strong>跨城市有效知识迁移</strong>：芝加哥出租车数据集预测结果验证了我们的模型在跨城市场景中的优越能力。这种增强可以<strong>归因于时空编码器与时空指令调整范式的集成。</strong>通过合并这些组件，我们的模型有效地<strong>捕获了通用的和可转移的时空模式</strong>，使它能够做出准确的预测。此外，<strong>通过考虑不同的地理信息和时间因素以及学习到的知识转移，我们的模型成功地关联了相似功能区和历史时期的时空模式。</strong></li>
</ul>
<img src="/2024/04/30/urbangpt-spatio-temporal-large-language-models/image-20240319143415576.png">

<h3 id="典型有监督预测任务（RQ2）"><a href="#典型有监督预测任务（RQ2）" class="headerlink" title="典型有监督预测任务（RQ2）"></a>典型有监督预测任务（RQ2）</h3><p>本节研究了我们的UrbanGPT在端到端监督预测场景中的预测能力，如表2所示。</p>
<ul>
<li><strong>增强的长期预测能力</strong>：我们利用时间间隔跨度更广的测试数据集来测试模型在长期时空预测中的有效性。例如，使用2017年的数据训练模型，并使用2021年的数据进行评估。结果表明，我们的UrbanGPT在基线相比具有显著的优势，突显了其<strong>长期时间跨度场景的卓越泛化能力</strong>。此特性<strong>减少了频繁重新训练或增量更新的需要</strong>，使模型更符合实际应用。此外，实验还证实，<strong>加入额外的文本知识不会阻碍模型性能或引入噪声</strong>，从而进一步验证了利用大型语言模型增强时空预测任务的可行性。</li>
<li><strong>空间语义理解</strong>：准确捕捉空间相关性在时空预测领域至关重要。传统的方法通常使用<strong>图网络或注意机制</strong>来分析这些相关性。缺乏专门的空间相关模块的模型，如LSTM，在忽视空间环境时往往表现不佳。相比之下，我们的模型通过<strong>在文本输入中集成广泛的地理和感兴趣点（POIs）数据来弥补了显式空间编码器的缺失</strong>。<strong>这种方法使模型能够在更高的语义层次上理解具有相似功能的区域的共享特征。因此，它推导出不同功能区之间的关联模式，并有效地代表了不同区域之间的相互联系。</strong></li>
</ul>
<img src="/2024/04/30/urbangpt-spatio-temporal-large-language-models/image-20240319143505846.png" alt="image-20240319143505846" style="zoom:80%;">

<h3 id="消融研究（RQ3）"><a href="#消融研究（RQ3）" class="headerlink" title="消融研究（RQ3）"></a>消融研究（RQ3）</h3><p>本节研究了不同关键组件对模型性能的影响，如图5所示。我们严格的测试主要围绕着使用纽约市出租车数据集的零样本场景展开。通过我们的分析，我们将不同模块所提供的好处提炼为四个关键点。</p>
<p><strong>(1) 时空上下文的影响</strong>：-STC。从指示文本中移除时空信息后出现了性能衰减，这可能由于<strong>缺乏时间信息</strong>，<strong>使得模型仅依赖于时空编码器来编码与时间相关的特征和执行预测任务</strong>。此外，空间信息的缺失阻碍了模型捕捉空间相关性的能力，使得分析不同区域的不同时空模式具有挑战性。</p>
<p><strong>(2) 使用多个数据集进行指令微调的影响</strong>：-Multi。我们仅在NYC-taxi数据集进行训练。由于<strong>缺乏不同的城市指标的信息，限制了模型充分揭示城市时空动态的能力</strong>。通过整合来自多个来源的不同时空数据，模型可以有效地捕获不同地理位置的独特特征及演化的时空模式。</p>
<p><strong>(3) 时空编码器的影响</strong>：-STE。我们从模型中移除了时空编码器。结果表明，时空编码器的缺失<strong>显著地阻碍了大语言模型在时空预测场景中的预测性能</strong>。这强调了所提出的时空编码器在提高模型的预测能力方面所发挥的关键作用。</p>
<p><strong>(4) 指令微调中的回归层</strong>：T2P。我们直接指示UrbanGPT以文本格式生成其预测。次优的性能表现主要是由于训练过程中依赖于多类损失来进行优化，导致<strong>模型的概率输出和时空预测所需的连续值分布之间的不匹配</strong>。为了弥补这一差距，我们在模型中加入了一个回归预测器，显著提高了它在回归任务生成更精确的数值预测的能力。</p>
<img src="/2024/04/30/urbangpt-spatio-temporal-large-language-models/image-20240319145301101.png" alt="image-20240319145301101" style="zoom:80%;">

<h3 id="模型鲁棒性研究（RQ4）"><a href="#模型鲁棒性研究（RQ4）" class="headerlink" title="模型鲁棒性研究（RQ4）"></a>模型鲁棒性研究（RQ4）</h3><p>在本节中，我们将重点评估我们的UrbanGPT在不同时空模式场景下的稳健性。<strong>我们根据数值变化的大小对区域进行分类，</strong>如在特定时间段内的出租车流量。<strong>较低的方差表明稳定的时间模式，而较高的方差表明时空模式多样化的地段，如活跃商业区或人口稠密地区。</strong>如图6所示，大多模型在方差较低的区域表现良好，因为这些区域的时空模式相对稳定。然而，基线在方差较高的区域中表现不佳，特别是在方差处于 (0.75, 1.0] 范围的区域，这一限制可能源自<strong>基线模型在零样本场景下难以推断未见区域的复杂时空模式</strong>。在实际应用中，<strong>人口密集或繁华区域的准确预测对于城市治理至关重要</strong>，例如交通灯控制和安全调度。UrbanGPT在(0.75, 1.0]区间表现出显着的性能提升，突显了所提出方法的强大的零样本预测能力。</p>
<img src="/2024/04/30/urbangpt-spatio-temporal-large-language-models/image-20240319152953670.png" alt="image-20240319152953670" style="zoom:80%;">

<h3 id="案例研究"><a href="#案例研究" class="headerlink" title="案例研究"></a>案例研究</h3><p>在我们的案例研究中，我们彻底评估了几个大型语言模型（llm）的零样本时空预测。我们强调了这些模型在直接从数字地理序列数据中理解时空模式方面所面临的挑战。相比之下，我们展示了我们提出的UrbanGPT框架在捕获通用时空模式方面的特殊性能，以及它在各种零样本时空预测场景中有效推广的能力。</p>
<p>结果表明，各种llm能够基于这些指令生成预测，从而突出了提示设计的有效性。<strong>例如，ChatGPT依赖于历史平均值，而不是在其预测中明确地组合时间或空间数据。Llama-2-70b分析了特定的时间段和区域，但它在编码数值时间序列依赖性方面遇到了挑战，导致了次优的预测性能。另一方面，Claude-2.1有效地总结和分析了历史数据，利用高峰时段模式和兴趣点来实现更准确的交通趋势预测。</strong></p>
<p>我们提出的UrbanGPT通过一个时空指令调优范式，无缝地将时空上下文信号与大型语言模型（llm）的推理能力集成起来。这种整合导致了预测数值和时空趋势的显著改进。</p>
<p>表3：我们用所提供的instruction测试了不同llm对纽约市自行车流量的零样本预测</p>
<img src="/2024/04/30/urbangpt-spatio-temporal-large-language-models/image-20240319170828390.png" alt="image-20240319170828390" style="zoom:80%;">

<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p><strong>深度时空预测模型。</strong>深度时空预测方法由于其出色的性能而在深度学习中获得了突出的地位。这些模型通常由两个组成部分组成：<strong>时间依赖建模和空间相关编码。</strong>早期的模型，如D-LSTM [42]和ST-resnet [44]，使用rnn和卷积网络来建模时间和空间依赖性。图神经网络（GNNs）被证明是空间相关建模的一种自然拟合，就像在STGCN [41]和DCRNN [13]等模型中所看到的那样，它们利用了基于节点距离的图结构。可学习的区域级图结构[35,36]和动态时空图网络[8,47]等技术进一步增强了空间相关建模。</p>
<p>此外，研究人员还探索了诸如多尺度时间学习[33]和多粒度时间学习[7]来编码时间依赖性的方法。这些策略能够捕获诸如长期和短期相关性以及周期性等特征。这些进步有助于时空预测的进展。然而，值得注意的是，这些研究大多数是为监督环境量身定制的，有限的研究和发展集中在零样本时空预测。这是一个需要进一步探索的重要领域。</p>
<p><strong>时空预训练。</strong>时空预训练技术最近受到了广泛的研究关注。这些技术主要关注于<strong>生成式[15,23]和对比式[45]预训练模型</strong>，以提高下游任务的预测性能。对少样本学习场景[12,18]的训练前微调框架也进行了广泛的探索，<strong>旨在通过对齐源数据和目标数据来提高知识的可转移性。</strong>然而，这些方法需要对目标数据进行训练或微调，并且缺乏零样本预测能力。在这项工作中，我们通过提出UrbanGPT来解决下游城市场景中数据稀缺的挑战。我们的模型展示了在各种场景中很好地泛化的能力，减轻了对目标数据进行广泛训练或微调的需要。</p>
<p><strong>大型语言模型。</strong>大型语言模型[3,20]的出现由于其在<strong>文本理解和推理</strong>等任务中前所未有的机器性能而引起了广泛的关注。这些模型已经成为一个热点话题，展示了从智能算法发展到人工智能的发展潜力。开源的大型语言模型，如Llama [27,28]、Vicuna [49]和ChatGLM [43]已经发布，导致研究人员探索它们在各个领域的应用，<strong>通过这些模型中的领域知识来增强迁移学习能力。</strong>在计算机视觉领域，研究人员将多模态大型语言模型与即时学习方法相结合，以实现下游任务[24,50,51]的零样本预测。此外，大型语言模型在图推理[2,4,26]和推荐[9,22,34]中的能力已被广泛研究。然而，在时空预测领域，利用大型语言模型进行零样本时空预测任务仍未得到很大程度的探索</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>我们提出了UrbanGPT，一种时空大型语言模型，以很好地推广到不同的城市场景。为实现时空上下文信号与LLMs无缝对齐，本文引入了一种时空指令微调范式。这赋予UrbanGPT在各种类型的城市数据中学习通用和可迁移的时空模式的卓越能力。大量实验分析展示了UrbanGPT架构及其关键组件的卓越有效性。</p>
<p>然而，需要注意的是，虽然结果是令人鼓舞的，但在未来的研究中仍然存在待解决的限制。作为第一步，我们积极收集更多种类的城市数据，以增强和完善UrbanGPT在更广泛的城市计算领域的能力。此外，理解UrbanGPT的决策过程也是重要的。虽然该模型表现出卓越的性能，但提供可解释性同样重要。未来的研究也将集中于赋予UrbanGPT模型解释其预测的能力。</p>
<h2 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h2><h3 id="训练UrbanGPT"><a href="#训练UrbanGPT" class="headerlink" title="训练UrbanGPT"></a>训练UrbanGPT</h3><h4 id="准备预训练checkpoint"><a href="#准备预训练checkpoint" class="headerlink" title="准备预训练checkpoint"></a>准备预训练checkpoint</h4><blockquote>
<p>checkpoint文件包含的内容很多，比如：模型参数、优化器状态、训练进度等信息。checkpoint文件的主要作用是在训练过程中保存模型状态，以便在训练过程中发生中断或结束后能够恢复模型的状态，或者在推断时使用已经训练好的模型参数。</p>
</blockquote>
<p>UrabnGPT基于以下优秀的现有模型进行训练。请按照指示准备checkpoint：</p>
<ul>
<li><p><code>Vicuna</code>:<br>准备我们的基本模型Vicuna，它是一个指令微调过的的chatbot，也是我们实现中的base model。</p>
<p>请下载权重<a target="_blank" rel="noopener" href="https://github.com/lm-sys/FastChat#model-weights">here</a>.  我们通常使用具有7B参数的v1.5和v1.5-16k模型。您应该更新vicuna中的config.json，例如，v1.5-16k中的Json ‘可以在<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/bjdwh/checkpoints/blob/main/train_config/config.json">config.json</a>中找到。</p>
</li>
<li><p><code>Spatio-temporal Encoder</code>:<br>我们使用一个简单的基于TCN的时空编码器对时空依赖进行编码。通过典型的<strong>多步时空预测任务</strong>对<a href="./checkpoints/st_encoder/pretrain_stencoder.pth">st_encoder</a>的权值进行预训练。</p>
</li>
<li><p><code>Spatio-temporal Train Data</code>:<br>我们利用由纽约市出租车、自行车和犯罪数据组成的预训练数据，包括时空统计、记录的时间戳和有关区域兴趣点(poi)的信息。这些数据被组织在<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/bjdwh/ST_data_urbangpt/tree/main/train_data">train_data</a>中。请下载并放在。/UrbanGPT/ST_data_urbangpt/train_data 下。</p>
</li>
</ul>
<h4 id="指令微调"><a href="#指令微调" class="headerlink" title="指令微调"></a>指令微调</h4><ul>
<li><strong>Start tuning:</strong> 在上述步骤之后，您可以通过在<a href="urbangpt_train.sh">urbangpt_train.sh</a>中填充空白来开始指令调优。示例：</li>
</ul>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># to fill in the following path to run our UrbanGPT!</span>
<span class="token assign-left variable">model_path</span><span class="token operator">=</span>./checkpoints/vicuna-7b-v1.5-16k
<span class="token assign-left variable">instruct_ds</span><span class="token operator">=</span>./ST_data_urbangpt/train_data/multi_NYC.json
<span class="token assign-left variable">st_data_path</span><span class="token operator">=</span>./ST_data_urbangpt/train_data/multi_NYC_pkl.pkl
<span class="token assign-left variable">pretra_ste</span><span class="token operator">=</span>ST_Encoder
<span class="token assign-left variable">output_model</span><span class="token operator">=</span>./checkpoints/UrbanGPT

wandb offline
python <span class="token parameter variable">-m</span> torch.distributed.run <span class="token parameter variable">--nnodes</span><span class="token operator">=</span><span class="token number">1</span> <span class="token parameter variable">--nproc_per_node</span><span class="token operator">=</span><span class="token number">8</span> <span class="token parameter variable">--master_port</span><span class="token operator">=</span><span class="token number">20001</span> <span class="token punctuation">\</span>
    urbangpt/train/train_mem.py <span class="token punctuation">\</span>
    <span class="token parameter variable">--model_name_or_path</span> <span class="token variable">${model_path}</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--version</span> v1 <span class="token punctuation">\</span>
    <span class="token parameter variable">--data_path</span> <span class="token variable">${instruct_ds}</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--st_content</span> ./TAXI.json <span class="token punctuation">\</span>
    <span class="token parameter variable">--st_data_path</span> <span class="token variable">${st_data_path}</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--st_tower</span> <span class="token variable">${pretra_ste}</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--tune_st_mlp_adapter</span> True <span class="token punctuation">\</span>
    <span class="token parameter variable">--st_select_layer</span> <span class="token parameter variable">-2</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--use_st_start_end</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--bf16</span> True <span class="token punctuation">\</span>
    <span class="token parameter variable">--output_dir</span> <span class="token variable">${output_model}</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--num_train_epochs</span> <span class="token number">3</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--per_device_train_batch_size</span> <span class="token number">4</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--per_device_eval_batch_size</span> <span class="token number">4</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--gradient_accumulation_steps</span> <span class="token number">1</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--evaluation_strategy</span> <span class="token string">"no"</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--save_strategy</span> <span class="token string">"steps"</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--save_steps</span> <span class="token number">2400</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--save_total_limit</span> <span class="token number">1</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--learning_rate</span> 2e-3 <span class="token punctuation">\</span>
    <span class="token parameter variable">--weight_decay</span> <span class="token number">0</span>. <span class="token punctuation">\</span>
    <span class="token parameter variable">--warmup_ratio</span> <span class="token number">0.03</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--lr_scheduler_type</span> <span class="token string">"cosine"</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--logging_steps</span> <span class="token number">1</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--tf32</span> True <span class="token punctuation">\</span>
    <span class="token parameter variable">--model_max_length</span> <span class="token number">2048</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--gradient_checkpointing</span> True <span class="token punctuation">\</span>
    <span class="token parameter variable">--lazy_preprocess</span> True <span class="token punctuation">\</span>
    <span class="token parameter variable">--report_to</span> wandb<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="评估UrbanGPT"><a href="#评估UrbanGPT" class="headerlink" title="评估UrbanGPT"></a>评估UrbanGPT</h3><h4 id="准备-Checkpoints-and-Data"><a href="#准备-Checkpoints-and-Data" class="headerlink" title="准备 Checkpoints and Data"></a>准备 Checkpoints and Data</h4><ul>
<li>**Checkpoints: **您可以尝试通过使用自己的模型或我们发布的检查点来评估UrbanGPT。</li>
<li><strong>Data:</strong> 我们为纽约出租车数据拆分测试集，并为评估创建指令数据。请参阅[评估]<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/bjdwh/ST_data_urbangpt%EF%BC%89">https://huggingface.co/datasets/bjdwh/ST_data_urbangpt）</a></li>
</ul>
<span id="Running Evaluation">

<h4 id="运行Evaluation"><a href="#运行Evaluation" class="headerlink" title="运行Evaluation"></a>运行Evaluation</h4><p>您可以通过在[urbangpt_eval.sh]（urbangpt_eval.sh）填充空白开始第二阶段tuning。下面是一个示例：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># to fill in the following path to evaluation!</span>
<span class="token assign-left variable">output_model</span><span class="token operator">=</span>./checkpoints/tw2t_multi_reg-cla-gird
<span class="token assign-left variable">datapath</span><span class="token operator">=</span>./ST_data_urbangpt/NYC_taxi_cross-region/NYC_taxi.json
<span class="token assign-left variable">st_data_path</span><span class="token operator">=</span>./ST_data_urbangpt/NYC_taxi_cross-region/NYC_taxi_pkl.pkl
<span class="token assign-left variable">res_path</span><span class="token operator">=</span>./result_test/cross-region/NYC_taxi
<span class="token assign-left variable">start_id</span><span class="token operator">=</span><span class="token number">0</span>
<span class="token assign-left variable">end_id</span><span class="token operator">=</span><span class="token number">51920</span>
<span class="token assign-left variable">num_gpus</span><span class="token operator">=</span><span class="token number">8</span>

python ./urbangpt/eval/run_urbangpt.py --model-name <span class="token variable">${output_model}</span>  <span class="token parameter variable">--prompting_file</span> <span class="token variable">${datapath}</span> <span class="token parameter variable">--st_data_path</span> <span class="token variable">${st_data_path}</span> <span class="token parameter variable">--output_res_path</span> <span class="token variable">${res_path}</span> <span class="token parameter variable">--start_id</span> <span class="token variable">${start_id}</span> <span class="token parameter variable">--end_id</span> <span class="token variable">${end_id}</span> <span class="token parameter variable">--num_gpus</span> <span class="token variable">${num_gpus}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><h4 id="扩张卷积"><a href="#扩张卷积" class="headerlink" title="扩张卷积"></a>扩张卷积</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">DilatedInception</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cin<span class="token punctuation">,</span> cout<span class="token punctuation">,</span> dilation_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>DilatedInception<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>tconv <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># 创建一个列表以容纳多个卷积层</span>
        self<span class="token punctuation">.</span>kernel_set <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span>  <span class="token comment"># 不同的卷积核大小</span>
        cout <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>cout<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>kernel_set<span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment"># 计算每个卷积的输出通道数</span>
        <span class="token keyword">for</span> kern <span class="token keyword">in</span> self<span class="token punctuation">.</span>kernel_set<span class="token punctuation">:</span>
            <span class="token comment"># 添加具有不同卷积核大小和扩张率的卷积层，一维扩散卷积核</span>
            self<span class="token punctuation">.</span>tconv<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>cin<span class="token punctuation">,</span> cout<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> kern<span class="token punctuation">)</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> dilation_factor<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token comment"># 使用定义的层执行卷积操作</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>kernel_set<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            x<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>tconv<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>kernel_set<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            x<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span>x<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">]</span>   <span class="token comment"># 沿最后一个维度切片张量</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>                 <span class="token comment"># 沿着通道维度拼接张量</span>
        <span class="token keyword">return</span> x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="ST-Encoder-前向传播"><a href="#ST-Encoder-前向传播" class="headerlink" title="ST_Encoder 前向传播"></a>ST_Encoder 前向传播</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> source<span class="token punctuation">)</span><span class="token punctuation">:</span>
    inputs <span class="token operator">=</span> source
    <span class="token comment"># 转置维度以进行正确的卷积操作</span>
    inputs <span class="token operator">=</span> inputs<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment"># (batch_size, feature_dim, num_nodes, input_window)</span>
    <span class="token keyword">assert</span> inputs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">==</span> self<span class="token punctuation">.</span>input_window<span class="token punctuation">,</span> <span class="token string">'input sequence length not equal to preset sequence length'</span>
    <span class="token comment"># 输入扩展到最大感受野，扩展部分填充0</span>
    <span class="token keyword">if</span> self<span class="token punctuation">.</span>input_window <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>receptive_field<span class="token punctuation">:</span>
        inputs <span class="token operator">=</span> nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>receptive_field<span class="token operator">-</span>self<span class="token punctuation">.</span>input_window<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    x <span class="token operator">=</span> self<span class="token punctuation">.</span>start_conv<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>     <span class="token comment"># 将输入张量进行卷积操作，输出特征图的通道数为 residual_channels=32，</span>
    skip <span class="token operator">=</span> self<span class="token punctuation">.</span>skip0<span class="token punctuation">(</span>F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 三层卷积</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
        residual <span class="token operator">=</span> x  <span class="token comment"># 记录当前块输入作为残差</span>
        filters <span class="token operator">=</span> self<span class="token punctuation">.</span>filter_convs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment"># 普通卷积操作</span>
        filters <span class="token operator">=</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>filters<span class="token punctuation">)</span>  <span class="token comment"># 应用tanh激活函数</span>
        gate <span class="token operator">=</span> self<span class="token punctuation">.</span>gate_convs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment"># 执行门控卷积操作</span>
        gate <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>gate<span class="token punctuation">)</span>  <span class="token comment"># 应用sigmoid激活函数，映射到0，1范围，进行门控</span>
        x <span class="token operator">=</span> filters <span class="token operator">*</span> gate  <span class="token comment"># 使用门控机制进行特征调整---张量积，逐元素相乘，抑制噪声</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>  <span class="token comment"># 执行dropout操作</span>
        s <span class="token operator">=</span> x
        s <span class="token operator">=</span> self<span class="token punctuation">.</span>skip_convs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span>  <span class="token comment"># 跳跃连接中的卷积操作</span>
        skip <span class="token operator">=</span> s <span class="token operator">+</span> skip  <span class="token comment"># 计算跳跃连接的输出</span>

        x <span class="token operator">=</span> self<span class="token punctuation">.</span>residual_convs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment"># 执行残差卷积操作</span>
        x <span class="token operator">=</span> x <span class="token operator">+</span> residual<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># 添加残差并更新当前块输入</span>

    <span class="token comment"># 跳跃连接  负责多层次关联注入</span>
    skip <span class="token operator">=</span> self<span class="token punctuation">.</span>skipE<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">+</span> skip
    x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>skip<span class="token punctuation">)</span>
    x_emb <span class="token operator">=</span> x<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>end_conv_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>end_conv_2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x<span class="token punctuation">,</span> x_emb<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="STLlama-前向传播"><a href="#STLlama-前向传播" class="headerlink" title="STLlama 前向传播"></a>STLlama 前向传播</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        input_ids<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>LongTensor <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        attention_mask<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        past_key_values<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>List<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        inputs_embeds<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        use_cache<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">bool</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        output_attentions<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">bool</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        output_hidden_states<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">bool</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        st_data_x<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">list</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        st_data_y<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">list</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        region_start<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>
        region_end<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>
        return_dict<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">bool</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Union<span class="token punctuation">[</span>Tuple<span class="token punctuation">,</span> BaseModelOutputWithPast<span class="token punctuation">]</span><span class="token punctuation">:</span>

    <span class="token comment"># HACK: replace back original embeddings for LLaVA pretraining</span>
    orig_embeds_params <span class="token operator">=</span> <span class="token builtin">getattr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token string">'orig_embeds_params'</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
    <span class="token comment"># if orig_embeds_params is not None:</span>
    <span class="token comment">#     orig_embeds_params = orig_embeds_params[0]</span>
    <span class="token comment">#     with torch.no_grad():</span>
    <span class="token comment">#         self.get_input_embeddings().weight.data[:-2] = orig_embeds_params[:-2].data</span>

    <span class="token comment"># 检查是否有传入的嵌入 inputs_embeds，如果没有则通过 embed_tokens 方法将输入的 input_ids 转换成嵌入表示。</span>
    <span class="token keyword">if</span> inputs_embeds <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        inputs_embeds <span class="token operator">=</span> self<span class="token punctuation">.</span>embed_tokens<span class="token punctuation">(</span>input_ids<span class="token punctuation">)</span>
    <span class="token comment"># 检查是否需要将多个 st_data_x 和 st_data_y 进行拼接</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>st_data_x<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">:</span>
        st_data_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>st_data_x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        st_data_y <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>st_data_y<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    st_tower <span class="token operator">=</span> self<span class="token punctuation">.</span>get_st_tower<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 如果 st_tower 不为空，且输入数据的长度不为1或者处于训练模式，同时 st_data_x 也不为空，则进行时空信息的处理。</span>
    <span class="token keyword">if</span> st_tower <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> <span class="token punctuation">(</span>input_ids<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token number">1</span> <span class="token keyword">or</span> self<span class="token punctuation">.</span>training<span class="token punctuation">)</span> <span class="token keyword">and</span> st_data_x <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">type</span><span class="token punctuation">(</span>st_data_x<span class="token punctuation">)</span> <span class="token keyword">is</span> <span class="token builtin">list</span><span class="token punctuation">:</span>
            <span class="token comment"># variable length images</span>
            <span class="token comment"># 将 st_data_x 输入到 st_tower 中，得到时空编码的结果 STE_out，同时将 st_data_y 输入到 st_tower 中得到时空编码标签的结果 STE_lbls_out</span>
            pre_STE<span class="token punctuation">,</span> STE_out <span class="token operator">=</span> st_tower<span class="token punctuation">(</span>st_data_x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            _<span class="token punctuation">,</span> STE_lbls_out <span class="token operator">=</span> st_tower<span class="token punctuation">(</span>st_data_y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> STE_out<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">&gt;=</span> <span class="token number">1</span><span class="token punctuation">:</span>
                <span class="token comment"># 根据指定的 region_start 和 region_end 对 STE_out（时空编码信息） 进行切片得到区域选择输出 region_select_out。</span>
                region_select_out <span class="token operator">=</span> STE_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> region_start<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>region_end<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>bfloat16<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            pre_STE<span class="token punctuation">,</span> STE_out <span class="token operator">=</span> st_tower<span class="token punctuation">(</span>st_data_x<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            _<span class="token punctuation">,</span> STE_lbls_out <span class="token operator">=</span> st_tower<span class="token punctuation">(</span>st_data_y<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            region_select_out <span class="token operator">=</span> STE_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> region_start<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>region_end<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>bfloat16<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pre_STE <span class="token operator">=</span> pre_STE
        <span class="token comment"># ===========将 region_select_out 经过线性层 st_projector 处理得到投影的结果 st_projector_out。==========</span>
        st_projector_out <span class="token operator">=</span> self<span class="token punctuation">.</span>st_projector<span class="token punctuation">(</span>region_select_out<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        new_input_embeds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token comment"># new_stpre_embeds = []</span>
        cur_st_idx <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token comment"># 遍历输入的 input_ids 和对应的 inputs_embeds。</span>
        <span class="token keyword">for</span> cur_input_ids<span class="token punctuation">,</span> cur_input_embeds <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>input_ids<span class="token punctuation">,</span> inputs_embeds<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># if st_tower.config.use_st_start_end:</span>
            <span class="token comment"># 根据 st_tower 的配置信息，找到对应的起始标记和结束标记位置，然后根据这些位置和时空特征的投影结果，更新输入嵌入表示。</span>
            cur_st_features <span class="token operator">=</span> st_projector_out<span class="token punctuation">[</span>cur_st_idx<span class="token punctuation">]</span>
            cur_st_features <span class="token operator">=</span> cur_st_features<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>cur_st_features<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token comment"># 根据时空特征来划分patch</span>
            num_patches <span class="token operator">=</span> cur_st_features<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            <span class="token comment"># 判断开始标记和结束标记数量要一致</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>cur_input_ids <span class="token operator">==</span> st_tower<span class="token punctuation">.</span>config<span class="token punctuation">.</span>st_start_token<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token punctuation">(</span>
                    cur_input_ids <span class="token operator">==</span> st_tower<span class="token punctuation">.</span>config<span class="token punctuation">.</span>st_end_token<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"The number of st start tokens and st end tokens should be the same."</span><span class="token punctuation">)</span>
            st_start_tokens <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>cur_input_ids <span class="token operator">==</span> st_tower<span class="token punctuation">.</span>config<span class="token punctuation">.</span>st_start_token<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            <span class="token comment"># st_end_tokens = torch.where(cur_input_ids == st_tower.config.st_end_token)[0]</span>

            <span class="token keyword">if</span> st_start_tokens<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&gt;=</span> <span class="token number">3</span><span class="token punctuation">:</span>   <span class="token comment"># 标记&gt;=3</span>
                st_start_token_pos1 <span class="token operator">=</span> st_start_tokens<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
                st_start_token_pos2 <span class="token operator">=</span> st_start_tokens<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
                st_start_token_pos3 <span class="token operator">=</span> st_start_tokens<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>
                self<span class="token punctuation">.</span>st_start_id0 <span class="token operator">=</span> st_start_token_pos1
                self<span class="token punctuation">.</span>st_start_id1 <span class="token operator">=</span> st_start_token_pos3

                <span class="token keyword">if</span> cur_input_ids<span class="token punctuation">[</span>
                    st_start_token_pos1 <span class="token operator">+</span> num_patches <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">!=</span> st_tower<span class="token punctuation">.</span>config<span class="token punctuation">.</span>st_end_token<span class="token punctuation">:</span>
                    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"The st end token should follow the st start token."</span><span class="token punctuation">)</span>

                <span class="token keyword">if</span> orig_embeds_params <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                    <span class="token comment"># 根据这些位置和时空特征的投影结果，更新输入嵌入表示（拼接文本embedding张量+时空特征投影结果，只有start到end位置参与梯度更新）</span>
                    cur_new_input_embeds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>cur_input_embeds<span class="token punctuation">[</span><span class="token punctuation">:</span>st_start_token_pos1<span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                                      <span class="token comment"># 时空特征前后拼接原始input embed的start与end位置，start之前和end之后的用detach</span>
                                                      <span class="token comment"># 创建离断版本 将这些元素从计算图中分离出来，使得它们不参与梯度计算，从而防止对它们的修改影响到之后的反向传播过程</span>
                                                      cur_input_embeds<span class="token punctuation">[</span>st_start_token_pos1<span class="token punctuation">:</span>st_start_token_pos1 <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                      cur_st_features<span class="token punctuation">,</span>
                                                      cur_input_embeds<span class="token punctuation">[</span>
                                                      st_start_token_pos1 <span class="token operator">+</span> num_patches <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span>st_start_token_pos1 <span class="token operator">+</span> num_patches <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                      cur_input_embeds<span class="token punctuation">[</span>
                                                      st_start_token_pos1 <span class="token operator">+</span> num_patches <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">:</span>st_start_token_pos2<span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                                      cur_input_embeds<span class="token punctuation">[</span>
                                                      st_start_token_pos2<span class="token punctuation">:</span>st_start_token_pos2 <span class="token operator">+</span> num_patches <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                      cur_input_embeds<span class="token punctuation">[</span>
                                                      st_start_token_pos2 <span class="token operator">+</span> num_patches <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">:</span>st_start_token_pos3<span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                                      cur_input_embeds<span class="token punctuation">[</span>
                                                      st_start_token_pos3<span class="token punctuation">:</span>st_start_token_pos3 <span class="token operator">+</span> num_patches <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                      cur_input_embeds<span class="token punctuation">[</span>
                                                      st_start_token_pos3 <span class="token operator">+</span> num_patches <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    cur_new_input_embeds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>cur_input_embeds<span class="token punctuation">[</span><span class="token punctuation">:</span>st_start_token_pos1 <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                      cur_st_features<span class="token punctuation">,</span>
                                                      cur_input_embeds<span class="token punctuation">[</span>st_start_token_pos1 <span class="token operator">+</span> num_patches <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                                     dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
                cur_st_idx <span class="token operator">+=</span> <span class="token number">1</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>   <span class="token comment"># 一组标记，流程和上面一样</span>
                st_start_token_pos <span class="token operator">=</span> st_start_tokens<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
                self<span class="token punctuation">.</span>st_start_id0 <span class="token operator">=</span> st_start_token_pos
                num_patches <span class="token operator">=</span> cur_st_features<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

                <span class="token keyword">if</span> cur_input_ids<span class="token punctuation">[</span>st_start_token_pos <span class="token operator">+</span> num_patches <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">!=</span> st_tower<span class="token punctuation">.</span>config<span class="token punctuation">.</span>st_end_token<span class="token punctuation">:</span>
                    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"The st end token should follow the st start token."</span><span class="token punctuation">)</span>

                <span class="token keyword">if</span> orig_embeds_params <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                    cur_new_input_embeds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>cur_input_embeds<span class="token punctuation">[</span><span class="token punctuation">:</span>st_start_token_pos<span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                                      cur_input_embeds<span class="token punctuation">[</span>st_start_token_pos<span class="token punctuation">:</span>st_start_token_pos <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                      cur_st_features<span class="token punctuation">,</span>
                                                      cur_input_embeds<span class="token punctuation">[</span>
                                                      st_start_token_pos <span class="token operator">+</span> num_patches <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span>st_start_token_pos <span class="token operator">+</span> num_patches <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                      cur_input_embeds<span class="token punctuation">[</span>
                                                      st_start_token_pos <span class="token operator">+</span> num_patches <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    cur_new_input_embeds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>cur_input_embeds<span class="token punctuation">[</span><span class="token punctuation">:</span>st_start_token_pos <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                      cur_st_features<span class="token punctuation">,</span>
                                                      cur_input_embeds<span class="token punctuation">[</span>st_start_token_pos <span class="token operator">+</span> num_patches <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                                     dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
                cur_st_idx <span class="token operator">+=</span> <span class="token number">1</span>
            new_input_embeds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cur_new_input_embeds<span class="token punctuation">)</span>

        <span class="token keyword">assert</span> cur_st_idx <span class="token operator">==</span> <span class="token builtin">len</span><span class="token punctuation">(</span>st_projector_out<span class="token punctuation">)</span>
        <span class="token comment"># 输入embedding替换为缝合了时空编码信息的embedding</span>
        inputs_embeds <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>new_input_embeds<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token comment"># 调用llama的前向传播过程，解码输入信息</span>
    <span class="token keyword">return</span> <span class="token builtin">super</span><span class="token punctuation">(</span>STLlamaModel<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>forward<span class="token punctuation">(</span>
        input_ids<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> attention_mask<span class="token operator">=</span>attention_mask<span class="token punctuation">,</span> past_key_values<span class="token operator">=</span>past_key_values<span class="token punctuation">,</span>
        inputs_embeds<span class="token operator">=</span>inputs_embeds<span class="token punctuation">,</span> use_cache<span class="token operator">=</span>use_cache<span class="token punctuation">,</span>
        <span class="token comment"># 隐层也要输出，所以有这个参数</span>
        output_attentions<span class="token operator">=</span>output_attentions<span class="token punctuation">,</span> output_hidden_states<span class="token operator">=</span>output_hidden_states<span class="token punctuation">,</span>
        return_dict<span class="token operator">=</span>return_dict
    <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="主体模型-前向传播"><a href="#主体模型-前向传播" class="headerlink" title="主体模型 前向传播"></a>主体模型 前向传播</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 对时空信息的处理，包括时空特征的提取、投影和整合，以及更新输入嵌入表示后的模型正常前向传播过程</span>
  <span class="token comment"># 根据分类和回归损失对STLlama的时空相关部分进行梯度更新</span>
  <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>
          self<span class="token punctuation">,</span>
          input_ids<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>LongTensor <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># 输入标记的ID</span>
          attention_mask<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># 注意力遮罩</span>
          past_key_values<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>List<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># 过去的键值</span>
          inputs_embeds<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># 输入的嵌入表示</span>
          labels<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># 标签（用于计算损失）</span>
          use_cache<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">bool</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># 是否使用缓存</span>
          output_attentions<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">bool</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># 输出注意力权重</span>
          output_hidden_states<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">bool</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># 输出隐藏状态</span>
          st_data_x<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">list</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># 时序数据</span>
          st_data_y<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">list</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># 时序数据的标签</span>
          <span class="token comment"># x和y要送入STLlama执行时空编码，编码后经过线性层 st_projector 处理得到投影的结果，然后将其与文本嵌入拼接形成新的嵌入，送入大模型</span>
          region_start<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>  <span class="token comment"># 区域开始位置</span>
          region_end<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>  <span class="token comment"># 区域结束位置</span>
          return_dict<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">bool</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># 是否返回字典形式的输出</span>
  <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Union<span class="token punctuation">[</span>Tuple<span class="token punctuation">,</span> CausalLMOutputWithPast<span class="token punctuation">]</span><span class="token punctuation">:</span>
      output_attentions <span class="token operator">=</span> output_attentions <span class="token keyword">if</span> output_attentions <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">else</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>output_attentions
      output_hidden_states <span class="token operator">=</span> <span class="token punctuation">(</span>
          output_hidden_states <span class="token keyword">if</span> output_hidden_states <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">else</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>output_hidden_states
      <span class="token punctuation">)</span>
      return_dict <span class="token operator">=</span> return_dict <span class="token keyword">if</span> return_dict <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">else</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>use_return_dict

      <span class="token comment"># STllama解码器的输出包括(dec_features, layer_state, dec_hidden, dec_attn)</span>
      outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>
          input_ids<span class="token operator">=</span>input_ids<span class="token punctuation">,</span>
          attention_mask<span class="token operator">=</span>attention_mask<span class="token punctuation">,</span>
          past_key_values<span class="token operator">=</span>past_key_values<span class="token punctuation">,</span>
          inputs_embeds<span class="token operator">=</span>inputs_embeds<span class="token punctuation">,</span>
          use_cache<span class="token operator">=</span>use_cache<span class="token punctuation">,</span>
          output_attentions<span class="token operator">=</span>output_attentions<span class="token punctuation">,</span>
          output_hidden_states<span class="token operator">=</span>output_hidden_states<span class="token punctuation">,</span>
          return_dict<span class="token operator">=</span>return_dict<span class="token punctuation">,</span>
          st_data_x<span class="token operator">=</span>st_data_x<span class="token punctuation">,</span>
          st_data_y<span class="token operator">=</span>st_data_y<span class="token punctuation">,</span>
          region_start<span class="token operator">=</span>region_start<span class="token punctuation">,</span>
          region_end<span class="token operator">=</span>region_end
      <span class="token punctuation">)</span>

      feature_nums <span class="token operator">=</span> <span class="token number">2</span>
      hidden_states <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment"># STllama解码的隐层</span>
      batch_size <span class="token operator">=</span> hidden_states<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

      <span class="token comment"># =========通过自定义的回归层对hidden_state投影及预测部分做回归预测，然后比较和label之间的误差，</span>
      <span class="token comment"># 同时融合大模型隐层预测的结果logits的误差，综合回归+分类+文本生成误差，更新梯度===========</span>

      <span class="token comment"># 隐层做全连接得到最终st_pre结果</span>
      <span class="token keyword">if</span> labels <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
          <span class="token comment"># 从 hidden_states 中切片出start-end对应的部分（分别是待预测序列，预测表征序列），并将其转换成训练表征 st_pre_embs1 和 st_pre_embs2。</span>
          <span class="token comment"># 对 st_pre_embs1 和 st_pre_embs2 分别进行线性变换和relu激活函数操作，得到 st_pre_out1 和 st_pre_out2。</span>
          st_pre_embs1 <span class="token operator">=</span> hidden_states<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>
                         self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>st_start_id0 <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>st_start_id0 <span class="token operator">+</span> feature_nums <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>
                         <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> feature_nums<span class="token punctuation">,</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>
          <span class="token comment"># # [4, 1, 2, 4096]--&gt;[4, 1, 2, 128]</span>
          st_pre_out1 <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>st_pred_linear_1<span class="token punctuation">(</span>st_pre_embs1<span class="token punctuation">)</span><span class="token punctuation">)</span>
          st_pre_embs2 <span class="token operator">=</span> hidden_states<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>
                         self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>st_start_id1 <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>st_start_id1 <span class="token operator">+</span> feature_nums <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>
                         <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> feature_nums<span class="token punctuation">,</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>
          <span class="token comment"># # [4, 1, 2, 4096]--&gt;[4, 1, 2, 128]</span>
          st_pre_out2 <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>st_pred_linear_3<span class="token punctuation">(</span>st_pre_embs2<span class="token punctuation">)</span><span class="token punctuation">)</span>

          <span class="token comment"># 将 st_pre_out1 和 st_pre_out2 拼接起来，并经过另一个线性变换得到最终结果 st_pre_final。</span>
          <span class="token comment"># # [4, 1, 2, 256]--&gt;[4, 1, 2, 12]</span>
          st_pre_final <span class="token operator">=</span> self<span class="token punctuation">.</span>st_pred_linear_2<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>st_pre_out1<span class="token punctuation">,</span> st_pre_out2<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
          <span class="token comment"># # [4, 1, 2, 12]--&gt;[4, 1, 12, 2]</span>
          st_pre_final <span class="token operator">=</span> st_pre_final<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span>
      <span class="token keyword">else</span><span class="token punctuation">:</span>   <span class="token comment"># 测试，而非训练</span>
          self<span class="token punctuation">.</span>st_pre_res<span class="token punctuation">.</span>append<span class="token punctuation">(</span>hidden_states<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token comment"># 线性层，lm_head将隐层特征映射到词表</span>
      logits <span class="token operator">=</span> self<span class="token punctuation">.</span>lm_head<span class="token punctuation">(</span>hidden_states<span class="token punctuation">)</span>
      loss <span class="token operator">=</span> <span class="token boolean">None</span>
      <span class="token keyword">if</span> labels <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>  <span class="token comment"># 训练过程</span>

          <span class="token comment"># Shift so that tokens &lt; n predict n</span>
          shift_logits <span class="token operator">=</span> logits<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>
          shift_labels <span class="token operator">=</span> labels<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>
          <span class="token comment"># Flatten the tokens</span>
          loss_fct <span class="token operator">=</span> CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment"># fct，交叉熵</span>
          rec_loss <span class="token operator">=</span> scaler_mae_loss<span class="token punctuation">(</span>scaler<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> mask_value<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>    <span class="token comment">#MAE</span>
          bce_loss <span class="token operator">=</span> BCEWithLogitsLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
          shift_logits <span class="token operator">=</span> shift_logits<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>vocab_size<span class="token punctuation">)</span>
          shift_labels <span class="token operator">=</span> shift_labels<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
          <span class="token comment"># Enable model/pipeline parallelism</span>
          shift_labels <span class="token operator">=</span> shift_labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>shift_logits<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
          <span class="token comment"># 处理标签</span>
          <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>st_data_y<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">:</span>
              st_data_y <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>st_data_y<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
              labels_stpre <span class="token operator">=</span> st_data_y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> region_start<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>region_end<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>feature_nums<span class="token punctuation">]</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>
                  torch<span class="token punctuation">.</span>bfloat16<span class="token punctuation">)</span>
              task_type_all <span class="token operator">=</span> st_data_y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> region_start<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
          <span class="token keyword">else</span><span class="token punctuation">:</span>
              labels_stpre <span class="token operator">=</span> st_data_y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> region_start<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>region_end<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>feature_nums<span class="token punctuation">]</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>
                  torch<span class="token punctuation">.</span>bfloat16<span class="token punctuation">)</span>
              task_type_all <span class="token operator">=</span> st_data_y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> region_start<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>

          regress_idx_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
          classificate_idx_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
          regress_result_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
          classificate_result_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
          <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
              task_type <span class="token operator">=</span> task_type_all<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
              <span class="token comment"># classification</span>
              <span class="token keyword">if</span> task_type <span class="token operator">==</span> <span class="token number">3</span> <span class="token keyword">or</span> task_type <span class="token operator">==</span> <span class="token number">4</span><span class="token punctuation">:</span>
                  classificate_idx_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>
                  regress_result_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>st_pre_final<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                  classificate_result_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>st_pre_final<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
              <span class="token comment"># regression</span>
              <span class="token keyword">else</span><span class="token punctuation">:</span>
                  regress_idx_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>
                  classificate_result_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>st_pre_final<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                  regress_result_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>st_pre_final<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
          regress_result <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>regress_result_list<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
          classificate_result <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>classificate_result_list<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
          <span class="token comment"># 回归损失--MAE</span>
          loss_regress <span class="token operator">=</span> rec_loss<span class="token punctuation">(</span>regress_result<span class="token punctuation">,</span> labels_stpre<span class="token punctuation">)</span>
          labels_classificate <span class="token operator">=</span> labels_stpre
          labels_classificate<span class="token punctuation">[</span>labels_classificate <span class="token operator">&gt;=</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
          labels_classificate<span class="token punctuation">[</span>labels_classificate <span class="token operator">&lt;</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
          <span class="token comment"># 分类损失bce</span>
          loss_classificate <span class="token operator">=</span> bce_loss<span class="token punctuation">(</span>classificate_result<span class="token punctuation">,</span> labels_classificate<span class="token punctuation">)</span>
          <span class="token comment"># 综合损失</span>
          loss <span class="token operator">=</span> loss_fct<span class="token punctuation">(</span>shift_logits<span class="token punctuation">,</span> shift_labels<span class="token punctuation">)</span> <span class="token operator">+</span> loss_regress <span class="token operator">+</span> loss_classificate

      <span class="token keyword">if</span> <span class="token keyword">not</span> return_dict<span class="token punctuation">:</span>
          <span class="token comment"># print('not return dict')</span>
          output <span class="token operator">=</span> <span class="token punctuation">(</span>logits<span class="token punctuation">,</span><span class="token punctuation">)</span> <span class="token operator">+</span> outputs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
          <span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
          <span class="token keyword">return</span> <span class="token punctuation">(</span>loss<span class="token punctuation">,</span><span class="token punctuation">)</span> <span class="token operator">+</span> output <span class="token keyword">if</span> loss <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">else</span> output

      <span class="token keyword">return</span> CausalLMOutputWithPast<span class="token punctuation">(</span>
          loss<span class="token operator">=</span>loss<span class="token punctuation">,</span>
          logits<span class="token operator">=</span>logits<span class="token punctuation">,</span>
          past_key_values<span class="token operator">=</span>outputs<span class="token punctuation">.</span>past_key_values<span class="token punctuation">,</span>
          hidden_states<span class="token operator">=</span>outputs<span class="token punctuation">.</span>hidden_states<span class="token punctuation">,</span>
          attentions<span class="token operator">=</span>outputs<span class="token punctuation">.</span>attentions<span class="token punctuation">,</span>
      <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="评估-1"><a href="#评估-1" class="headerlink" title="评估"></a>评估</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token decorator annotation punctuation">@ray<span class="token punctuation">.</span>remote</span><span class="token punctuation">(</span>num_gpus<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>inference_mode</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">eval_model</span><span class="token punctuation">(</span>args<span class="token punctuation">,</span> prompt_file<span class="token punctuation">,</span> start_idx<span class="token punctuation">,</span> end_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># load prompting file</span>
    <span class="token comment"># prompt_file = load_prompting_file(args.prompting_file)</span>

    <span class="token comment"># Model</span>
    disable_torch_init<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># model_name = os.path.expanduser(args.model_name)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'start loading'</span><span class="token punctuation">)</span>
    <span class="token comment"># 加载预训练的tokenizer，用于对输入文本进行编码</span>
    tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>args<span class="token punctuation">.</span>model_name<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'finish loading'</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'start loading'</span><span class="token punctuation">)</span>
    <span class="token comment"># 加载预训练的时空语言模型</span>
    model <span class="token operator">=</span> STLlamaForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>args<span class="token punctuation">.</span>model_name<span class="token punctuation">,</span> torch_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bfloat16<span class="token punctuation">,</span> use_cache<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                                  low_cpu_mem_usage<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 设置时空依赖编码器</span>
    model<span class="token punctuation">.</span>set_st_tower<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'finish loading'</span><span class="token punctuation">)</span>

    <span class="token comment"># 根据模型配置，调整tokenizer的词汇表，添加时空相关的特殊标记。</span>
    use_st_start_end <span class="token operator">=</span> <span class="token builtin">getattr</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>config<span class="token punctuation">,</span> <span class="token string">"use_st_start_end"</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span>
    tokenizer<span class="token punctuation">.</span>add_tokens<span class="token punctuation">(</span><span class="token punctuation">[</span>DEFAULT_ST_PATCH_TOKEN<span class="token punctuation">]</span><span class="token punctuation">,</span> special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> use_st_start_end<span class="token punctuation">:</span>
        tokenizer<span class="token punctuation">.</span>add_tokens<span class="token punctuation">(</span><span class="token punctuation">[</span>DEFAULT_ST_START_TOKEN<span class="token punctuation">,</span> DEFAULT_ST_END_TOKEN<span class="token punctuation">]</span><span class="token punctuation">,</span> special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    st_tower <span class="token operator">=</span> model<span class="token punctuation">.</span>get_model<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>st_tower
    <span class="token comment"># 配置编码器</span>
    st_config <span class="token operator">=</span> st_tower<span class="token punctuation">.</span>config
    st_config<span class="token punctuation">.</span>st_patch_token <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>convert_tokens_to_ids<span class="token punctuation">(</span><span class="token punctuation">[</span>DEFAULT_ST_PATCH_TOKEN<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token comment"># 配置中的token使用对应词汇在词表中的id</span>
    st_config<span class="token punctuation">.</span>use_st_start_end <span class="token operator">=</span> use_st_start_end
    <span class="token keyword">if</span> use_st_start_end<span class="token punctuation">:</span>
        st_config<span class="token punctuation">.</span>st_start_token<span class="token punctuation">,</span> st_config<span class="token punctuation">.</span>st_end_token <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>convert_tokens_to_ids<span class="token punctuation">(</span>
            <span class="token punctuation">[</span>DEFAULT_ST_START_TOKEN<span class="token punctuation">,</span> DEFAULT_ST_END_TOKEN<span class="token punctuation">]</span><span class="token punctuation">)</span>

    res_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'total: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>prompt_file<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>st_data_path<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
        st_data_all <span class="token operator">=</span> pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">)</span>
    error_i <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> idx<span class="token punctuation">,</span> instruct_item <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>prompt_file<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 使用load_st加载时空数据，包括时空标记长度、时空数据x和y的编码信息、时空区域的起始和结束位置等</span>
        <span class="token comment"># prompt file对应的instruct item：NYC_taxi.json</span>
        <span class="token comment"># st_data：pkl文件，存储已经训练好的时序编码信息</span>
        st_dict <span class="token operator">=</span> load_st<span class="token punctuation">(</span>idx<span class="token punctuation">,</span> instruct_item<span class="token punctuation">,</span> st_data_all<span class="token punctuation">)</span>
        st_token_len <span class="token operator">=</span> st_dict<span class="token punctuation">[</span><span class="token string">'st_token_len'</span><span class="token punctuation">]</span>
        st_data_x <span class="token operator">=</span> st_dict<span class="token punctuation">[</span><span class="token string">'st_data_x'</span><span class="token punctuation">]</span>
        st_data_y <span class="token operator">=</span> st_dict<span class="token punctuation">[</span><span class="token string">'st_data_y'</span><span class="token punctuation">]</span>
        region_start <span class="token operator">=</span> st_dict<span class="token punctuation">[</span><span class="token string">'region_start'</span><span class="token punctuation">]</span>
        region_end <span class="token operator">=</span> st_dict<span class="token punctuation">[</span><span class="token string">'region_end'</span><span class="token punctuation">]</span>
        <span class="token comment"># 自然语言问题从instruct_item中提取</span>
        qs <span class="token operator">=</span> instruct_item<span class="token punctuation">[</span><span class="token string">"conversations"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"value"</span><span class="token punctuation">]</span>
        replace_token <span class="token operator">=</span> DEFAULT_ST_PATCH_TOKEN <span class="token operator">*</span> st_token_len
        replace_token <span class="token operator">=</span> DEFAULT_ST_START_TOKEN <span class="token operator">+</span> replace_token <span class="token operator">+</span> DEFAULT_ST_END_TOKEN
        qs <span class="token operator">=</span> qs<span class="token punctuation">.</span>replace<span class="token punctuation">(</span>DEFAULT_STHIS_TOKEN<span class="token punctuation">,</span> replace_token<span class="token punctuation">)</span>
        qs <span class="token operator">=</span> qs<span class="token punctuation">.</span>replace<span class="token punctuation">(</span>DEFAULT_STPRE_TOKEN<span class="token punctuation">,</span> replace_token<span class="token punctuation">)</span>

        <span class="token comment"># if "v1" in args.model_name.lower():</span>
        <span class="token comment">#     conv_mode = "stchat_v1"</span>
        <span class="token comment"># else:</span>
        <span class="token comment">#     raise ValueError('Don\'t support this model')</span>
        conv_mode <span class="token operator">=</span> <span class="token string">"stchat_v1"</span>

        <span class="token keyword">if</span> args<span class="token punctuation">.</span>conv_mode <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> conv_mode <span class="token operator">!=</span> args<span class="token punctuation">.</span>conv_mode<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[WARNING] the auto inferred conversation mode is {}, while `--conv-mode` is {}, using {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
                conv_mode<span class="token punctuation">,</span> args<span class="token punctuation">.</span>conv_mode<span class="token punctuation">,</span> args<span class="token punctuation">.</span>conv_mode<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            args<span class="token punctuation">.</span>conv_mode <span class="token operator">=</span> conv_mode

        conv <span class="token operator">=</span> conv_templates<span class="token punctuation">[</span>args<span class="token punctuation">.</span>conv_mode<span class="token punctuation">]</span><span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
        conv<span class="token punctuation">.</span>append_message<span class="token punctuation">(</span>conv<span class="token punctuation">.</span>roles<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> qs<span class="token punctuation">)</span>  <span class="token comment"># 为用户角色添加qs问题</span>
        conv<span class="token punctuation">.</span>append_message<span class="token punctuation">(</span>conv<span class="token punctuation">.</span>roles<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
        prompt <span class="token operator">=</span> conv<span class="token punctuation">.</span>get_prompt<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 对prompt编码</span>
        inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span><span class="token punctuation">[</span>prompt<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment"># 输入张量</span>
        input_ids <span class="token operator">=</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>input_ids<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 停用词</span>
        stop_str <span class="token operator">=</span> conv<span class="token punctuation">.</span>sep <span class="token keyword">if</span> conv<span class="token punctuation">.</span>sep_style <span class="token operator">!=</span> SeparatorStyle<span class="token punctuation">.</span>TWO <span class="token keyword">else</span> conv<span class="token punctuation">.</span>sep2
        keywords <span class="token operator">=</span> <span class="token punctuation">[</span>stop_str<span class="token punctuation">]</span>
        stopping_criteria <span class="token operator">=</span> KeywordsStoppingCriteria<span class="token punctuation">(</span>keywords<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> input_ids<span class="token punctuation">)</span>

        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>inference_mode<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 大模型解码，生成预测文本tokens的id序列</span>
            output_ids <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>
                input_ids<span class="token punctuation">,</span>
                <span class="token comment"># st_data=st_data_x,</span>
                st_data_x<span class="token operator">=</span>st_data_x<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                st_data_y<span class="token operator">=</span>st_data_y<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                region_start<span class="token operator">=</span>region_start<span class="token punctuation">,</span>
                region_end<span class="token operator">=</span>region_end<span class="token punctuation">,</span>
                do_sample<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                <span class="token comment"># do_sample=False,</span>
                <span class="token comment"># temperature=0.2,</span>
                temperature<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
                <span class="token comment"># max_new_tokens=1024,</span>
                max_new_tokens<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>
                stopping_criteria<span class="token operator">=</span><span class="token punctuation">[</span>stopping_criteria<span class="token punctuation">]</span><span class="token punctuation">)</span>

            <span class="token comment"># 找到自定义的special token</span>
            start_inx <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>output_ids<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">32001</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            end_inx <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>output_ids<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">32002</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            <span class="token comment"># 获取隐层状态</span>
            hidden_states <span class="token operator">=</span> model<span class="token punctuation">.</span>get_st_pre_res<span class="token punctuation">(</span><span class="token punctuation">)</span>
            hidden_states <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>hidden_states<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
            model<span class="token punctuation">.</span>reset_st_pre_res<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># 将tokens解码为输出结果</span>
            batch_size <span class="token operator">=</span> hidden_states<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            feature_nums <span class="token operator">=</span> <span class="token number">2</span>
            st_pre_embs1 <span class="token operator">=</span> hidden_states<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>
                           model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>st_start_id0 <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span>model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>st_start_id0 <span class="token operator">+</span> feature_nums <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>
                           <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> feature_nums<span class="token punctuation">,</span> model<span class="token punctuation">.</span>config<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>
            <span class="token comment"># 通过一个线性层获取结果</span>
            st_pre_out1 <span class="token operator">=</span> model<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>model<span class="token punctuation">.</span>st_pred_linear_1<span class="token punctuation">(</span>st_pre_embs1<span class="token punctuation">)</span><span class="token punctuation">)</span>

            <span class="token keyword">if</span> start_inx<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">3</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> hidden_states<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&gt;</span> start_inx<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">+</span> feature_nums<span class="token punctuation">:</span>
                    st_pre_embs2 <span class="token operator">=</span> hidden_states<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> start_inx<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span>start_inx<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">+</span> feature_nums<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'========error========'</span><span class="token punctuation">)</span>
                    error_i <span class="token operator">=</span> error_i <span class="token operator">+</span> <span class="token number">1</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span>error_i<span class="token punctuation">)</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span>hidden_states<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> start_inx<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
                    st_pre_embs2 <span class="token operator">=</span> hidden_states<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">+</span>feature_nums<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'========error========'</span><span class="token punctuation">)</span>
                error_i <span class="token operator">=</span> error_i <span class="token operator">+</span> <span class="token number">1</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span>error_i<span class="token punctuation">)</span>
                st_pre_embs2 <span class="token operator">=</span> hidden_states<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">+</span>feature_nums<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
            st_pre_embs2 <span class="token operator">=</span> st_pre_embs2<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> feature_nums<span class="token punctuation">,</span> model<span class="token punctuation">.</span>config<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>
            st_pre_out2 <span class="token operator">=</span> model<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>model<span class="token punctuation">.</span>st_pred_linear_3<span class="token punctuation">(</span>st_pre_embs2<span class="token punctuation">)</span><span class="token punctuation">)</span>
            st_pre_final <span class="token operator">=</span> model<span class="token punctuation">.</span>st_pred_linear_2<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>st_pre_out1<span class="token punctuation">,</span> st_pre_out2<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            st_pre_final <span class="token operator">=</span> st_pre_final<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span>
            st_pre_infolow <span class="token operator">=</span> st_pre_final<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
            st_pre_outfolow <span class="token operator">=</span> st_pre_final<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>


        x_in<span class="token punctuation">,</span> y_in <span class="token operator">=</span> st_data_x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> region_start<span class="token punctuation">:</span>region_end<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> st_data_y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> region_start<span class="token punctuation">:</span>region_end<span class="token punctuation">,</span>
                                                                           <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
        x_out<span class="token punctuation">,</span> y_out <span class="token operator">=</span> st_data_x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> region_start<span class="token punctuation">:</span>region_end<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> st_data_y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> region_start<span class="token punctuation">:</span>region_end<span class="token punctuation">,</span>
                                                                             <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>

        input_token_len <span class="token operator">=</span> input_ids<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        n_diff_input_output <span class="token operator">=</span> <span class="token punctuation">(</span>input_ids <span class="token operator">!=</span> output_ids<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>input_token_len<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> n_diff_input_output <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'[Warning] </span><span class="token interpolation"><span class="token punctuation">{</span>n_diff_input_output<span class="token punctuation">}</span></span><span class="token string"> output_ids are not the same as the input_ids'</span></span><span class="token punctuation">)</span>
        <span class="token comment"># outputs = tokenizer.batch_decode(output_ids[:, input_token_len:], skip_special_tokens=True)[0]</span>
        outputs <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>output_ids<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> input_token_len<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        outputs <span class="token operator">=</span> outputs<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> outputs<span class="token punctuation">.</span>endswith<span class="token punctuation">(</span>stop_str<span class="token punctuation">)</span><span class="token punctuation">:</span>
            outputs <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token builtin">len</span><span class="token punctuation">(</span>stop_str<span class="token punctuation">)</span><span class="token punctuation">]</span>
        outputs <span class="token operator">=</span> outputs<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>

        res_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
            <span class="token punctuation">{</span><span class="token string">"id"</span><span class="token punctuation">:</span> instruct_item<span class="token punctuation">[</span><span class="token string">"id"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"res"</span><span class="token punctuation">:</span> outputs<span class="token punctuation">,</span> <span class="token string">"x_in"</span><span class="token punctuation">:</span> x_in<span class="token punctuation">,</span> <span class="token string">"x_out"</span><span class="token punctuation">:</span> x_out<span class="token punctuation">,</span> <span class="token string">"y_in"</span><span class="token punctuation">:</span> y_in<span class="token punctuation">,</span> <span class="token string">"y_out"</span><span class="token punctuation">:</span> y_out<span class="token punctuation">,</span>
             <span class="token string">"st_pre_infolow"</span><span class="token punctuation">:</span> st_pre_infolow<span class="token punctuation">,</span> <span class="token string">"st_pre_outfolow"</span><span class="token punctuation">:</span> st_pre_outfolow<span class="token punctuation">}</span><span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>osp<span class="token punctuation">.</span>join<span class="token punctuation">(</span>args<span class="token punctuation">.</span>output_res_path<span class="token punctuation">,</span> <span class="token string">'arxiv_test_res_{}_{}.json'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>start_idx<span class="token punctuation">,</span> end_idx<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fout<span class="token punctuation">:</span>
            json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>res_data<span class="token punctuation">,</span> fout<span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> res_data
    <span class="token comment"># with open(args.output_res_path, "w") as fout:</span>
    <span class="token comment">#     json.dump(res_data, fout, indent=4)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

</span>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">wolf-ll</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://wolf-ll.github.io/2024/04/30/urbangpt-spatio-temporal-large-language-models/">http://wolf-ll.github.io/2024/04/30/urbangpt-spatio-temporal-large-language-models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">wolf-ll</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/LLM/">
                                    <span class="chip bg-color">LLM</span>
                                </a>
                            
                                <a href="/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/">
                                    <span class="chip bg-color">时间序列</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    
    <div class="card" data-aos="fade-up">
    <div id="utteranc-container" class="card-content">
        <script src="https://utteranc.es/client.js"
                repo="wolf-ll/comments"
                issue-term="pathname"
                theme="github-light"
                crossorigin="anonymous"
                async>
        </script>
    </div>
</div>
    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2024/05/11/redis/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/19.jpg" class="responsive-img" alt="redis">
                        
                        <span class="card-title">redis</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Redis数据库基础与原理
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-05-11
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%90%8E%E7%AB%AF/" class="post-category">
                                    后端
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/">
                        <span class="chip bg-color">数据库</span>
                    </a>
                    
                    <a href="/tags/Redis/">
                        <span class="chip bg-color">Redis</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2024/04/26/mysql/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/18.jpg" class="responsive-img" alt="MySQL">
                        
                        <span class="card-title">MySQL</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            MySQL数据库查漏补缺，持续更新
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-04-26
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%90%8E%E7%AB%AF/" class="post-category">
                                    后端
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/">
                        <span class="chip bg-color">数据库</span>
                    </a>
                    
                    <a href="/tags/MySQL/">
                        <span class="chip bg-color">MySQL</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <span id="year">2024</span>
            <a href="/about" target="_blank">wolf-ll</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">264k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2024";
                    var startMonth = "4";
                    var startDate = "21";
                    var startHour = "16";
                    var startMinute = "35";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/wolf-ll" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:837691088@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=837691088" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 837691088" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>





    <a href="https://www.zhihu.com/people/zhi-qi-wei-tuo" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/zhi-qi-wei-tuo" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

	
    

    

    
    <script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async="async"></script>
    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
